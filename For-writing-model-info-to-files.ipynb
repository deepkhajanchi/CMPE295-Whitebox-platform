{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 1)\n",
      "(2947, 128, 9) (2947, 1)\n",
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
      "INFO:tensorflow:Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               44000     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 54,706\n",
      "Trainable params: 54,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 7352 samples\n",
      "Epoch 1/5\n",
      "INFO:tensorflow:For batch 0, loss is    1.76.\n",
      "INFO:tensorflow:For batch 0, accuracy is    0.28.\n",
      "  64/7352 [..............................] - ETA: 4:18 - loss: 1.7614 - accuracy: 0.2812INFO:tensorflow:For batch 1, loss is    1.74.\n",
      "INFO:tensorflow:For batch 1, accuracy is    0.28.\n",
      " 128/7352 [..............................] - ETA: 2:17 - loss: 1.7512 - accuracy: 0.2812INFO:tensorflow:For batch 2, loss is    1.73.\n",
      "INFO:tensorflow:For batch 2, accuracy is    0.31.\n",
      " 192/7352 [..............................] - ETA: 1:37 - loss: 1.7444 - accuracy: 0.3125INFO:tensorflow:For batch 3, loss is    1.73.\n",
      "INFO:tensorflow:For batch 3, accuracy is    0.32.\n",
      " 256/7352 [>.............................] - ETA: 1:18 - loss: 1.7418 - accuracy: 0.3203INFO:tensorflow:For batch 4, loss is    1.69.\n",
      "INFO:tensorflow:For batch 4, accuracy is    0.33.\n",
      " 320/7352 [>.............................] - ETA: 1:05 - loss: 1.7323 - accuracy: 0.3344INFO:tensorflow:For batch 5, loss is    1.72.\n",
      "INFO:tensorflow:For batch 5, accuracy is    0.32.\n",
      " 384/7352 [>.............................] - ETA: 57s - loss: 1.7294 - accuracy: 0.3229 INFO:tensorflow:For batch 6, loss is    1.68.\n",
      "INFO:tensorflow:For batch 6, accuracy is    0.32.\n",
      " 448/7352 [>.............................] - ETA: 52s - loss: 1.7216 - accuracy: 0.3192INFO:tensorflow:For batch 7, loss is    1.59.\n",
      "INFO:tensorflow:For batch 7, accuracy is    0.35.\n",
      " 512/7352 [=>............................] - ETA: 48s - loss: 1.7055 - accuracy: 0.3457INFO:tensorflow:For batch 8, loss is    1.62.\n",
      "INFO:tensorflow:For batch 8, accuracy is    0.35.\n",
      " 576/7352 [=>............................] - ETA: 44s - loss: 1.6957 - accuracy: 0.3490INFO:tensorflow:For batch 9, loss is    1.59.\n",
      "INFO:tensorflow:For batch 9, accuracy is    0.35.\n",
      " 640/7352 [=>............................] - ETA: 41s - loss: 1.6847 - accuracy: 0.3531INFO:tensorflow:For batch 10, loss is    1.53.\n",
      "INFO:tensorflow:For batch 10, accuracy is    0.36.\n",
      " 704/7352 [=>............................] - ETA: 38s - loss: 1.6707 - accuracy: 0.3636INFO:tensorflow:For batch 11, loss is    1.42.\n",
      "INFO:tensorflow:For batch 11, accuracy is    0.37.\n",
      " 768/7352 [==>...........................] - ETA: 37s - loss: 1.6495 - accuracy: 0.3659INFO:tensorflow:For batch 12, loss is    1.30.\n",
      "INFO:tensorflow:For batch 12, accuracy is    0.38.\n",
      " 832/7352 [==>...........................] - ETA: 35s - loss: 1.6224 - accuracy: 0.3750INFO:tensorflow:For batch 13, loss is    1.40.\n",
      "INFO:tensorflow:For batch 13, accuracy is    0.38.\n",
      " 896/7352 [==>...........................] - ETA: 33s - loss: 1.6068 - accuracy: 0.3795INFO:tensorflow:For batch 14, loss is    1.28.\n",
      "INFO:tensorflow:For batch 14, accuracy is    0.39.\n",
      " 960/7352 [==>...........................] - ETA: 33s - loss: 1.5849 - accuracy: 0.3875INFO:tensorflow:For batch 15, loss is    1.39.\n",
      "INFO:tensorflow:For batch 15, accuracy is    0.39.\n",
      "1024/7352 [===>..........................] - ETA: 31s - loss: 1.5726 - accuracy: 0.3877INFO:tensorflow:For batch 16, loss is    1.25.\n",
      "INFO:tensorflow:For batch 16, accuracy is    0.39.\n",
      "1088/7352 [===>..........................] - ETA: 30s - loss: 1.5538 - accuracy: 0.3879INFO:tensorflow:For batch 17, loss is    1.43.\n",
      "INFO:tensorflow:For batch 17, accuracy is    0.39.\n",
      "1152/7352 [===>..........................] - ETA: 29s - loss: 1.5467 - accuracy: 0.3872INFO:tensorflow:For batch 18, loss is    1.48.\n",
      "INFO:tensorflow:For batch 18, accuracy is    0.38.\n",
      "1216/7352 [===>..........................] - ETA: 28s - loss: 1.5432 - accuracy: 0.3840INFO:tensorflow:For batch 19, loss is    1.29.\n",
      "INFO:tensorflow:For batch 19, accuracy is    0.39.\n",
      "1280/7352 [====>.........................] - ETA: 28s - loss: 1.5305 - accuracy: 0.3867INFO:tensorflow:For batch 20, loss is    1.36.\n",
      "INFO:tensorflow:For batch 20, accuracy is    0.38.\n",
      "1344/7352 [====>.........................] - ETA: 27s - loss: 1.5225 - accuracy: 0.3839INFO:tensorflow:For batch 21, loss is    1.33.\n",
      "INFO:tensorflow:For batch 21, accuracy is    0.39.\n",
      "1408/7352 [====>.........................] - ETA: 26s - loss: 1.5139 - accuracy: 0.3864INFO:tensorflow:For batch 22, loss is    1.35.\n",
      "INFO:tensorflow:For batch 22, accuracy is    0.39.\n",
      "1472/7352 [=====>........................] - ETA: 25s - loss: 1.5067 - accuracy: 0.3852INFO:tensorflow:For batch 23, loss is    1.30.\n",
      "INFO:tensorflow:For batch 23, accuracy is    0.39.\n",
      "1536/7352 [=====>........................] - ETA: 25s - loss: 1.4982 - accuracy: 0.3867INFO:tensorflow:For batch 24, loss is    1.21.\n",
      "INFO:tensorflow:For batch 24, accuracy is    0.39.\n",
      "1600/7352 [=====>........................] - ETA: 25s - loss: 1.4865 - accuracy: 0.3919INFO:tensorflow:For batch 25, loss is    1.33.\n",
      "INFO:tensorflow:For batch 25, accuracy is    0.39.\n",
      "1664/7352 [=====>........................] - ETA: 24s - loss: 1.4804 - accuracy: 0.3948INFO:tensorflow:For batch 26, loss is    1.29.\n",
      "INFO:tensorflow:For batch 26, accuracy is    0.39.\n",
      "1728/7352 [======>.......................] - ETA: 24s - loss: 1.4734 - accuracy: 0.3947INFO:tensorflow:For batch 27, loss is    1.15.\n",
      "INFO:tensorflow:For batch 27, accuracy is    0.40.\n",
      "1792/7352 [======>.......................] - ETA: 23s - loss: 1.4620 - accuracy: 0.4007INFO:tensorflow:For batch 28, loss is    1.48.\n",
      "INFO:tensorflow:For batch 28, accuracy is    0.40.\n",
      "1856/7352 [======>.......................] - ETA: 23s - loss: 1.4625 - accuracy: 0.3987INFO:tensorflow:For batch 29, loss is    1.22.\n",
      "INFO:tensorflow:For batch 29, accuracy is    0.40.\n",
      "1920/7352 [======>.......................] - ETA: 23s - loss: 1.4543 - accuracy: 0.4010INFO:tensorflow:For batch 30, loss is    1.30.\n",
      "INFO:tensorflow:For batch 30, accuracy is    0.40.\n",
      "1984/7352 [=======>......................] - ETA: 22s - loss: 1.4491 - accuracy: 0.4017INFO:tensorflow:For batch 31, loss is    1.18.\n",
      "INFO:tensorflow:For batch 31, accuracy is    0.41.\n",
      "2048/7352 [=======>......................] - ETA: 22s - loss: 1.4407 - accuracy: 0.4067INFO:tensorflow:For batch 32, loss is    1.36.\n",
      "INFO:tensorflow:For batch 32, accuracy is    0.41.\n",
      "2112/7352 [=======>......................] - ETA: 21s - loss: 1.4383 - accuracy: 0.4067INFO:tensorflow:For batch 33, loss is    1.20.\n",
      "INFO:tensorflow:For batch 33, accuracy is    0.41.\n",
      "2176/7352 [=======>......................] - ETA: 21s - loss: 1.4313 - accuracy: 0.4072INFO:tensorflow:For batch 34, loss is    1.31.\n",
      "INFO:tensorflow:For batch 34, accuracy is    0.41.\n",
      "2240/7352 [========>.....................] - ETA: 20s - loss: 1.4279 - accuracy: 0.4089INFO:tensorflow:For batch 35, loss is    1.29.\n",
      "INFO:tensorflow:For batch 35, accuracy is    0.41.\n",
      "2304/7352 [========>.....................] - ETA: 20s - loss: 1.4240 - accuracy: 0.4110INFO:tensorflow:For batch 36, loss is    1.06.\n",
      "INFO:tensorflow:For batch 36, accuracy is    0.41.\n",
      "2368/7352 [========>.....................] - ETA: 20s - loss: 1.4142 - accuracy: 0.4143INFO:tensorflow:For batch 37, loss is    1.22.\n",
      "INFO:tensorflow:For batch 37, accuracy is    0.42.\n",
      "2432/7352 [========>.....................] - ETA: 19s - loss: 1.4090 - accuracy: 0.4157INFO:tensorflow:For batch 38, loss is    0.96.\n",
      "INFO:tensorflow:For batch 38, accuracy is    0.42.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2496/7352 [=========>....................] - ETA: 19s - loss: 1.3975 - accuracy: 0.4187INFO:tensorflow:For batch 39, loss is    1.08.\n",
      "INFO:tensorflow:For batch 39, accuracy is    0.42.\n",
      "2560/7352 [=========>....................] - ETA: 18s - loss: 1.3896 - accuracy: 0.4223INFO:tensorflow:For batch 40, loss is    1.26.\n",
      "INFO:tensorflow:For batch 40, accuracy is    0.42.\n",
      "2624/7352 [=========>....................] - ETA: 18s - loss: 1.3864 - accuracy: 0.4238INFO:tensorflow:For batch 41, loss is    1.25.\n",
      "INFO:tensorflow:For batch 41, accuracy is    0.42.\n",
      "2688/7352 [=========>....................] - ETA: 18s - loss: 1.3832 - accuracy: 0.4241INFO:tensorflow:For batch 42, loss is    0.95.\n",
      "INFO:tensorflow:For batch 42, accuracy is    0.43.\n",
      "2752/7352 [==========>...................] - ETA: 17s - loss: 1.3731 - accuracy: 0.4277INFO:tensorflow:For batch 43, loss is    1.22.\n",
      "INFO:tensorflow:For batch 43, accuracy is    0.43.\n",
      "2816/7352 [==========>...................] - ETA: 17s - loss: 1.3697 - accuracy: 0.4300INFO:tensorflow:For batch 44, loss is    0.94.\n",
      "INFO:tensorflow:For batch 44, accuracy is    0.43.\n",
      "2880/7352 [==========>...................] - ETA: 17s - loss: 1.3600 - accuracy: 0.4337INFO:tensorflow:For batch 45, loss is    1.07.\n",
      "INFO:tensorflow:For batch 45, accuracy is    0.44.\n",
      "2944/7352 [===========>..................] - ETA: 16s - loss: 1.3538 - accuracy: 0.4355INFO:tensorflow:For batch 46, loss is    0.90.\n",
      "INFO:tensorflow:For batch 46, accuracy is    0.44.\n",
      "3008/7352 [===========>..................] - ETA: 16s - loss: 1.3441 - accuracy: 0.4388INFO:tensorflow:For batch 47, loss is    1.16.\n",
      "INFO:tensorflow:For batch 47, accuracy is    0.44.\n",
      "3072/7352 [===========>..................] - ETA: 16s - loss: 1.3403 - accuracy: 0.4398INFO:tensorflow:For batch 48, loss is    1.34.\n",
      "INFO:tensorflow:For batch 48, accuracy is    0.44.\n",
      "3136/7352 [===========>..................] - ETA: 15s - loss: 1.3402 - accuracy: 0.4385INFO:tensorflow:For batch 49, loss is    0.99.\n",
      "INFO:tensorflow:For batch 49, accuracy is    0.44.\n",
      "3200/7352 [============>.................] - ETA: 15s - loss: 1.3332 - accuracy: 0.4412INFO:tensorflow:For batch 50, loss is    1.14.\n",
      "INFO:tensorflow:For batch 50, accuracy is    0.44.\n",
      "3264/7352 [============>.................] - ETA: 15s - loss: 1.3294 - accuracy: 0.4433INFO:tensorflow:For batch 51, loss is    1.02.\n",
      "INFO:tensorflow:For batch 51, accuracy is    0.45.\n",
      "3328/7352 [============>.................] - ETA: 14s - loss: 1.3236 - accuracy: 0.4456INFO:tensorflow:For batch 52, loss is    1.11.\n",
      "INFO:tensorflow:For batch 52, accuracy is    0.45.\n",
      "3392/7352 [============>.................] - ETA: 14s - loss: 1.3195 - accuracy: 0.4463INFO:tensorflow:For batch 53, loss is    1.22.\n",
      "INFO:tensorflow:For batch 53, accuracy is    0.45.\n",
      "3456/7352 [=============>................] - ETA: 14s - loss: 1.3177 - accuracy: 0.4465INFO:tensorflow:For batch 54, loss is    1.01.\n",
      "INFO:tensorflow:For batch 54, accuracy is    0.45.\n",
      "3520/7352 [=============>................] - ETA: 14s - loss: 1.3120 - accuracy: 0.4483INFO:tensorflow:For batch 55, loss is    1.20.\n",
      "INFO:tensorflow:For batch 55, accuracy is    0.45.\n",
      "3584/7352 [=============>................] - ETA: 13s - loss: 1.3099 - accuracy: 0.4487INFO:tensorflow:For batch 56, loss is    1.16.\n",
      "INFO:tensorflow:For batch 56, accuracy is    0.45.\n",
      "3648/7352 [=============>................] - ETA: 13s - loss: 1.3074 - accuracy: 0.4490INFO:tensorflow:For batch 57, loss is    1.22.\n",
      "INFO:tensorflow:For batch 57, accuracy is    0.45.\n",
      "3712/7352 [==============>...............] - ETA: 13s - loss: 1.3058 - accuracy: 0.4494INFO:tensorflow:For batch 58, loss is    1.02.\n",
      "INFO:tensorflow:For batch 58, accuracy is    0.45.\n",
      "3776/7352 [==============>...............] - ETA: 13s - loss: 1.3009 - accuracy: 0.4518INFO:tensorflow:For batch 59, loss is    1.17.\n",
      "INFO:tensorflow:For batch 59, accuracy is    0.45.\n",
      "3840/7352 [==============>...............] - ETA: 12s - loss: 1.2987 - accuracy: 0.4529INFO:tensorflow:For batch 60, loss is    1.05.\n",
      "INFO:tensorflow:For batch 60, accuracy is    0.45.\n",
      "3904/7352 [==============>...............] - ETA: 12s - loss: 1.2946 - accuracy: 0.4541INFO:tensorflow:For batch 61, loss is    0.98.\n",
      "INFO:tensorflow:For batch 61, accuracy is    0.46.\n",
      "3968/7352 [===============>..............] - ETA: 12s - loss: 1.2895 - accuracy: 0.4564INFO:tensorflow:For batch 62, loss is    1.01.\n",
      "INFO:tensorflow:For batch 62, accuracy is    0.46.\n",
      "4032/7352 [===============>..............] - ETA: 11s - loss: 1.2851 - accuracy: 0.4573INFO:tensorflow:For batch 63, loss is    1.11.\n",
      "INFO:tensorflow:For batch 63, accuracy is    0.46.\n",
      "4096/7352 [===============>..............] - ETA: 11s - loss: 1.2824 - accuracy: 0.4578INFO:tensorflow:For batch 64, loss is    0.96.\n",
      "INFO:tensorflow:For batch 64, accuracy is    0.46.\n",
      "4160/7352 [===============>..............] - ETA: 11s - loss: 1.2774 - accuracy: 0.4608INFO:tensorflow:For batch 65, loss is    1.03.\n",
      "INFO:tensorflow:For batch 65, accuracy is    0.46.\n",
      "4224/7352 [================>.............] - ETA: 11s - loss: 1.2736 - accuracy: 0.4619INFO:tensorflow:For batch 66, loss is    1.11.\n",
      "INFO:tensorflow:For batch 66, accuracy is    0.46.\n",
      "4288/7352 [================>.............] - ETA: 10s - loss: 1.2712 - accuracy: 0.4620INFO:tensorflow:For batch 67, loss is    1.00.\n",
      "INFO:tensorflow:For batch 67, accuracy is    0.46.\n",
      "4352/7352 [================>.............] - ETA: 10s - loss: 1.2673 - accuracy: 0.4642INFO:tensorflow:For batch 68, loss is    1.25.\n",
      "INFO:tensorflow:For batch 68, accuracy is    0.46.\n",
      "4416/7352 [=================>............] - ETA: 10s - loss: 1.2669 - accuracy: 0.4638INFO:tensorflow:For batch 69, loss is    1.13.\n",
      "INFO:tensorflow:For batch 69, accuracy is    0.46.\n",
      "4480/7352 [=================>............] - ETA: 10s - loss: 1.2650 - accuracy: 0.4641INFO:tensorflow:For batch 70, loss is    0.85.\n",
      "INFO:tensorflow:For batch 70, accuracy is    0.47.\n",
      "4544/7352 [=================>............] - ETA: 9s - loss: 1.2592 - accuracy: 0.4670 INFO:tensorflow:For batch 71, loss is    0.92.\n",
      "INFO:tensorflow:For batch 71, accuracy is    0.47.\n",
      "4608/7352 [=================>............] - ETA: 9s - loss: 1.2545 - accuracy: 0.4688INFO:tensorflow:For batch 72, loss is    0.99.\n",
      "INFO:tensorflow:For batch 72, accuracy is    0.47.\n",
      "4672/7352 [==================>...........] - ETA: 9s - loss: 1.2509 - accuracy: 0.4696INFO:tensorflow:For batch 73, loss is    1.01.\n",
      "INFO:tensorflow:For batch 73, accuracy is    0.47.\n",
      "4736/7352 [==================>...........] - ETA: 9s - loss: 1.2477 - accuracy: 0.4702INFO:tensorflow:For batch 74, loss is    0.95.\n",
      "INFO:tensorflow:For batch 74, accuracy is    0.47.\n",
      "4800/7352 [==================>...........] - ETA: 8s - loss: 1.2438 - accuracy: 0.4717INFO:tensorflow:For batch 75, loss is    1.25.\n",
      "INFO:tensorflow:For batch 75, accuracy is    0.47.\n",
      "4864/7352 [==================>...........] - ETA: 8s - loss: 1.2439 - accuracy: 0.4712INFO:tensorflow:For batch 76, loss is    1.08.\n",
      "INFO:tensorflow:For batch 76, accuracy is    0.47.\n",
      "4928/7352 [===================>..........] - ETA: 8s - loss: 1.2417 - accuracy: 0.4728INFO:tensorflow:For batch 77, loss is    1.10.\n",
      "INFO:tensorflow:For batch 77, accuracy is    0.47.\n",
      "4992/7352 [===================>..........] - ETA: 8s - loss: 1.2399 - accuracy: 0.4738INFO:tensorflow:For batch 78, loss is    1.02.\n",
      "INFO:tensorflow:For batch 78, accuracy is    0.48.\n",
      "5056/7352 [===================>..........] - ETA: 8s - loss: 1.2371 - accuracy: 0.4763INFO:tensorflow:For batch 79, loss is    0.98.\n",
      "INFO:tensorflow:For batch 79, accuracy is    0.48.\n",
      "5120/7352 [===================>..........] - ETA: 7s - loss: 1.2339 - accuracy: 0.4781INFO:tensorflow:For batch 80, loss is    0.98.\n",
      "INFO:tensorflow:For batch 80, accuracy is    0.48.\n",
      "5184/7352 [====================>.........] - ETA: 7s - loss: 1.2307 - accuracy: 0.4797INFO:tensorflow:For batch 81, loss is    1.04.\n",
      "INFO:tensorflow:For batch 81, accuracy is    0.48.\n",
      "5248/7352 [====================>.........] - ETA: 7s - loss: 1.2284 - accuracy: 0.4819INFO:tensorflow:For batch 82, loss is    1.07.\n",
      "INFO:tensorflow:For batch 82, accuracy is    0.48.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5312/7352 [====================>.........] - ETA: 7s - loss: 1.2265 - accuracy: 0.4825INFO:tensorflow:For batch 83, loss is    1.02.\n",
      "INFO:tensorflow:For batch 83, accuracy is    0.48.\n",
      "5376/7352 [====================>.........] - ETA: 6s - loss: 1.2241 - accuracy: 0.4846INFO:tensorflow:For batch 84, loss is    1.11.\n",
      "INFO:tensorflow:For batch 84, accuracy is    0.49.\n",
      "5440/7352 [=====================>........] - ETA: 6s - loss: 1.2227 - accuracy: 0.4853INFO:tensorflow:For batch 85, loss is    0.95.\n",
      "INFO:tensorflow:For batch 85, accuracy is    0.49.\n",
      "5504/7352 [=====================>........] - ETA: 6s - loss: 1.2195 - accuracy: 0.4866INFO:tensorflow:For batch 86, loss is    0.88.\n",
      "INFO:tensorflow:For batch 86, accuracy is    0.49.\n",
      "5568/7352 [=====================>........] - ETA: 6s - loss: 1.2156 - accuracy: 0.4880INFO:tensorflow:For batch 87, loss is    1.03.\n",
      "INFO:tensorflow:For batch 87, accuracy is    0.49.\n",
      "5632/7352 [=====================>........] - ETA: 5s - loss: 1.2135 - accuracy: 0.4893INFO:tensorflow:For batch 88, loss is    0.90.\n",
      "INFO:tensorflow:For batch 88, accuracy is    0.49.\n",
      "5696/7352 [======================>.......] - ETA: 5s - loss: 1.2099 - accuracy: 0.4900INFO:tensorflow:For batch 89, loss is    0.97.\n",
      "INFO:tensorflow:For batch 89, accuracy is    0.49.\n",
      "5760/7352 [======================>.......] - ETA: 5s - loss: 1.2072 - accuracy: 0.4910INFO:tensorflow:For batch 90, loss is    0.91.\n",
      "INFO:tensorflow:For batch 90, accuracy is    0.49.\n",
      "5824/7352 [======================>.......] - ETA: 5s - loss: 1.2040 - accuracy: 0.4921INFO:tensorflow:For batch 91, loss is    1.02.\n",
      "INFO:tensorflow:For batch 91, accuracy is    0.49.\n",
      "5888/7352 [=======================>......] - ETA: 5s - loss: 1.2020 - accuracy: 0.4924INFO:tensorflow:For batch 92, loss is    1.01.\n",
      "INFO:tensorflow:For batch 92, accuracy is    0.49.\n",
      "5952/7352 [=======================>......] - ETA: 4s - loss: 1.1999 - accuracy: 0.4919INFO:tensorflow:For batch 93, loss is    0.83.\n",
      "INFO:tensorflow:For batch 93, accuracy is    0.49.\n",
      "6016/7352 [=======================>......] - ETA: 4s - loss: 1.1960 - accuracy: 0.4938INFO:tensorflow:For batch 94, loss is    0.98.\n",
      "INFO:tensorflow:For batch 94, accuracy is    0.49.\n",
      "6080/7352 [=======================>......] - ETA: 4s - loss: 1.1938 - accuracy: 0.4946INFO:tensorflow:For batch 95, loss is    0.99.\n",
      "INFO:tensorflow:For batch 95, accuracy is    0.50.\n",
      "6144/7352 [========================>.....] - ETA: 4s - loss: 1.1917 - accuracy: 0.4956INFO:tensorflow:For batch 96, loss is    0.82.\n",
      "INFO:tensorflow:For batch 96, accuracy is    0.50.\n",
      "6208/7352 [========================>.....] - ETA: 3s - loss: 1.1878 - accuracy: 0.4969INFO:tensorflow:For batch 97, loss is    0.85.\n",
      "INFO:tensorflow:For batch 97, accuracy is    0.50.\n",
      "6272/7352 [========================>.....] - ETA: 3s - loss: 1.1844 - accuracy: 0.4984INFO:tensorflow:For batch 98, loss is    0.71.\n",
      "INFO:tensorflow:For batch 98, accuracy is    0.50.\n",
      "6336/7352 [========================>.....] - ETA: 3s - loss: 1.1796 - accuracy: 0.5014INFO:tensorflow:For batch 99, loss is    0.82.\n",
      "INFO:tensorflow:For batch 99, accuracy is    0.50.\n",
      "6400/7352 [=========================>....] - ETA: 3s - loss: 1.1760 - accuracy: 0.5039INFO:tensorflow:For batch 100, loss is    0.70.\n",
      "INFO:tensorflow:For batch 100, accuracy is    0.51.\n",
      "6464/7352 [=========================>....] - ETA: 2s - loss: 1.1713 - accuracy: 0.5062INFO:tensorflow:For batch 101, loss is    0.89.\n",
      "INFO:tensorflow:For batch 101, accuracy is    0.51.\n",
      "6528/7352 [=========================>....] - ETA: 2s - loss: 1.1685 - accuracy: 0.5067INFO:tensorflow:For batch 102, loss is    0.85.\n",
      "INFO:tensorflow:For batch 102, accuracy is    0.51.\n",
      "6592/7352 [=========================>....] - ETA: 2s - loss: 1.1655 - accuracy: 0.5080INFO:tensorflow:For batch 103, loss is    0.89.\n",
      "INFO:tensorflow:For batch 103, accuracy is    0.51.\n",
      "6656/7352 [==========================>...] - ETA: 2s - loss: 1.1628 - accuracy: 0.5081INFO:tensorflow:For batch 104, loss is    0.67.\n",
      "INFO:tensorflow:For batch 104, accuracy is    0.51.\n",
      "6720/7352 [==========================>...] - ETA: 2s - loss: 1.1581 - accuracy: 0.5097INFO:tensorflow:For batch 105, loss is    0.90.\n",
      "INFO:tensorflow:For batch 105, accuracy is    0.51.\n",
      "6784/7352 [==========================>...] - ETA: 1s - loss: 1.1557 - accuracy: 0.5115INFO:tensorflow:For batch 106, loss is    1.01.\n",
      "INFO:tensorflow:For batch 106, accuracy is    0.51.\n",
      "6848/7352 [==========================>...] - ETA: 1s - loss: 1.1543 - accuracy: 0.5120INFO:tensorflow:For batch 107, loss is    0.73.\n",
      "INFO:tensorflow:For batch 107, accuracy is    0.51.\n",
      "6912/7352 [===========================>..] - ETA: 1s - loss: 1.1504 - accuracy: 0.5136INFO:tensorflow:For batch 108, loss is    0.78.\n",
      "INFO:tensorflow:For batch 108, accuracy is    0.52.\n",
      "6976/7352 [===========================>..] - ETA: 1s - loss: 1.1470 - accuracy: 0.5153INFO:tensorflow:For batch 109, loss is    0.73.\n",
      "INFO:tensorflow:For batch 109, accuracy is    0.52.\n",
      "7040/7352 [===========================>..] - ETA: 1s - loss: 1.1432 - accuracy: 0.5172INFO:tensorflow:For batch 110, loss is    1.03.\n",
      "INFO:tensorflow:For batch 110, accuracy is    0.52.\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 1.1421 - accuracy: 0.5183INFO:tensorflow:For batch 111, loss is    0.97.\n",
      "INFO:tensorflow:For batch 111, accuracy is    0.52.\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 1.1406 - accuracy: 0.5190INFO:tensorflow:For batch 112, loss is    0.83.\n",
      "INFO:tensorflow:For batch 112, accuracy is    0.52.\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 1.1379 - accuracy: 0.5203INFO:tensorflow:For batch 113, loss is    0.81.\n",
      "INFO:tensorflow:For batch 113, accuracy is    0.52.\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 1.1350 - accuracy: 0.5215INFO:tensorflow:For batch 114, loss is    0.79.\n",
      "INFO:tensorflow:For batch 114, accuracy is    0.52.\n",
      "INFO:tensorflow:weights of 1 layers for epoch0 is [array([[-0.00493747,  0.0526592 , -0.04366444, ..., -0.10303303,\n",
      "        -0.074174  , -0.1088144 ],\n",
      "       [-0.01697703, -0.08703741,  0.03761723, ...,  0.02197293,\n",
      "        -0.01536969,  0.05659256],\n",
      "       [ 0.02019197,  0.08921489, -0.02535874, ..., -0.09232441,\n",
      "        -0.06635777, -0.01036749],\n",
      "       ...,\n",
      "       [-0.03158607, -0.02639531, -0.06673604, ..., -0.0690475 ,\n",
      "        -0.1496907 ,  0.0261866 ],\n",
      "       [ 0.03506248,  0.00641701,  0.06042431, ..., -0.08243423,\n",
      "         0.16145572,  0.00518919],\n",
      "       [-0.11191797,  0.0816319 , -0.08251616, ..., -0.1516758 ,\n",
      "         0.11698665, -0.11333031]], dtype=float32), array([[-0.03189622,  0.06014793, -0.01391965, ..., -0.13027972,\n",
      "        -0.06922802, -0.05749119],\n",
      "       [-0.12854974,  0.10700748, -0.03631712, ...,  0.12139547,\n",
      "         0.01225116,  0.06390234],\n",
      "       [ 0.05659172, -0.05824633, -0.02321301, ..., -0.03675821,\n",
      "        -0.06055963, -0.03278158],\n",
      "       ...,\n",
      "       [-0.01648064,  0.06331718, -0.0376016 , ...,  0.04783898,\n",
      "         0.04986556,  0.05511827],\n",
      "       [ 0.06479775,  0.03334939,  0.02388664, ...,  0.00404798,\n",
      "        -0.03557154,  0.02821221],\n",
      "       [-0.05226963, -0.03629197,  0.05273991, ..., -0.09496316,\n",
      "         0.03166974, -0.0783139 ]], dtype=float32), array([-4.76248888e-03,  9.54843126e-03,  2.43801288e-02,  1.11016789e-02,\n",
      "        2.42312923e-02,  5.09886211e-03, -2.03676652e-02,  1.50188748e-02,\n",
      "       -1.72356737e-03,  8.07941984e-03,  1.73888020e-02,  3.00603304e-02,\n",
      "        2.08354858e-03, -1.88650507e-02,  5.20977192e-03, -1.42387534e-03,\n",
      "        1.58519670e-02,  1.59100965e-02,  2.29211282e-02,  2.18764022e-02,\n",
      "        1.52936950e-02,  1.76599510e-02,  1.55142341e-02,  1.62239112e-02,\n",
      "        1.27837323e-02, -6.42604486e-04,  7.15228124e-03,  2.32722219e-02,\n",
      "        1.47719802e-02,  3.76571715e-02,  1.09180370e-02,  1.57199544e-03,\n",
      "       -3.05543747e-03,  2.03385446e-02,  1.17655778e-02, -1.52162183e-03,\n",
      "        1.56326704e-02,  4.76967311e-04,  1.93514302e-02,  2.23679524e-02,\n",
      "        8.96126870e-03,  2.43683476e-02,  1.11280680e-02,  2.42860653e-02,\n",
      "        2.14788169e-02,  7.49390433e-03,  1.30453520e-02,  2.16531362e-02,\n",
      "       -2.67881844e-02,  1.11749228e-02,  2.66341660e-02,  1.93867348e-02,\n",
      "        1.28807994e-02,  2.47692410e-02,  2.06407197e-02,  1.21616684e-02,\n",
      "        1.72116831e-02,  7.87669141e-03,  5.72227547e-03,  1.00217611e-02,\n",
      "       -6.53464161e-03,  1.57844753e-03, -1.07886633e-02,  2.06439495e-02,\n",
      "        8.26089550e-03,  9.75640398e-03,  1.48430904e-02,  2.24025175e-02,\n",
      "        2.02958751e-02,  8.17796402e-03,  1.48146981e-02,  2.40551084e-02,\n",
      "        7.75177544e-03,  7.13619078e-03,  1.33610601e-02, -2.09917873e-03,\n",
      "        9.55688953e-03,  1.06797311e-02,  5.25035290e-03,  1.04672993e-02,\n",
      "       -5.88977290e-03,  1.91060863e-02,  1.55630484e-02,  7.57387327e-03,\n",
      "       -4.56507411e-03,  3.08291726e-02,  3.71485110e-03,  1.85817853e-02,\n",
      "        6.93346746e-03,  4.59462916e-03, -1.41224742e-03,  2.35773660e-02,\n",
      "        1.83787402e-02,  2.06124783e-02,  3.01842019e-02,  3.48184630e-02,\n",
      "        1.19579700e-03,  5.41486265e-03, -8.60742002e-04, -1.23567376e-02,\n",
      "        9.91263628e-01,  1.01301062e+00,  1.02762938e+00,  1.01295078e+00,\n",
      "        1.02660978e+00,  1.00545728e+00,  9.80539203e-01,  1.01600814e+00,\n",
      "        1.00127816e+00,  1.00754130e+00,  1.01578462e+00,  1.03108752e+00,\n",
      "        9.99292195e-01,  9.84885037e-01,  1.00949693e+00,  9.98755693e-01,\n",
      "        1.01690745e+00,  1.02485895e+00,  1.02109826e+00,  1.02289963e+00,\n",
      "        1.01628506e+00,  1.01887739e+00,  1.01284671e+00,  1.01538110e+00,\n",
      "        1.01384950e+00,  1.00016010e+00,  1.00995064e+00,  1.02437747e+00,\n",
      "        1.01523089e+00,  1.03671789e+00,  1.01358283e+00,  1.01003754e+00,\n",
      "        9.97556090e-01,  1.01891577e+00,  1.01625288e+00,  9.98844504e-01,\n",
      "        1.01605844e+00,  1.00039959e+00,  1.03046703e+00,  1.02276313e+00,\n",
      "        1.01053262e+00,  1.03756928e+00,  1.01363885e+00,  1.03254902e+00,\n",
      "        1.02398646e+00,  1.00881219e+00,  1.01809883e+00,  1.02296579e+00,\n",
      "        9.74862993e-01,  1.01196015e+00,  1.02880347e+00,  1.02053702e+00,\n",
      "        1.01583159e+00,  1.02723861e+00,  1.02065003e+00,  1.01129007e+00,\n",
      "        1.01823521e+00,  1.00937116e+00,  1.00830376e+00,  1.01114964e+00,\n",
      "        9.91479278e-01,  1.00986981e+00,  9.91118133e-01,  1.02255452e+00,\n",
      "        1.01093030e+00,  1.01483989e+00,  1.01452565e+00,  1.01806521e+00,\n",
      "        1.01941180e+00,  1.00925839e+00,  1.01555562e+00,  1.02631187e+00,\n",
      "        1.01211071e+00,  1.00856042e+00,  1.01228988e+00,  1.00133646e+00,\n",
      "        1.00893593e+00,  1.01037216e+00,  1.00024152e+00,  1.01145864e+00,\n",
      "        1.00103056e+00,  1.02075219e+00,  1.01629496e+00,  1.00805664e+00,\n",
      "        9.98099267e-01,  1.02825773e+00,  1.00412190e+00,  1.01872349e+00,\n",
      "        1.00834584e+00,  1.00304139e+00,  9.95786786e-01,  1.02247679e+00,\n",
      "        1.01947474e+00,  1.02347696e+00,  1.02971852e+00,  1.03835452e+00,\n",
      "        9.98684287e-01,  1.00947797e+00,  1.00476551e+00,  9.87940907e-01,\n",
      "       -9.05130524e-03,  3.14878271e-04,  1.20679289e-02, -3.31173837e-03,\n",
      "       -1.25620198e-02, -2.05743015e-02,  2.02071555e-02, -2.97159213e-03,\n",
      "       -6.16602367e-03,  8.00791010e-03, -1.72767397e-02, -1.53392646e-03,\n",
      "       -1.17194122e-02, -2.43166680e-04,  2.56661722e-03,  1.14753805e-02,\n",
      "        1.68003291e-02, -2.24459358e-03,  8.03903770e-03, -2.26104483e-02,\n",
      "       -1.07848383e-02, -1.48782264e-02, -4.02584765e-03,  1.91812520e-03,\n",
      "       -1.20042637e-02, -1.78446192e-02, -1.05469739e-02,  3.21607143e-02,\n",
      "       -1.69595629e-02,  1.32060992e-02, -1.09312590e-02,  1.66539452e-03,\n",
      "       -4.74105589e-03, -1.14436094e-02,  4.52751759e-03,  9.50087700e-03,\n",
      "       -1.44157000e-02, -1.42821250e-02, -1.02387406e-02,  6.12907857e-03,\n",
      "       -8.85021966e-03,  7.29412714e-04,  9.51343868e-03, -2.02073976e-02,\n",
      "        6.69410871e-03, -5.73148392e-03, -1.20518301e-02,  1.14071313e-02,\n",
      "       -1.88319199e-02,  9.94819216e-03,  1.04209343e-02, -5.84956957e-03,\n",
      "        1.66292186e-03, -7.45884376e-03, -1.64851081e-02,  2.57912464e-03,\n",
      "       -1.72850713e-02,  1.16849570e-02,  5.77135105e-03,  4.21281392e-03,\n",
      "       -1.89263541e-02, -3.07412911e-03, -7.68282544e-03, -1.15870601e-02,\n",
      "       -1.13620786e-02,  4.49393550e-03,  6.14206679e-03, -1.95336286e-02,\n",
      "       -1.58352498e-02, -1.28059285e-02, -2.15386245e-02, -1.56405335e-03,\n",
      "       -1.72848403e-02, -1.59410406e-02,  1.59223452e-02, -4.02186299e-03,\n",
      "       -1.93922948e-02, -2.27896171e-03, -9.50400427e-04, -3.31568159e-03,\n",
      "       -5.47123887e-03,  1.21066894e-03, -8.17397796e-03,  3.24269733e-03,\n",
      "        2.41698977e-03, -6.92954240e-03, -1.47655495e-02,  1.16041470e-02,\n",
      "       -1.07426904e-02,  1.70946587e-02,  1.18570880e-03, -1.94603927e-04,\n",
      "        3.78360832e-03,  1.03236660e-02,  5.83208725e-03, -7.03996141e-03,\n",
      "        1.97594091e-02,  1.32481884e-02,  2.27286876e-03, -1.33334449e-03,\n",
      "       -3.61289131e-03,  1.83962677e-02,  1.80150606e-02,  9.42606106e-03,\n",
      "        2.78293155e-02,  3.17360135e-03, -1.92902479e-02,  1.57661196e-02,\n",
      "       -5.90663822e-03,  1.31742423e-02,  1.80673245e-02,  3.18615511e-02,\n",
      "        2.37237895e-03, -1.47241410e-02,  1.92800313e-02, -2.02242658e-03,\n",
      "        1.79149471e-02,  2.42744163e-02,  2.11204942e-02,  2.57281587e-02,\n",
      "        1.47331124e-02,  1.83394477e-02,  1.60338655e-02,  1.70144159e-02,\n",
      "        1.30821280e-02,  1.22282666e-03,  8.30493961e-03,  2.63241678e-02,\n",
      "        1.66751910e-02,  3.51886265e-02,  1.42109860e-02,  7.65643036e-03,\n",
      "       -2.05306150e-03,  2.51619201e-02,  1.13308579e-02, -3.14745167e-03,\n",
      "        1.74090862e-02,  1.88155693e-03,  3.44838835e-02,  2.40685474e-02,\n",
      "        1.23062739e-02,  2.66101919e-02,  7.62865273e-03,  1.89259890e-02,\n",
      "        2.36912146e-02,  5.69671812e-03,  1.21171409e-02,  1.92272644e-02,\n",
      "       -2.40948219e-02,  1.73363574e-02,  2.48672329e-02,  2.17944868e-02,\n",
      "        1.64103489e-02,  2.81206705e-02,  2.20539309e-02,  1.52911935e-02,\n",
      "        2.47888248e-02,  9.31658782e-03,  7.93876033e-03,  1.02480995e-02,\n",
      "       -6.02086540e-03,  1.50179937e-02, -1.11059826e-02,  2.00241823e-02,\n",
      "        7.75266858e-03,  1.98715609e-02,  1.59646831e-02,  2.21470129e-02,\n",
      "        1.93871539e-02,  1.04517220e-02,  1.78021360e-02,  2.91348193e-02,\n",
      "        9.02595837e-03,  9.11383703e-03,  1.73830986e-02,  1.27856631e-03,\n",
      "        1.01125045e-02,  8.03113636e-03,  1.57907652e-03,  1.71202403e-02,\n",
      "       -4.45473846e-03,  1.84182171e-02,  1.89312771e-02,  2.48287572e-04,\n",
      "       -3.50728689e-04,  3.40665840e-02,  7.31869228e-03,  1.96656082e-02,\n",
      "        9.47822537e-03,  6.09354628e-03, -2.02330970e-03,  2.35982016e-02,\n",
      "        1.90637615e-02,  2.09439266e-02,  3.50894481e-02,  4.48194221e-02,\n",
      "        5.73622528e-04,  6.80111349e-03,  5.75398328e-03, -1.37870321e-02],\n",
      "      dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:weights of 2 layers for epoch0 is []\n",
      "INFO:tensorflow:weights of 3 layers for epoch0 is [array([[-0.02672616,  0.14621186,  0.05128063, ..., -0.10931678,\n",
      "         0.04192034,  0.03566625],\n",
      "       [-0.04017503, -0.16816749, -0.08515023, ...,  0.082712  ,\n",
      "        -0.17125043,  0.09562171],\n",
      "       [ 0.05237131,  0.17473064, -0.03619789, ...,  0.12029404,\n",
      "         0.15826368, -0.05491549],\n",
      "       ...,\n",
      "       [ 0.13180546,  0.06070846, -0.22198531, ..., -0.11049569,\n",
      "         0.05071298,  0.12191661],\n",
      "       [ 0.0365625 ,  0.05445123, -0.15149467, ..., -0.13128184,\n",
      "         0.11104594, -0.00207009],\n",
      "       [ 0.13779852,  0.18599337, -0.06132601, ...,  0.04542718,\n",
      "        -0.10317281,  0.07537553]], dtype=float32), array([ 6.08346472e-03,  1.28350351e-02,  1.81909148e-02,  4.34350967e-02,\n",
      "        1.26857515e-02,  2.07579918e-02, -2.65386095e-03, -2.96354922e-03,\n",
      "       -1.32720433e-02,  2.31985319e-02,  4.20463905e-02,  3.05860769e-02,\n",
      "        4.61909594e-03,  2.36460473e-02,  2.80878618e-02, -3.74992867e-03,\n",
      "        7.29229720e-03, -1.48307020e-03,  4.13193330e-02,  1.39888898e-02,\n",
      "        1.99471619e-02,  2.64949165e-02,  2.18450483e-02,  1.28364353e-03,\n",
      "        1.13856299e-02,  4.33943719e-02,  1.53737236e-02,  2.88845673e-02,\n",
      "        2.03215703e-02, -9.15433094e-03,  2.33570766e-02, -1.69101637e-02,\n",
      "        2.16232035e-02,  3.23518552e-02,  1.78459547e-02, -2.38320120e-02,\n",
      "        2.86127208e-03,  1.91820934e-02,  3.37101221e-02,  1.35195274e-02,\n",
      "        3.44496779e-03,  4.81034406e-02,  1.82052795e-02,  8.90742987e-03,\n",
      "        3.37837040e-02, -7.99144339e-03,  4.71694395e-02, -8.35435698e-04,\n",
      "       -1.15230223e-02,  4.16213507e-03, -7.76442175e-05,  3.15995701e-02,\n",
      "       -1.69712852e-03, -2.47228984e-03,  3.18459310e-02,  5.74075012e-03,\n",
      "        3.00390478e-02, -3.91450431e-03,  3.28866653e-02, -2.01170496e-03,\n",
      "       -1.09107476e-02, -3.69925611e-03, -5.74163627e-04,  3.81923392e-02,\n",
      "       -1.47137267e-03,  2.15904582e-02,  2.76170168e-02, -7.04020122e-03,\n",
      "        3.04795365e-04,  1.96081754e-02,  4.37754067e-03,  5.41067682e-03,\n",
      "        2.03354135e-02, -4.01320681e-02,  1.85654182e-02,  3.03576980e-02,\n",
      "        1.04037765e-02,  1.90789513e-02, -1.65457204e-02, -1.51125761e-03,\n",
      "       -6.09780196e-04,  1.28012942e-02,  1.60187352e-02,  2.63619721e-02,\n",
      "        2.47516092e-02, -1.76015019e-03,  1.41283851e-02, -4.52862633e-03,\n",
      "        2.70263162e-02, -4.70598135e-03, -1.14219105e-02,  2.77897678e-02,\n",
      "        2.14513876e-02,  1.17853060e-02, -5.19097550e-03, -4.56337864e-03,\n",
      "        1.82163366e-03,  8.57274141e-03,  2.00056713e-02, -3.00242519e-03],\n",
      "      dtype=float32)]\n",
      "INFO:tensorflow:weights of 4 layers for epoch0 is [array([[ 3.58777470e-03,  9.14400294e-02,  1.78851962e-01,\n",
      "        -6.26067072e-02,  1.37673942e-02, -9.34577435e-02],\n",
      "       [-1.84579283e-01, -1.32905051e-01, -4.74390760e-02,\n",
      "        -3.46017107e-02,  3.40777822e-02,  1.51357085e-01],\n",
      "       [ 1.35816053e-01,  9.82459337e-02,  1.60550311e-01,\n",
      "         1.31294936e-01,  1.86515644e-01, -1.25149041e-01],\n",
      "       [ 2.65145153e-01, -5.98375034e-03, -4.63707708e-02,\n",
      "        -2.22442597e-01,  2.41094120e-02, -2.48887241e-01],\n",
      "       [-8.82010087e-02,  1.13660820e-01, -2.16924965e-01,\n",
      "         1.32395089e-01, -1.30000532e-01,  2.36914605e-01],\n",
      "       [-8.21918845e-02,  1.03971630e-01,  1.38203457e-01,\n",
      "        -1.21665813e-01, -1.69437572e-01, -2.80034751e-01],\n",
      "       [ 6.74356967e-02,  5.74142560e-02, -7.74288177e-02,\n",
      "        -1.65729329e-01,  1.12336308e-01,  7.18580186e-02],\n",
      "       [-2.05139801e-01,  1.53534198e-02,  2.20336139e-01,\n",
      "        -1.56045794e-01, -2.10427344e-02,  8.61745030e-02],\n",
      "       [-7.78938010e-02, -1.17008656e-01,  2.05968603e-01,\n",
      "         4.05934304e-02, -4.05047610e-02, -2.11083651e-01],\n",
      "       [-1.61223665e-01,  1.90267712e-01,  4.85951081e-02,\n",
      "         8.93154666e-02,  5.48135377e-02,  2.31488883e-01],\n",
      "       [ 1.78499356e-01,  9.25406143e-02,  2.25685447e-01,\n",
      "        -7.40025938e-02,  1.26035631e-01,  8.87399912e-02],\n",
      "       [ 4.16774116e-02, -4.54231538e-02,  8.82589966e-02,\n",
      "        -2.68133402e-01, -2.06468642e-01, -2.69999444e-01],\n",
      "       [ 1.31582618e-01, -1.78432763e-01, -2.63471995e-02,\n",
      "        -1.02517731e-01, -8.10264423e-02,  2.05771506e-01],\n",
      "       [-2.01266646e-01, -1.97448850e-01, -1.24734743e-02,\n",
      "        -5.78030087e-02, -1.88408270e-01,  1.83622628e-01],\n",
      "       [ 1.83505878e-01, -1.11200102e-01,  2.05241114e-01,\n",
      "        -2.46803254e-01, -2.18062669e-01, -2.76551276e-01],\n",
      "       [-2.20535323e-01, -8.17515031e-02,  1.37185594e-02,\n",
      "         2.08591834e-01,  1.36414230e-01,  1.03147782e-01],\n",
      "       [-1.60124511e-01, -5.36894798e-02,  1.91285193e-01,\n",
      "         7.06350505e-02,  1.41299635e-01, -1.00475252e-02],\n",
      "       [ 8.40650052e-02,  1.33285195e-01, -7.63373449e-02,\n",
      "         1.82809204e-01, -7.45969489e-02, -2.11018845e-01],\n",
      "       [ 3.05856336e-02, -1.30958900e-01,  5.33649996e-02,\n",
      "        -7.84732103e-02, -3.25091705e-02, -2.81448781e-01],\n",
      "       [ 3.04860249e-02,  1.01738371e-01,  2.30198167e-02,\n",
      "        -4.16349582e-02,  2.38629475e-01, -2.19716698e-01],\n",
      "       [-1.57024533e-01,  6.69416934e-02, -7.54845142e-03,\n",
      "         1.25032634e-01, -1.99812666e-01,  1.12707980e-01],\n",
      "       [ 1.43888488e-01,  1.32603869e-01, -1.93896323e-01,\n",
      "        -2.79385168e-02,  9.75529179e-02, -2.32726574e-01],\n",
      "       [-1.53563842e-01, -1.83624357e-01, -1.14202119e-01,\n",
      "         5.92342988e-02, -2.71763876e-02, -1.89742729e-01],\n",
      "       [ 7.70633221e-02, -2.07406208e-01, -2.24425539e-01,\n",
      "         9.06500220e-02, -1.75702140e-01, -2.12031916e-01],\n",
      "       [-5.16750291e-02, -4.40352932e-02, -1.57094613e-01,\n",
      "         2.52811126e-02,  1.56844296e-02,  1.84547752e-02],\n",
      "       [ 1.86679780e-01, -6.20402470e-02,  1.91726685e-01,\n",
      "        -1.43685015e-02,  1.36522129e-01, -2.15800032e-01],\n",
      "       [ 1.26726672e-01, -7.24162236e-02, -2.34332323e-01,\n",
      "        -1.40571207e-01, -2.07468960e-02,  1.08864799e-01],\n",
      "       [ 2.99603883e-02,  1.00347087e-01,  1.93169042e-01,\n",
      "        -6.64729029e-02, -5.52504398e-02,  1.28269032e-01],\n",
      "       [-2.51591474e-01, -1.91329494e-01, -1.67703941e-01,\n",
      "        -1.09276146e-01,  5.16227633e-02,  7.25960359e-02],\n",
      "       [-9.58081484e-02,  1.39429659e-01,  1.16443112e-01,\n",
      "         8.40454325e-02,  2.13764697e-01, -2.79355403e-02],\n",
      "       [-4.91979234e-02,  1.53209418e-01, -1.67222962e-01,\n",
      "        -1.11505039e-01, -9.71544832e-02,  1.62580729e-01],\n",
      "       [-2.17828184e-01,  5.84706739e-02,  1.40694231e-01,\n",
      "         8.52148011e-02, -2.21371785e-01,  4.31679077e-02],\n",
      "       [-1.91765442e-01, -1.41673848e-01,  7.98029304e-02,\n",
      "         1.13251120e-01, -2.37397656e-01,  1.25079742e-02],\n",
      "       [-9.41440463e-02,  1.16492450e-01, -1.88547581e-01,\n",
      "         1.84074700e-01, -2.72991478e-01,  2.35346809e-01],\n",
      "       [ 1.27458721e-01, -1.22659504e-01,  4.19468246e-02,\n",
      "        -1.26427785e-01, -1.41628265e-01,  2.08341315e-01],\n",
      "       [-2.85100453e-02,  1.37199700e-01, -1.23815104e-01,\n",
      "         1.44483715e-01, -1.18498370e-01, -1.13848485e-01],\n",
      "       [ 1.70670822e-01,  9.91610661e-02, -1.94481015e-01,\n",
      "         1.53972372e-01, -2.43722320e-01,  1.42845139e-01],\n",
      "       [ 2.22253397e-01,  1.56894743e-01,  6.32468835e-02,\n",
      "        -3.04978102e-01, -8.56233016e-02, -1.35079041e-01],\n",
      "       [ 1.19929232e-01, -1.95320114e-01, -2.73641557e-01,\n",
      "         1.86359569e-01, -2.28112668e-01,  2.17383683e-01],\n",
      "       [ 1.00076282e-02, -9.95833576e-02,  1.51575357e-02,\n",
      "         2.20171064e-01, -4.61666621e-02,  6.12781681e-02],\n",
      "       [-1.74140081e-01, -4.00099233e-02, -1.76826030e-01,\n",
      "         2.02416688e-01,  2.43429869e-01, -1.74559325e-01],\n",
      "       [-2.44845450e-02, -3.15407842e-01, -1.41138002e-01,\n",
      "         1.53855622e-01,  2.99604870e-02,  1.80374403e-02],\n",
      "       [ 1.48848388e-02,  1.42778322e-01, -1.80205151e-01,\n",
      "        -1.99971974e-01,  7.50731081e-02,  3.58209908e-02],\n",
      "       [-2.61017323e-01, -1.45418718e-01, -2.72661388e-01,\n",
      "         2.15958431e-01, -2.07190722e-01, -1.17772363e-01],\n",
      "       [-1.42077461e-01, -2.41966948e-01, -2.66633272e-01,\n",
      "         7.03592002e-02,  8.89469981e-02, -2.60105312e-01],\n",
      "       [-4.07958925e-02,  2.24894211e-01,  1.66952670e-01,\n",
      "         1.37441367e-01,  1.57443583e-01, -1.09351814e-01],\n",
      "       [ 1.08090498e-01, -1.89316243e-01, -2.21363641e-02,\n",
      "         5.81409149e-02,  1.17313251e-01, -5.44794314e-02],\n",
      "       [ 2.22600281e-01,  1.62787914e-01,  9.03464016e-03,\n",
      "        -2.10338775e-02, -9.92354453e-02,  1.56251356e-01],\n",
      "       [ 6.22256938e-03,  2.35023707e-01, -8.48224908e-02,\n",
      "         8.20696503e-02, -2.30152503e-01, -1.13055594e-01],\n",
      "       [ 1.58525482e-01,  1.05329454e-01, -1.43996030e-01,\n",
      "         1.65255502e-01,  1.51465997e-01, -3.36449929e-02],\n",
      "       [-1.22473128e-01, -1.43901818e-02, -1.39698863e-01,\n",
      "        -1.85681477e-01,  1.89884782e-01,  1.49180174e-01],\n",
      "       [-6.84582517e-02,  1.46822166e-02, -1.95114449e-01,\n",
      "         1.15707591e-01, -9.25823972e-02,  2.49655440e-01],\n",
      "       [-1.11796632e-01,  8.94706696e-02, -1.52073115e-01,\n",
      "         1.61009967e-01, -2.39161849e-01,  4.55140360e-02],\n",
      "       [-1.15386965e-02, -4.74882312e-02, -1.71788543e-01,\n",
      "         5.32752573e-02,  9.18538049e-02,  6.74745515e-02],\n",
      "       [ 6.82589412e-02, -2.96601690e-02,  1.48461238e-01,\n",
      "        -1.32394940e-01, -1.50949406e-02, -1.65918142e-01],\n",
      "       [ 1.52361542e-01, -1.54677838e-01,  2.47199744e-01,\n",
      "         1.37974560e-01, -2.04021081e-01, -2.81724751e-01],\n",
      "       [-4.37827110e-02, -2.40937188e-01, -4.60319668e-02,\n",
      "         1.25979811e-01, -1.55397460e-01,  2.37366900e-01],\n",
      "       [ 1.61314845e-01, -6.10255748e-02, -1.97073091e-02,\n",
      "         4.34478186e-02, -5.26305735e-02,  5.95143437e-02],\n",
      "       [-8.58322755e-02, -6.22536913e-02, -2.42347047e-01,\n",
      "         5.89843653e-02,  6.04040548e-02,  5.28670922e-02],\n",
      "       [-1.27215797e-04,  1.82911754e-01,  1.59229741e-01,\n",
      "        -8.08250085e-02, -9.36965123e-02, -1.72328979e-01],\n",
      "       [-2.19903499e-01,  8.14767927e-02,  3.30951326e-02,\n",
      "         1.29541576e-01,  2.99271895e-03, -1.15170501e-01],\n",
      "       [ 6.16907217e-02, -1.86020076e-01,  5.09234183e-02,\n",
      "         1.40123323e-01, -2.22390175e-01,  2.00589001e-01],\n",
      "       [ 9.71313566e-03, -1.91060185e-01, -2.26674214e-01,\n",
      "        -1.44443706e-01, -1.69052035e-01,  3.23633216e-02],\n",
      "       [ 1.05505988e-01,  2.27805018e-01,  2.22403303e-01,\n",
      "        -2.85975635e-01,  1.83988176e-02, -1.88009351e-01],\n",
      "       [ 7.83543065e-02, -3.62281315e-02, -7.39050508e-02,\n",
      "         6.76729009e-02, -1.53396636e-01,  2.37478971e-01],\n",
      "       [-1.89514652e-01, -5.83905354e-02,  4.73945104e-02,\n",
      "         1.23734318e-01, -1.59118816e-01,  2.09225982e-01],\n",
      "       [-7.39691108e-02,  1.09007731e-01,  1.75546616e-01,\n",
      "        -7.00581744e-02,  4.00393121e-02, -2.28498280e-01],\n",
      "       [-6.54295203e-04,  3.66310254e-02,  4.82523665e-02,\n",
      "         3.41870100e-03,  2.18526591e-02,  1.42109320e-01],\n",
      "       [ 1.84079975e-01, -1.64035112e-01,  5.75346425e-02,\n",
      "         2.97564790e-02,  2.26505369e-01,  5.95247298e-02],\n",
      "       [-1.65478945e-01, -9.12530869e-02,  1.75194651e-01,\n",
      "         1.70888066e-01,  2.41708457e-01, -4.28764001e-02],\n",
      "       [ 1.52041733e-01, -1.14974447e-01,  8.93200934e-02,\n",
      "        -1.82045311e-01, -1.26346260e-01,  1.85684383e-01],\n",
      "       [-1.70656204e-01, -1.91855848e-01,  7.74054602e-03,\n",
      "        -2.26714462e-01, -5.11997268e-02,  2.07046717e-01],\n",
      "       [-3.15605700e-02,  2.48993993e-01,  8.69404823e-02,\n",
      "        -1.79481342e-01, -1.08854719e-01,  6.43315464e-02],\n",
      "       [-1.61501184e-01,  1.75241858e-01, -5.91464862e-02,\n",
      "         7.53892735e-02,  3.33496369e-03, -3.49525884e-02],\n",
      "       [-1.36895373e-01, -9.71319005e-02, -1.34148598e-01,\n",
      "        -4.95828949e-02,  4.71448712e-02,  1.13244914e-01],\n",
      "       [-2.67969761e-02, -2.47517332e-01,  3.19412500e-02,\n",
      "         2.01118127e-01,  2.31457219e-01, -1.86041608e-01],\n",
      "       [-1.63861305e-01, -1.18215764e-02,  5.64550795e-02,\n",
      "        -1.68897748e-01,  2.39401549e-01, -1.98626205e-01],\n",
      "       [-1.78016856e-01,  3.15072834e-02,  4.31577414e-02,\n",
      "        -1.99021086e-01, -2.14903384e-01, -9.54311565e-02],\n",
      "       [ 1.33359924e-01,  1.38857558e-01, -1.35876372e-01,\n",
      "        -3.26652676e-02, -1.14907041e-01, -2.09413752e-01],\n",
      "       [-1.05072677e-01,  1.51220039e-01, -4.72483449e-02,\n",
      "         2.51147281e-02,  2.05997035e-01, -1.43709868e-01],\n",
      "       [-1.53672636e-01,  2.56214831e-02, -2.38067672e-01,\n",
      "        -1.41497284e-01,  9.01954323e-02,  9.14270580e-02],\n",
      "       [ 1.78654537e-01,  3.25558111e-02, -1.38735035e-02,\n",
      "         1.84062749e-01, -2.27454111e-01,  1.12303264e-01],\n",
      "       [-1.26749858e-01,  2.19318479e-01,  1.73053835e-02,\n",
      "         6.60079271e-02, -2.38870308e-01,  2.19040111e-01],\n",
      "       [ 6.33912385e-02,  2.60252446e-01, -1.66009158e-01,\n",
      "        -2.60972798e-01, -1.71484500e-01, -1.30031168e-01],\n",
      "       [-6.44835411e-03,  1.37809128e-01,  1.13296688e-01,\n",
      "        -2.46437639e-01, -5.95243536e-02,  3.42495702e-02],\n",
      "       [ 2.46204194e-02,  1.38620511e-01, -2.26454511e-01,\n",
      "         1.30160481e-01, -1.61911845e-02, -2.59968668e-01],\n",
      "       [ 1.08427174e-01,  5.31838462e-02, -9.04000998e-02,\n",
      "         2.34846428e-01, -1.30467519e-01,  2.18962818e-01],\n",
      "       [-1.94582894e-01,  1.84272781e-01,  1.31561346e-02,\n",
      "        -1.57622337e-01, -2.53546745e-01,  2.54614512e-03],\n",
      "       [ 2.40419269e-01, -1.57880843e-01, -6.10487610e-02,\n",
      "         1.72433957e-01,  1.81443796e-01, -2.93555617e-01],\n",
      "       [-6.98709190e-02, -1.88386083e-01,  4.48063314e-02,\n",
      "        -1.23417549e-01, -2.68657468e-02,  2.21297413e-01],\n",
      "       [-2.19689473e-03,  1.00305721e-01, -1.57225013e-01,\n",
      "         1.41957626e-01, -1.42036885e-01, -2.09961861e-01],\n",
      "       [-1.49092630e-01, -2.65127450e-01, -8.94512683e-02,\n",
      "        -1.60112437e-02,  1.91186428e-01, -1.78244218e-01],\n",
      "       [ 1.75275818e-01,  1.67600755e-02, -2.21274540e-01,\n",
      "        -2.52680749e-01,  1.91367939e-01, -1.08945027e-01],\n",
      "       [-2.17230376e-02, -3.04695237e-02, -1.54485703e-01,\n",
      "        -1.94919601e-01, -1.85225576e-01,  1.15027189e-01],\n",
      "       [-1.46872208e-01,  9.55998003e-02,  1.75570607e-01,\n",
      "        -1.05108686e-01, -7.83825517e-02, -2.50601042e-02],\n",
      "       [ 4.92056943e-02, -2.70239692e-02, -8.78308117e-02,\n",
      "        -1.62707970e-01, -2.30107084e-01,  2.28136435e-01],\n",
      "       [-2.22995412e-02, -1.64795741e-01, -1.06535085e-01,\n",
      "         4.95661199e-02, -1.46678492e-01, -2.79658228e-01],\n",
      "       [ 8.34050328e-02,  2.02623636e-01, -2.17459481e-02,\n",
      "         1.57632738e-01,  1.77155271e-01, -2.49847695e-02],\n",
      "       [ 1.41330078e-01,  2.15423778e-02,  9.50147770e-03,\n",
      "        -1.19081466e-02, -2.68064532e-03,  2.29882494e-01],\n",
      "       [ 1.63395837e-01,  3.62369837e-03, -3.55155095e-02,\n",
      "         4.32252362e-02, -1.30922332e-01,  8.86441544e-02]], dtype=float32), array([ 0.00620439, -0.01945898,  0.0019549 , -0.01229595,  0.01231307,\n",
      "        0.0028489 ], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The average loss for epoch 0 is    1.13 and accuracy is    0.52.\n",
      "7352/7352 [==============================] - 24s 3ms/sample - loss: 1.1324 - accuracy: 0.5227\n",
      "Epoch 2/5\n",
      "INFO:tensorflow:For batch 0, loss is    0.80.\n",
      "INFO:tensorflow:For batch 0, accuracy is    0.59.\n",
      "  64/7352 [..............................] - ETA: 17s - loss: 0.7983 - accuracy: 0.5938INFO:tensorflow:For batch 1, loss is    0.69.\n",
      "INFO:tensorflow:For batch 1, accuracy is    0.62.\n",
      " 128/7352 [..............................] - ETA: 16s - loss: 0.7460 - accuracy: 0.6250INFO:tensorflow:For batch 2, loss is    0.90.\n",
      "INFO:tensorflow:For batch 2, accuracy is    0.60.\n",
      " 192/7352 [..............................] - ETA: 16s - loss: 0.7962 - accuracy: 0.6042INFO:tensorflow:For batch 3, loss is    0.77.\n",
      "INFO:tensorflow:For batch 3, accuracy is    0.62.\n",
      " 256/7352 [>.............................] - ETA: 16s - loss: 0.7906 - accuracy: 0.6211INFO:tensorflow:For batch 4, loss is    0.72.\n",
      "INFO:tensorflow:For batch 4, accuracy is    0.65.\n",
      " 320/7352 [>.............................] - ETA: 16s - loss: 0.7759 - accuracy: 0.6469INFO:tensorflow:For batch 5, loss is    0.81.\n",
      "INFO:tensorflow:For batch 5, accuracy is    0.65.\n",
      " 384/7352 [>.............................] - ETA: 16s - loss: 0.7821 - accuracy: 0.6510INFO:tensorflow:For batch 6, loss is    0.75.\n",
      "INFO:tensorflow:For batch 6, accuracy is    0.65.\n",
      " 448/7352 [>.............................] - ETA: 15s - loss: 0.7776 - accuracy: 0.6540INFO:tensorflow:For batch 7, loss is    0.81.\n",
      "INFO:tensorflow:For batch 7, accuracy is    0.66.\n",
      " 512/7352 [=>............................] - ETA: 15s - loss: 0.7816 - accuracy: 0.6582INFO:tensorflow:For batch 8, loss is    0.58.\n",
      "INFO:tensorflow:For batch 8, accuracy is    0.67.\n",
      " 576/7352 [=>............................] - ETA: 15s - loss: 0.7587 - accuracy: 0.6701INFO:tensorflow:For batch 9, loss is    0.70.\n",
      "INFO:tensorflow:For batch 9, accuracy is    0.67.\n",
      " 640/7352 [=>............................] - ETA: 15s - loss: 0.7532 - accuracy: 0.6719INFO:tensorflow:For batch 10, loss is    0.77.\n",
      "INFO:tensorflow:For batch 10, accuracy is    0.67.\n",
      " 704/7352 [=>............................] - ETA: 15s - loss: 0.7543 - accuracy: 0.6705INFO:tensorflow:For batch 11, loss is    0.61.\n",
      "INFO:tensorflow:For batch 11, accuracy is    0.68.\n",
      " 768/7352 [==>...........................] - ETA: 15s - loss: 0.7422 - accuracy: 0.6797INFO:tensorflow:For batch 12, loss is    0.70.\n",
      "INFO:tensorflow:For batch 12, accuracy is    0.69.\n",
      " 832/7352 [==>...........................] - ETA: 14s - loss: 0.7393 - accuracy: 0.6863INFO:tensorflow:For batch 13, loss is    0.85.\n",
      "INFO:tensorflow:For batch 13, accuracy is    0.68.\n",
      " 896/7352 [==>...........................] - ETA: 14s - loss: 0.7472 - accuracy: 0.6763INFO:tensorflow:For batch 14, loss is    0.76.\n",
      "INFO:tensorflow:For batch 14, accuracy is    0.68.\n",
      " 960/7352 [==>...........................] - ETA: 14s - loss: 0.7479 - accuracy: 0.6781INFO:tensorflow:For batch 15, loss is    0.81.\n",
      "INFO:tensorflow:For batch 15, accuracy is    0.67.\n",
      "1024/7352 [===>..........................] - ETA: 14s - loss: 0.7520 - accuracy: 0.6699INFO:tensorflow:For batch 16, loss is    0.69.\n",
      "INFO:tensorflow:For batch 16, accuracy is    0.67.\n",
      "1088/7352 [===>..........................] - ETA: 14s - loss: 0.7482 - accuracy: 0.6710INFO:tensorflow:For batch 17, loss is    0.73.\n",
      "INFO:tensorflow:For batch 17, accuracy is    0.68.\n",
      "1152/7352 [===>..........................] - ETA: 14s - loss: 0.7471 - accuracy: 0.6771INFO:tensorflow:For batch 18, loss is    0.64.\n",
      "INFO:tensorflow:For batch 18, accuracy is    0.68.\n",
      "1216/7352 [===>..........................] - ETA: 14s - loss: 0.7414 - accuracy: 0.6793INFO:tensorflow:For batch 19, loss is    0.83.\n",
      "INFO:tensorflow:For batch 19, accuracy is    0.68.\n",
      "1280/7352 [====>.........................] - ETA: 13s - loss: 0.7457 - accuracy: 0.6781INFO:tensorflow:For batch 20, loss is    0.79.\n",
      "INFO:tensorflow:For batch 20, accuracy is    0.68.\n",
      "1344/7352 [====>.........................] - ETA: 13s - loss: 0.7480 - accuracy: 0.6763INFO:tensorflow:For batch 21, loss is    0.71.\n",
      "INFO:tensorflow:For batch 21, accuracy is    0.67.\n",
      "1408/7352 [====>.........................] - ETA: 13s - loss: 0.7460 - accuracy: 0.6733INFO:tensorflow:For batch 22, loss is    0.69.\n",
      "INFO:tensorflow:For batch 22, accuracy is    0.67.\n",
      "1472/7352 [=====>........................] - ETA: 13s - loss: 0.7436 - accuracy: 0.6719INFO:tensorflow:For batch 23, loss is    0.80.\n",
      "INFO:tensorflow:For batch 23, accuracy is    0.67.\n",
      "1536/7352 [=====>........................] - ETA: 13s - loss: 0.7458 - accuracy: 0.6706INFO:tensorflow:For batch 24, loss is    0.92.\n",
      "INFO:tensorflow:For batch 24, accuracy is    0.67.\n",
      "1600/7352 [=====>........................] - ETA: 13s - loss: 0.7528 - accuracy: 0.6687INFO:tensorflow:For batch 25, loss is    0.75.\n",
      "INFO:tensorflow:For batch 25, accuracy is    0.67.\n",
      "1664/7352 [=====>........................] - ETA: 13s - loss: 0.7526 - accuracy: 0.6677INFO:tensorflow:For batch 26, loss is    0.64.\n",
      "INFO:tensorflow:For batch 26, accuracy is    0.67.\n",
      "1728/7352 [======>.......................] - ETA: 12s - loss: 0.7485 - accuracy: 0.6719INFO:tensorflow:For batch 27, loss is    0.88.\n",
      "INFO:tensorflow:For batch 27, accuracy is    0.67.\n",
      "1792/7352 [======>.......................] - ETA: 12s - loss: 0.7531 - accuracy: 0.6691INFO:tensorflow:For batch 28, loss is    0.77.\n",
      "INFO:tensorflow:For batch 28, accuracy is    0.67.\n",
      "1856/7352 [======>.......................] - ETA: 12s - loss: 0.7537 - accuracy: 0.6654INFO:tensorflow:For batch 29, loss is    0.85.\n",
      "INFO:tensorflow:For batch 29, accuracy is    0.66.\n",
      "1920/7352 [======>.......................] - ETA: 12s - loss: 0.7568 - accuracy: 0.6635INFO:tensorflow:For batch 30, loss is    0.66.\n",
      "INFO:tensorflow:For batch 30, accuracy is    0.66.\n",
      "1984/7352 [=======>......................] - ETA: 12s - loss: 0.7538 - accuracy: 0.6638INFO:tensorflow:For batch 31, loss is    0.77.\n",
      "INFO:tensorflow:For batch 31, accuracy is    0.66.\n",
      "2048/7352 [=======>......................] - ETA: 12s - loss: 0.7544 - accuracy: 0.6641INFO:tensorflow:For batch 32, loss is    0.81.\n",
      "INFO:tensorflow:For batch 32, accuracy is    0.66.\n",
      "2112/7352 [=======>......................] - ETA: 12s - loss: 0.7560 - accuracy: 0.6648INFO:tensorflow:For batch 33, loss is    0.74.\n",
      "INFO:tensorflow:For batch 33, accuracy is    0.66.\n",
      "2176/7352 [=======>......................] - ETA: 12s - loss: 0.7555 - accuracy: 0.6645INFO:tensorflow:For batch 34, loss is    0.85.\n",
      "INFO:tensorflow:For batch 34, accuracy is    0.66.\n",
      "2240/7352 [========>.....................] - ETA: 12s - loss: 0.7581 - accuracy: 0.6629INFO:tensorflow:For batch 35, loss is    0.68.\n",
      "INFO:tensorflow:For batch 35, accuracy is    0.66.\n",
      "2304/7352 [========>.....................] - ETA: 12s - loss: 0.7561 - accuracy: 0.6632INFO:tensorflow:For batch 36, loss is    0.74.\n",
      "INFO:tensorflow:For batch 36, accuracy is    0.66.\n",
      "2368/7352 [========>.....................] - ETA: 12s - loss: 0.7556 - accuracy: 0.6617INFO:tensorflow:For batch 37, loss is    0.83.\n",
      "INFO:tensorflow:For batch 37, accuracy is    0.66.\n",
      "2432/7352 [========>.....................] - ETA: 12s - loss: 0.7575 - accuracy: 0.6604INFO:tensorflow:For batch 38, loss is    0.63.\n",
      "INFO:tensorflow:For batch 38, accuracy is    0.66.\n",
      "2496/7352 [=========>....................] - ETA: 12s - loss: 0.7543 - accuracy: 0.6635INFO:tensorflow:For batch 39, loss is    0.80.\n",
      "INFO:tensorflow:For batch 39, accuracy is    0.66.\n",
      "2560/7352 [=========>....................] - ETA: 12s - loss: 0.7554 - accuracy: 0.6621INFO:tensorflow:For batch 40, loss is    0.78.\n",
      "INFO:tensorflow:For batch 40, accuracy is    0.66.\n",
      "2624/7352 [=========>....................] - ETA: 12s - loss: 0.7560 - accuracy: 0.6635INFO:tensorflow:For batch 41, loss is    0.91.\n",
      "INFO:tensorflow:For batch 41, accuracy is    0.66.\n",
      "2688/7352 [=========>....................] - ETA: 11s - loss: 0.7597 - accuracy: 0.6648INFO:tensorflow:For batch 42, loss is    0.65.\n",
      "INFO:tensorflow:For batch 42, accuracy is    0.67.\n",
      "2752/7352 [==========>...................] - ETA: 11s - loss: 0.7572 - accuracy: 0.6653INFO:tensorflow:For batch 43, loss is    0.71.\n",
      "INFO:tensorflow:For batch 43, accuracy is    0.66.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2816/7352 [==========>...................] - ETA: 11s - loss: 0.7561 - accuracy: 0.6648INFO:tensorflow:For batch 44, loss is    0.65.\n",
      "INFO:tensorflow:For batch 44, accuracy is    0.67.\n",
      "2880/7352 [==========>...................] - ETA: 11s - loss: 0.7538 - accuracy: 0.6653INFO:tensorflow:For batch 45, loss is    0.75.\n",
      "INFO:tensorflow:For batch 45, accuracy is    0.66.\n",
      "2944/7352 [===========>..................] - ETA: 11s - loss: 0.7537 - accuracy: 0.6647INFO:tensorflow:For batch 46, loss is    0.67.\n",
      "INFO:tensorflow:For batch 46, accuracy is    0.66.\n",
      "3008/7352 [===========>..................] - ETA: 11s - loss: 0.7519 - accuracy: 0.6646INFO:tensorflow:For batch 47, loss is    0.83.\n",
      "INFO:tensorflow:For batch 47, accuracy is    0.66.\n",
      "3072/7352 [===========>..................] - ETA: 11s - loss: 0.7536 - accuracy: 0.6647INFO:tensorflow:For batch 48, loss is    0.65.\n",
      "INFO:tensorflow:For batch 48, accuracy is    0.66.\n",
      "3136/7352 [===========>..................] - ETA: 11s - loss: 0.7515 - accuracy: 0.6649INFO:tensorflow:For batch 49, loss is    0.64.\n",
      "INFO:tensorflow:For batch 49, accuracy is    0.67.\n",
      "3200/7352 [============>.................] - ETA: 10s - loss: 0.7494 - accuracy: 0.6650INFO:tensorflow:For batch 50, loss is    0.77.\n",
      "INFO:tensorflow:For batch 50, accuracy is    0.66.\n",
      "3264/7352 [============>.................] - ETA: 10s - loss: 0.7498 - accuracy: 0.6648INFO:tensorflow:For batch 51, loss is    0.75.\n",
      "INFO:tensorflow:For batch 51, accuracy is    0.66.\n",
      "3328/7352 [============>.................] - ETA: 10s - loss: 0.7498 - accuracy: 0.6635INFO:tensorflow:For batch 52, loss is    0.67.\n",
      "INFO:tensorflow:For batch 52, accuracy is    0.66.\n",
      "3392/7352 [============>.................] - ETA: 10s - loss: 0.7483 - accuracy: 0.6636INFO:tensorflow:For batch 53, loss is    0.70.\n",
      "INFO:tensorflow:For batch 53, accuracy is    0.66.\n",
      "3456/7352 [=============>................] - ETA: 10s - loss: 0.7474 - accuracy: 0.6635INFO:tensorflow:For batch 54, loss is    0.65.\n",
      "INFO:tensorflow:For batch 54, accuracy is    0.66.\n",
      "3520/7352 [=============>................] - ETA: 10s - loss: 0.7457 - accuracy: 0.6648INFO:tensorflow:For batch 55, loss is    0.71.\n",
      "INFO:tensorflow:For batch 55, accuracy is    0.67.\n",
      "3584/7352 [=============>................] - ETA: 10s - loss: 0.7451 - accuracy: 0.6652INFO:tensorflow:For batch 56, loss is    0.63.\n",
      "INFO:tensorflow:For batch 56, accuracy is    0.67.\n",
      "3648/7352 [=============>................] - ETA: 10s - loss: 0.7431 - accuracy: 0.6650INFO:tensorflow:For batch 57, loss is    0.61.\n",
      "INFO:tensorflow:For batch 57, accuracy is    0.67.\n",
      "3712/7352 [==============>...............] - ETA: 10s - loss: 0.7408 - accuracy: 0.6654INFO:tensorflow:For batch 58, loss is    0.69.\n",
      "INFO:tensorflow:For batch 58, accuracy is    0.66.\n",
      "3776/7352 [==============>...............] - ETA: 9s - loss: 0.7400 - accuracy: 0.6650 INFO:tensorflow:For batch 59, loss is    0.64.\n",
      "INFO:tensorflow:For batch 59, accuracy is    0.67.\n",
      "3840/7352 [==============>...............] - ETA: 9s - loss: 0.7384 - accuracy: 0.6659INFO:tensorflow:For batch 60, loss is    0.65.\n",
      "INFO:tensorflow:For batch 60, accuracy is    0.67.\n",
      "3904/7352 [==============>...............] - ETA: 9s - loss: 0.7369 - accuracy: 0.6665INFO:tensorflow:For batch 61, loss is    0.68.\n",
      "INFO:tensorflow:For batch 61, accuracy is    0.67.\n",
      "3968/7352 [===============>..............] - ETA: 9s - loss: 0.7360 - accuracy: 0.6666INFO:tensorflow:For batch 62, loss is    0.60.\n",
      "INFO:tensorflow:For batch 62, accuracy is    0.67.\n",
      "4032/7352 [===============>..............] - ETA: 9s - loss: 0.7338 - accuracy: 0.6677INFO:tensorflow:For batch 63, loss is    0.81.\n",
      "INFO:tensorflow:For batch 63, accuracy is    0.67.\n",
      "4096/7352 [===============>..............] - ETA: 9s - loss: 0.7349 - accuracy: 0.6685INFO:tensorflow:For batch 64, loss is    0.65.\n",
      "INFO:tensorflow:For batch 64, accuracy is    0.67.\n",
      "4160/7352 [===============>..............] - ETA: 8s - loss: 0.7336 - accuracy: 0.6687INFO:tensorflow:For batch 65, loss is    0.79.\n",
      "INFO:tensorflow:For batch 65, accuracy is    0.67.\n",
      "4224/7352 [================>.............] - ETA: 8s - loss: 0.7345 - accuracy: 0.6690INFO:tensorflow:For batch 66, loss is    0.70.\n",
      "INFO:tensorflow:For batch 66, accuracy is    0.67.\n",
      "4288/7352 [================>.............] - ETA: 8s - loss: 0.7340 - accuracy: 0.6691INFO:tensorflow:For batch 67, loss is    0.70.\n",
      "INFO:tensorflow:For batch 67, accuracy is    0.67.\n",
      "4352/7352 [================>.............] - ETA: 8s - loss: 0.7335 - accuracy: 0.6698INFO:tensorflow:For batch 68, loss is    0.67.\n",
      "INFO:tensorflow:For batch 68, accuracy is    0.67.\n",
      "4416/7352 [=================>............] - ETA: 8s - loss: 0.7326 - accuracy: 0.6707INFO:tensorflow:For batch 69, loss is    0.61.\n",
      "INFO:tensorflow:For batch 69, accuracy is    0.67.\n",
      "4480/7352 [=================>............] - ETA: 8s - loss: 0.7308 - accuracy: 0.6710INFO:tensorflow:For batch 70, loss is    0.60.\n",
      "INFO:tensorflow:For batch 70, accuracy is    0.67.\n",
      "4544/7352 [=================>............] - ETA: 7s - loss: 0.7289 - accuracy: 0.6712INFO:tensorflow:For batch 71, loss is    0.70.\n",
      "INFO:tensorflow:For batch 71, accuracy is    0.67.\n",
      "4608/7352 [=================>............] - ETA: 7s - loss: 0.7285 - accuracy: 0.6710INFO:tensorflow:For batch 72, loss is    0.63.\n",
      "INFO:tensorflow:For batch 72, accuracy is    0.67.\n",
      "4672/7352 [==================>...........] - ETA: 7s - loss: 0.7270 - accuracy: 0.6719INFO:tensorflow:For batch 73, loss is    0.54.\n",
      "INFO:tensorflow:For batch 73, accuracy is    0.67.\n",
      "4736/7352 [==================>...........] - ETA: 7s - loss: 0.7246 - accuracy: 0.6744INFO:tensorflow:For batch 74, loss is    0.65.\n",
      "INFO:tensorflow:For batch 74, accuracy is    0.68.\n",
      "4800/7352 [==================>...........] - ETA: 7s - loss: 0.7235 - accuracy: 0.6756INFO:tensorflow:For batch 75, loss is    0.78.\n",
      "INFO:tensorflow:For batch 75, accuracy is    0.68.\n",
      "4864/7352 [==================>...........] - ETA: 7s - loss: 0.7243 - accuracy: 0.6754INFO:tensorflow:For batch 76, loss is    0.55.\n",
      "INFO:tensorflow:For batch 76, accuracy is    0.68.\n",
      "4928/7352 [===================>..........] - ETA: 6s - loss: 0.7220 - accuracy: 0.6767INFO:tensorflow:For batch 77, loss is    0.58.\n",
      "INFO:tensorflow:For batch 77, accuracy is    0.68.\n",
      "4992/7352 [===================>..........] - ETA: 6s - loss: 0.7202 - accuracy: 0.6777INFO:tensorflow:For batch 78, loss is    0.51.\n",
      "INFO:tensorflow:For batch 78, accuracy is    0.68.\n",
      "5056/7352 [===================>..........] - ETA: 6s - loss: 0.7175 - accuracy: 0.6790INFO:tensorflow:For batch 79, loss is    0.66.\n",
      "INFO:tensorflow:For batch 79, accuracy is    0.68.\n",
      "5120/7352 [===================>..........] - ETA: 6s - loss: 0.7168 - accuracy: 0.6793INFO:tensorflow:For batch 80, loss is    0.55.\n",
      "INFO:tensorflow:For batch 80, accuracy is    0.68.\n",
      "5184/7352 [====================>.........] - ETA: 6s - loss: 0.7148 - accuracy: 0.6798INFO:tensorflow:For batch 81, loss is    0.67.\n",
      "INFO:tensorflow:For batch 81, accuracy is    0.68.\n",
      "5248/7352 [====================>.........] - ETA: 5s - loss: 0.7142 - accuracy: 0.6799INFO:tensorflow:For batch 82, loss is    0.66.\n",
      "INFO:tensorflow:For batch 82, accuracy is    0.68.\n",
      "5312/7352 [====================>.........] - ETA: 5s - loss: 0.7135 - accuracy: 0.6798INFO:tensorflow:For batch 83, loss is    0.76.\n",
      "INFO:tensorflow:For batch 83, accuracy is    0.68.\n",
      "5376/7352 [====================>.........] - ETA: 5s - loss: 0.7141 - accuracy: 0.6793INFO:tensorflow:For batch 84, loss is    0.57.\n",
      "INFO:tensorflow:For batch 84, accuracy is    0.68.\n",
      "5440/7352 [=====================>........] - ETA: 5s - loss: 0.7124 - accuracy: 0.6801INFO:tensorflow:For batch 85, loss is    0.59.\n",
      "INFO:tensorflow:For batch 85, accuracy is    0.68.\n",
      "5504/7352 [=====================>........] - ETA: 5s - loss: 0.7110 - accuracy: 0.6801INFO:tensorflow:For batch 86, loss is    0.70.\n",
      "INFO:tensorflow:For batch 86, accuracy is    0.68.\n",
      "5568/7352 [=====================>........] - ETA: 4s - loss: 0.7109 - accuracy: 0.6801INFO:tensorflow:For batch 87, loss is    0.64.\n",
      "INFO:tensorflow:For batch 87, accuracy is    0.68.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632/7352 [=====================>........] - ETA: 4s - loss: 0.7101 - accuracy: 0.6813INFO:tensorflow:For batch 88, loss is    0.65.\n",
      "INFO:tensorflow:For batch 88, accuracy is    0.68.\n",
      "5696/7352 [======================>.......] - ETA: 4s - loss: 0.7094 - accuracy: 0.6815INFO:tensorflow:For batch 89, loss is    0.74.\n",
      "INFO:tensorflow:For batch 89, accuracy is    0.68.\n",
      "5760/7352 [======================>.......] - ETA: 4s - loss: 0.7097 - accuracy: 0.6812INFO:tensorflow:For batch 90, loss is    0.55.\n",
      "INFO:tensorflow:For batch 90, accuracy is    0.68.\n",
      "5824/7352 [======================>.......] - ETA: 4s - loss: 0.7080 - accuracy: 0.6827INFO:tensorflow:For batch 91, loss is    0.71.\n",
      "INFO:tensorflow:For batch 91, accuracy is    0.68.\n",
      "5888/7352 [=======================>......] - ETA: 4s - loss: 0.7080 - accuracy: 0.6824INFO:tensorflow:For batch 92, loss is    0.55.\n",
      "INFO:tensorflow:For batch 92, accuracy is    0.68.\n",
      "5952/7352 [=======================>......] - ETA: 3s - loss: 0.7063 - accuracy: 0.6831INFO:tensorflow:For batch 93, loss is    0.60.\n",
      "INFO:tensorflow:For batch 93, accuracy is    0.68.\n",
      "6016/7352 [=======================>......] - ETA: 3s - loss: 0.7051 - accuracy: 0.6838INFO:tensorflow:For batch 94, loss is    0.85.\n",
      "INFO:tensorflow:For batch 94, accuracy is    0.68.\n",
      "6080/7352 [=======================>......] - ETA: 3s - loss: 0.7066 - accuracy: 0.6832INFO:tensorflow:For batch 95, loss is    0.53.\n",
      "INFO:tensorflow:For batch 95, accuracy is    0.68.\n",
      "6144/7352 [========================>.....] - ETA: 3s - loss: 0.7048 - accuracy: 0.6836INFO:tensorflow:For batch 96, loss is    0.67.\n",
      "INFO:tensorflow:For batch 96, accuracy is    0.68.\n",
      "6208/7352 [========================>.....] - ETA: 3s - loss: 0.7045 - accuracy: 0.6843INFO:tensorflow:For batch 97, loss is    0.72.\n",
      "INFO:tensorflow:For batch 97, accuracy is    0.68.\n",
      "6272/7352 [========================>.....] - ETA: 2s - loss: 0.7046 - accuracy: 0.6845INFO:tensorflow:For batch 98, loss is    0.58.\n",
      "INFO:tensorflow:For batch 98, accuracy is    0.68.\n",
      "6336/7352 [========================>.....] - ETA: 2s - loss: 0.7034 - accuracy: 0.6845INFO:tensorflow:For batch 99, loss is    0.52.\n",
      "INFO:tensorflow:For batch 99, accuracy is    0.69.\n",
      "6400/7352 [=========================>....] - ETA: 2s - loss: 0.7016 - accuracy: 0.6853INFO:tensorflow:For batch 100, loss is    0.55.\n",
      "INFO:tensorflow:For batch 100, accuracy is    0.69.\n",
      "6464/7352 [=========================>....] - ETA: 2s - loss: 0.7001 - accuracy: 0.6861INFO:tensorflow:For batch 101, loss is    0.92.\n",
      "INFO:tensorflow:For batch 101, accuracy is    0.69.\n",
      "6528/7352 [=========================>....] - ETA: 2s - loss: 0.7023 - accuracy: 0.6854INFO:tensorflow:For batch 102, loss is    0.67.\n",
      "INFO:tensorflow:For batch 102, accuracy is    0.69.\n",
      "6592/7352 [=========================>....] - ETA: 2s - loss: 0.7020 - accuracy: 0.6854INFO:tensorflow:For batch 103, loss is    0.91.\n",
      "INFO:tensorflow:For batch 103, accuracy is    0.69.\n",
      "6656/7352 [==========================>...] - ETA: 1s - loss: 0.7039 - accuracy: 0.6857INFO:tensorflow:For batch 104, loss is    0.92.\n",
      "INFO:tensorflow:For batch 104, accuracy is    0.68.\n",
      "6720/7352 [==========================>...] - ETA: 1s - loss: 0.7060 - accuracy: 0.6850INFO:tensorflow:For batch 105, loss is    0.89.\n",
      "INFO:tensorflow:For batch 105, accuracy is    0.69.\n",
      "6784/7352 [==========================>...] - ETA: 1s - loss: 0.7078 - accuracy: 0.6853INFO:tensorflow:For batch 106, loss is    0.82.\n",
      "INFO:tensorflow:For batch 106, accuracy is    0.69.\n",
      "6848/7352 [==========================>...] - ETA: 1s - loss: 0.7088 - accuracy: 0.6853INFO:tensorflow:For batch 107, loss is    0.73.\n",
      "INFO:tensorflow:For batch 107, accuracy is    0.69.\n",
      "6912/7352 [===========================>..] - ETA: 1s - loss: 0.7091 - accuracy: 0.6852INFO:tensorflow:For batch 108, loss is    0.70.\n",
      "INFO:tensorflow:For batch 108, accuracy is    0.69.\n",
      "6976/7352 [===========================>..] - ETA: 1s - loss: 0.7090 - accuracy: 0.6853INFO:tensorflow:For batch 109, loss is    0.70.\n",
      "INFO:tensorflow:For batch 109, accuracy is    0.69.\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.7089 - accuracy: 0.6855INFO:tensorflow:For batch 110, loss is    0.71.\n",
      "INFO:tensorflow:For batch 110, accuracy is    0.69.\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.7090 - accuracy: 0.6857INFO:tensorflow:For batch 111, loss is    0.53.\n",
      "INFO:tensorflow:For batch 111, accuracy is    0.69.\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.7074 - accuracy: 0.6864INFO:tensorflow:For batch 112, loss is    0.71.\n",
      "INFO:tensorflow:For batch 112, accuracy is    0.69.\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.7074 - accuracy: 0.6864INFO:tensorflow:For batch 113, loss is    0.64.\n",
      "INFO:tensorflow:For batch 113, accuracy is    0.69.\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.7069 - accuracy: 0.6868INFO:tensorflow:For batch 114, loss is    0.64.\n",
      "INFO:tensorflow:For batch 114, accuracy is    0.69.\n",
      "INFO:tensorflow:weights of 1 layers for epoch1 is [array([[ 0.00130382,  0.04760838, -0.04057293, ..., -0.10510332,\n",
      "        -0.07745853, -0.10931837],\n",
      "       [ 0.00172554, -0.09134862,  0.02783905, ...,  0.01758271,\n",
      "        -0.01314026,  0.05463457],\n",
      "       [ 0.01235796,  0.07913245, -0.05424274, ..., -0.09940122,\n",
      "        -0.0824735 , -0.00721409],\n",
      "       ...,\n",
      "       [-0.04937297, -0.02962569, -0.11375054, ..., -0.11093422,\n",
      "        -0.20552261,  0.00150566],\n",
      "       [ 0.02671139, -0.00814252,  0.06832945, ..., -0.05105608,\n",
      "         0.2048104 ,  0.02484954],\n",
      "       [-0.13605714,  0.11326611, -0.07775422, ..., -0.17848821,\n",
      "         0.10325755, -0.0939501 ]], dtype=float32), array([[-0.02629171,  0.05394616, -0.00763435, ..., -0.13481018,\n",
      "        -0.07719369, -0.04379787],\n",
      "       [-0.1327059 ,  0.10843913, -0.03216023, ...,  0.12900876,\n",
      "         0.02112745,  0.06448004],\n",
      "       [ 0.0506995 , -0.04621726, -0.01425146, ..., -0.03119265,\n",
      "        -0.05623813, -0.04719155],\n",
      "       ...,\n",
      "       [-0.0211874 ,  0.06985413, -0.02957368, ...,  0.05537505,\n",
      "         0.05570063,  0.03776132],\n",
      "       [ 0.05580965,  0.04151329,  0.02166692, ...,  0.01043385,\n",
      "        -0.02583642,  0.02158005],\n",
      "       [-0.05350925, -0.03226713,  0.07603771, ..., -0.0845902 ,\n",
      "         0.04326612, -0.07957195]], dtype=float32), array([ 1.65924535e-03,  5.96135156e-03,  3.29722539e-02,  1.48919802e-02,\n",
      "        2.27089692e-02,  1.12144754e-03, -1.27119450e-02,  3.97995040e-02,\n",
      "       -4.22147848e-03,  1.24241598e-03,  2.92863622e-02,  3.61287184e-02,\n",
      "       -5.63115207e-03, -1.66434236e-02,  1.36470888e-02, -5.92875469e-04,\n",
      "        8.68969411e-03,  5.66083612e-03,  1.62183717e-02,  2.19316017e-02,\n",
      "        1.24595361e-02,  3.03012691e-02,  1.91829931e-02,  7.06263585e-03,\n",
      "        7.89729506e-03,  8.26655421e-03,  5.97210974e-03,  3.49631757e-02,\n",
      "        1.16086034e-02,  4.26339880e-02,  4.13453812e-03, -1.15732560e-02,\n",
      "       -7.46369455e-03,  2.62539890e-02,  1.59562975e-02, -7.22792326e-03,\n",
      "        1.93005279e-02,  1.35821262e-02,  1.74718872e-02,  9.18382313e-03,\n",
      "        1.46795418e-02,  1.96234323e-02,  9.82005801e-03,  2.15398856e-02,\n",
      "        2.75502726e-02,  1.47118722e-03,  1.14683416e-02,  2.44515352e-02,\n",
      "       -9.81098972e-03,  9.91053972e-03,  1.37144020e-02,  1.91409551e-02,\n",
      "        3.09191030e-02,  1.98765062e-02,  2.04462539e-02,  2.65860856e-02,\n",
      "        3.07491105e-02,  9.45178326e-03,  7.29813520e-03,  1.73970331e-02,\n",
      "       -2.25003273e-03,  5.72056230e-03, -1.60503816e-02,  2.44143866e-02,\n",
      "        1.83624662e-02,  1.89283509e-02,  9.06129740e-03,  2.13686377e-02,\n",
      "        3.15699801e-02,  3.58732324e-03,  1.45712420e-02,  3.08729690e-02,\n",
      "        1.41153242e-02,  1.46380961e-02,  6.18295511e-03, -1.24418745e-02,\n",
      "        1.26746530e-02,  1.50933564e-02,  3.11002657e-02,  2.12037638e-02,\n",
      "       -9.55597963e-03,  1.91203747e-02,  1.24897826e-02,  1.02986405e-02,\n",
      "       -1.37918480e-02,  4.42694090e-02,  4.37467452e-03,  5.71416691e-03,\n",
      "        5.81848715e-03,  7.48196105e-03, -2.13959557e-03,  2.66867895e-02,\n",
      "        1.17434310e-02,  2.02260595e-02,  2.54837014e-02,  3.63623612e-02,\n",
      "       -5.62384084e-04,  6.62210304e-03, -6.30702171e-03,  3.23273533e-04,\n",
      "        9.97261882e-01,  1.00963962e+00,  1.03698540e+00,  1.01766264e+00,\n",
      "        1.02744401e+00,  1.00510907e+00,  9.90369022e-01,  1.04124928e+00,\n",
      "        9.96380508e-01,  1.00112355e+00,  1.02335417e+00,  1.03292811e+00,\n",
      "        9.91095543e-01,  9.90060806e-01,  1.01780343e+00,  9.98241425e-01,\n",
      "        1.01151323e+00,  1.01788211e+00,  1.01528668e+00,  1.02291167e+00,\n",
      "        1.01493812e+00,  1.02980483e+00,  1.01728690e+00,  1.00621402e+00,\n",
      "        1.01164961e+00,  1.00101936e+00,  1.00779188e+00,  1.05802286e+00,\n",
      "        1.01153612e+00,  1.04171383e+00,  1.00941324e+00,  1.00778413e+00,\n",
      "        9.95656848e-01,  1.02279234e+00,  1.02694809e+00,  9.94689643e-01,\n",
      "        1.01754618e+00,  1.02285206e+00,  1.03599226e+00,  1.01306832e+00,\n",
      "        1.01411545e+00,  1.04605055e+00,  1.01363456e+00,  1.03361309e+00,\n",
      "        1.03089893e+00,  1.00437546e+00,  1.01755142e+00,  1.03289640e+00,\n",
      "        9.92268085e-01,  1.01258481e+00,  1.01941156e+00,  1.02507341e+00,\n",
      "        1.04897594e+00,  1.02527869e+00,  1.02102399e+00,  1.02880049e+00,\n",
      "        1.02979219e+00,  1.01174033e+00,  1.01544511e+00,  1.01877987e+00,\n",
      "        9.93852556e-01,  1.01828492e+00,  9.97855246e-01,  1.02600515e+00,\n",
      "        1.01861489e+00,  1.02639961e+00,  1.01055992e+00,  1.01442802e+00,\n",
      "        1.02958369e+00,  1.00548232e+00,  1.01345205e+00,  1.03230894e+00,\n",
      "        1.01608062e+00,  1.01572859e+00,  1.00743747e+00,  9.93296921e-01,\n",
      "        1.01175964e+00,  1.01571298e+00,  1.02952719e+00,  1.01894665e+00,\n",
      "        9.98492658e-01,  1.01941001e+00,  1.01551270e+00,  1.00895357e+00,\n",
      "        9.91536498e-01,  1.03700125e+00,  1.00417960e+00,  1.00696468e+00,\n",
      "        1.00576532e+00,  1.00286615e+00,  9.92756009e-01,  1.02583432e+00,\n",
      "        1.01535904e+00,  1.02183366e+00,  1.02963865e+00,  1.04829931e+00,\n",
      "        1.00527072e+00,  1.01279891e+00,  1.00772464e+00,  9.98875201e-01,\n",
      "       -4.18995041e-03, -6.70950976e-04,  1.03706066e-02, -1.82303041e-03,\n",
      "       -1.96129233e-02, -4.81529906e-02,  2.23526321e-02, -4.35219286e-03,\n",
      "       -1.64370015e-02,  2.09687427e-02, -2.19253860e-02, -8.01433716e-03,\n",
      "       -2.30537169e-02, -4.89727547e-03, -1.10548001e-03,  1.28630409e-02,\n",
      "        2.50129756e-02,  4.47622780e-03,  1.68988220e-02, -2.24991664e-02,\n",
      "       -1.50856609e-02, -1.53687578e-02,  2.22501555e-03, -7.05119735e-03,\n",
      "       -2.27043200e-02, -2.17424873e-02, -1.62921846e-02,  3.38608511e-02,\n",
      "       -3.01116854e-02,  1.06533021e-02, -1.59306042e-02,  1.58345904e-02,\n",
      "       -1.05323261e-02, -1.84206627e-02, -3.60380829e-04,  1.74931921e-02,\n",
      "       -1.62023269e-02, -2.62175184e-02, -1.19407400e-02,  3.00110672e-02,\n",
      "       -1.78472772e-02, -4.58224909e-03,  1.17421607e-02, -1.52956322e-02,\n",
      "        7.81141175e-03, -2.20367033e-02, -1.76995955e-02,  5.99936675e-03,\n",
      "       -3.57488990e-02,  6.41551055e-03,  2.11138520e-02, -1.08273793e-03,\n",
      "        1.33763691e-02, -9.20694135e-03, -2.70715486e-02, -8.86114687e-03,\n",
      "       -1.39085427e-02,  1.93097703e-02,  1.55128399e-02,  1.10953180e-02,\n",
      "       -1.67440195e-02, -4.58859792e-03,  1.17735481e-02, -1.04624648e-02,\n",
      "       -1.85626578e-02,  1.86169017e-02,  1.45333279e-02, -3.19559835e-02,\n",
      "       -1.87848229e-02, -2.01612134e-02, -3.40646505e-02, -3.26843327e-03,\n",
      "       -1.89346634e-02, -1.69306379e-02,  3.00943740e-02,  9.25692916e-03,\n",
      "       -2.36306600e-02, -8.59413203e-03, -4.50103916e-03, -1.39965711e-03,\n",
      "       -1.25331469e-02, -1.80983043e-04, -1.96883865e-02,  4.89034643e-03,\n",
      "        1.41387330e-02, -5.59351873e-03, -1.55046955e-02,  3.00383307e-02,\n",
      "       -2.41422579e-02,  2.19776854e-02,  3.66418669e-03,  5.67522412e-03,\n",
      "        1.61846466e-02,  1.18325474e-02,  1.63475312e-02, -9.89284553e-03,\n",
      "        2.77392548e-02,  9.41919815e-03,  3.65800981e-04, -3.41101643e-03,\n",
      "        2.39894143e-03,  1.66125875e-02,  2.43827272e-02,  1.18083172e-02,\n",
      "        3.00160684e-02, -1.66028470e-03, -1.24977501e-02,  3.83960120e-02,\n",
      "       -9.21527855e-03,  6.47932338e-03,  2.75111087e-02,  3.87034081e-02,\n",
      "       -5.79853496e-03, -1.10606467e-02,  2.96254065e-02, -3.96786025e-03,\n",
      "        1.21592684e-02,  1.88804734e-02,  1.35428403e-02,  2.81240959e-02,\n",
      "        1.54990237e-02,  2.20282804e-02,  2.02401616e-02,  1.28729669e-02,\n",
      "        1.00422669e-02,  7.57523160e-03,  6.85601588e-03,  5.85185327e-02,\n",
      "        1.34885684e-02,  4.04406562e-02,  9.75769851e-03,  6.74776221e-03,\n",
      "       -5.13053779e-03,  2.97478735e-02,  1.77892428e-02, -9.24333557e-03,\n",
      "        2.27414332e-02,  2.15987954e-02,  3.73337902e-02,  1.36779901e-02,\n",
      "        1.58050749e-02,  3.80983502e-02,  1.11755449e-02,  2.27094330e-02,\n",
      "        3.43656614e-02,  2.05163425e-03,  1.01987999e-02,  3.13015021e-02,\n",
      "       -7.35450024e-03,  1.67793073e-02,  1.53406449e-02,  2.32968889e-02,\n",
      "        5.30571863e-02,  2.83764005e-02,  2.32996568e-02,  3.29947546e-02,\n",
      "        4.06988747e-02,  1.17913941e-02,  1.50959361e-02,  1.75473988e-02,\n",
      "       -1.89561152e-03,  2.17907429e-02, -1.35988919e-02,  1.97444372e-02,\n",
      "        1.07583916e-02,  3.75509523e-02,  7.13753281e-03,  2.10993402e-02,\n",
      "        2.66812406e-02,  6.92159496e-03,  1.65122263e-02,  4.11000103e-02,\n",
      "        1.43589843e-02,  1.62907280e-02,  1.36351269e-02, -7.11177802e-03,\n",
      "        1.40261436e-02,  1.02809425e-02,  2.93564275e-02,  2.78088730e-02,\n",
      "       -7.68570229e-03,  1.36976289e-02,  1.82516128e-02,  6.15123194e-04,\n",
      "       -3.99617944e-03,  4.93947491e-02,  5.80814527e-03,  7.10391439e-03,\n",
      "        8.45678523e-03,  8.42239242e-03, -2.15873099e-03,  2.33523604e-02,\n",
      "        1.65964141e-02,  1.88187696e-02,  3.45557816e-02,  5.65962531e-02,\n",
      "        2.65864213e-03,  7.43049476e-03,  3.55769903e-03, -7.16885494e-04],\n",
      "      dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:weights of 2 layers for epoch1 is []\n",
      "INFO:tensorflow:weights of 3 layers for epoch1 is [array([[-0.03423771,  0.15211576,  0.080055  , ..., -0.09834465,\n",
      "         0.0195485 ,  0.03000432],\n",
      "       [-0.02611823, -0.16559374, -0.08733361, ...,  0.06883513,\n",
      "        -0.14866905,  0.08831345],\n",
      "       [ 0.07433157,  0.19176151, -0.05154756, ...,  0.12007113,\n",
      "         0.16690592, -0.05785355],\n",
      "       ...,\n",
      "       [ 0.16538876,  0.06219265, -0.22965898, ..., -0.12411749,\n",
      "         0.05356557,  0.10924557],\n",
      "       [ 0.04405705,  0.06047421, -0.15596738, ..., -0.14007808,\n",
      "         0.12649633,  0.00200172],\n",
      "       [ 0.12697929,  0.19152758, -0.06982262, ...,  0.03894269,\n",
      "        -0.09202811,  0.06724539]], dtype=float32), array([ 0.00560724,  0.0140112 ,  0.02598291,  0.05880027,  0.00919224,\n",
      "        0.02357315,  0.0111302 , -0.01114517, -0.01551114,  0.03332201,\n",
      "        0.06038263,  0.04489188,  0.01125355,  0.02971582,  0.04838587,\n",
      "        0.00844303,  0.00519807, -0.00176608,  0.05712621,  0.00864422,\n",
      "        0.02571779,  0.03387347,  0.01890656,  0.00098148,  0.02473248,\n",
      "        0.05785314,  0.03151292,  0.04768169,  0.03227599, -0.0058208 ,\n",
      "        0.033389  , -0.01607396,  0.02523218,  0.02934311,  0.02461716,\n",
      "       -0.04051274,  0.00398668,  0.04757646,  0.03887607,  0.0149977 ,\n",
      "        0.00874843,  0.05484368,  0.03084138,  0.01155579,  0.0360586 ,\n",
      "       -0.02281866,  0.06629346,  0.02091412, -0.00613435,  0.00621015,\n",
      "        0.0066333 ,  0.03780065, -0.00486802,  0.01314   ,  0.04289314,\n",
      "        0.02056785,  0.03761882,  0.02073903,  0.0469906 ,  0.00064567,\n",
      "       -0.02037446,  0.0189777 , -0.00219504,  0.0446545 , -0.00141263,\n",
      "        0.02672638,  0.01534689,  0.00396867,  0.00796484,  0.01861744,\n",
      "        0.02814973,  0.02803677,  0.02667828, -0.05750379,  0.02285866,\n",
      "        0.03683768,  0.00193516,  0.02685106, -0.01606384, -0.00971185,\n",
      "        0.00292187,  0.01549074,  0.02936546,  0.03365193,  0.03764629,\n",
      "       -0.00072517,  0.02761246, -0.01142829,  0.05088424,  0.02260864,\n",
      "       -0.00930017,  0.03150697,  0.03376683,  0.03260015, -0.01151776,\n",
      "        0.02692478,  0.00745022,  0.00597287,  0.04688285,  0.0002016 ],\n",
      "      dtype=float32)]\n",
      "INFO:tensorflow:weights of 4 layers for epoch1 is [array([[ 0.00863928,  0.10131843,  0.19212718, -0.07948551, -0.02005311,\n",
      "        -0.12048566],\n",
      "       [-0.1969765 , -0.12578344, -0.05431107, -0.03718063,  0.03321302,\n",
      "         0.15715453],\n",
      "       [ 0.14510289,  0.10481914,  0.14572129,  0.13034205,  0.19052254,\n",
      "        -0.15609133],\n",
      "       [ 0.27673602, -0.00496672, -0.03890575, -0.23254421,  0.00986043,\n",
      "        -0.2669532 ],\n",
      "       [-0.08220147,  0.1042246 , -0.2273184 ,  0.1286838 , -0.13428505,\n",
      "         0.2439691 ],\n",
      "       [-0.0774238 ,  0.11800364,  0.15243484, -0.13508147, -0.21712415,\n",
      "        -0.2982857 ],\n",
      "       [ 0.02677085,  0.05228459, -0.07355375, -0.16381562,  0.13073319,\n",
      "         0.07736826],\n",
      "       [-0.21062915,  0.0180081 ,  0.23590805, -0.15042695, -0.05546419,\n",
      "         0.07972398],\n",
      "       [-0.06953898, -0.11581489,  0.21745639,  0.03203805, -0.0674945 ,\n",
      "        -0.20588385],\n",
      "       [-0.20304605,  0.19579938,  0.07707369,  0.07768845,  0.00933616,\n",
      "         0.24654517],\n",
      "       [ 0.20392832,  0.08897962,  0.23142815, -0.09444927,  0.10253416,\n",
      "         0.06933276],\n",
      "       [ 0.05802912, -0.04148153,  0.08884101, -0.28440365, -0.22225979,\n",
      "        -0.27871346],\n",
      "       [ 0.12183916, -0.18527411, -0.03656488, -0.10447931, -0.09092756,\n",
      "         0.21552438],\n",
      "       [-0.2093705 , -0.20542333, -0.01963584, -0.05955355, -0.20033468,\n",
      "         0.19216472],\n",
      "       [ 0.20245832, -0.10515989,  0.20950747, -0.25693214, -0.2541011 ,\n",
      "        -0.2953284 ],\n",
      "       [-0.23950575, -0.08868717, -0.0036709 ,  0.2215422 ,  0.13690454,\n",
      "         0.10335312],\n",
      "       [-0.15885593, -0.06074451,  0.18687586,  0.0851699 ,  0.13289174,\n",
      "        -0.01837436],\n",
      "       [ 0.09372315,  0.12631185, -0.06283627,  0.17349309, -0.08573177,\n",
      "        -0.21064319],\n",
      "       [ 0.03753248, -0.12911525,  0.04768153, -0.0787008 , -0.03122419,\n",
      "        -0.30798322],\n",
      "       [ 0.03413017,  0.10034083,  0.01116761, -0.03874712,  0.2445452 ,\n",
      "        -0.23859909],\n",
      "       [-0.16997144,  0.07825917, -0.0206458 ,  0.12408037, -0.20266783,\n",
      "         0.11981186],\n",
      "       [ 0.15514706,  0.13199915, -0.20097768, -0.03103343,  0.09821262,\n",
      "        -0.25146335],\n",
      "       [-0.16939922, -0.18614888, -0.13204715,  0.06877736, -0.0198613 ,\n",
      "        -0.19546147],\n",
      "       [ 0.07519335, -0.23040469, -0.23039265,  0.10046536, -0.174656  ,\n",
      "        -0.22168355],\n",
      "       [-0.07426047, -0.05011645, -0.16362363,  0.02839254,  0.01890155,\n",
      "         0.0236571 ],\n",
      "       [ 0.20239787, -0.07116549,  0.18749155, -0.01578308,  0.1384296 ,\n",
      "        -0.24870503],\n",
      "       [ 0.11543411, -0.05963092, -0.24392386, -0.14985584, -0.02684165,\n",
      "         0.13896285],\n",
      "       [ 0.02670686,  0.1029376 ,  0.2151902 , -0.07338543, -0.12817915,\n",
      "         0.13784629],\n",
      "       [-0.2720845 , -0.19898689, -0.18356813, -0.10691731,  0.05063359,\n",
      "         0.0779837 ],\n",
      "       [-0.11036197,  0.1398306 ,  0.10180856,  0.09127324,  0.22196077,\n",
      "        -0.02785184],\n",
      "       [-0.06346977,  0.1693704 , -0.16276388, -0.13544986, -0.14700139,\n",
      "         0.21356864],\n",
      "       [-0.2308807 ,  0.04801666,  0.13698947,  0.08180992, -0.22239278,\n",
      "         0.05310255],\n",
      "       [-0.21609966, -0.15118481,  0.05339024,  0.12283931, -0.24597958,\n",
      "         0.01901872],\n",
      "       [-0.12504107,  0.10697573, -0.1998353 ,  0.1797186 , -0.26713562,\n",
      "         0.24304274],\n",
      "       [ 0.12176374, -0.12685356,  0.03128793, -0.13129449, -0.1464795 ,\n",
      "         0.21569073],\n",
      "       [-0.02069771,  0.14757568, -0.12693262,  0.12720847, -0.12991819,\n",
      "        -0.09867156],\n",
      "       [ 0.16061535,  0.09168682, -0.17971067,  0.14988938, -0.25294366,\n",
      "         0.15339257],\n",
      "       [ 0.23804504,  0.1642445 ,  0.06987215, -0.34559727, -0.13879631,\n",
      "        -0.12235664],\n",
      "       [ 0.09250361, -0.20759329, -0.28793934,  0.19192278, -0.2361458 ,\n",
      "         0.22290294],\n",
      "       [-0.01812954, -0.10890181,  0.00120179,  0.22541672, -0.03903513,\n",
      "         0.06800237],\n",
      "       [-0.18460234, -0.05449493, -0.208909  ,  0.20708981,  0.2571026 ,\n",
      "        -0.18052308],\n",
      "       [-0.05830206, -0.32289156, -0.16013727,  0.15997252,  0.04368735,\n",
      "         0.01574988],\n",
      "       [ 0.01907959,  0.13045955, -0.2099756 , -0.20215203,  0.09105379,\n",
      "         0.06531025],\n",
      "       [-0.2776524 , -0.15190536, -0.2862737 ,  0.229232  , -0.21307257,\n",
      "        -0.1145407 ],\n",
      "       [-0.1596647 , -0.25563866, -0.2784955 ,  0.07671675,  0.10078806,\n",
      "        -0.27470648],\n",
      "       [-0.04536172,  0.22812974,  0.17212576,  0.13922073,  0.14780836,\n",
      "        -0.09390829],\n",
      "       [ 0.11558091, -0.2084309 , -0.04352138,  0.06313948,  0.12580475,\n",
      "        -0.07255737],\n",
      "       [ 0.2324707 ,  0.17067134,  0.02007544, -0.04051035, -0.16642128,\n",
      "         0.15419707],\n",
      "       [ 0.00539233,  0.23810524, -0.06474287,  0.0719842 , -0.27223104,\n",
      "        -0.09858117],\n",
      "       [ 0.14527841,  0.09584473, -0.1517345 ,  0.16817701,  0.16516565,\n",
      "        -0.03921961],\n",
      "       [-0.13571605, -0.01413305, -0.13777862, -0.1892605 ,  0.16934657,\n",
      "         0.15833208],\n",
      "       [-0.08793813,  0.00520235, -0.2033443 ,  0.11648474, -0.09737463,\n",
      "         0.2560235 ],\n",
      "       [-0.13391615,  0.07902955, -0.16604172,  0.16491853, -0.23880032,\n",
      "         0.05209578],\n",
      "       [-0.02833114, -0.0549022 , -0.19155492,  0.05679609,  0.10000405,\n",
      "         0.07452086],\n",
      "       [ 0.09058505, -0.03049257,  0.15228991, -0.13245828, -0.04260549,\n",
      "        -0.18894228],\n",
      "       [ 0.1666548 , -0.15340738,  0.25410378,  0.12545934, -0.22136548,\n",
      "        -0.29604104],\n",
      "       [-0.06401717, -0.24792095, -0.05481306,  0.12608387, -0.15850258,\n",
      "         0.24609858],\n",
      "       [ 0.1733656 , -0.05606381, -0.02048434,  0.02427329, -0.07739877,\n",
      "         0.06919969],\n",
      "       [-0.12383894, -0.06363435, -0.2628088 ,  0.0720559 ,  0.06351873,\n",
      "         0.05381396],\n",
      "       [ 0.00973983,  0.18792245,  0.1702447 , -0.09437556, -0.12298915,\n",
      "        -0.1753011 ],\n",
      "       [-0.21768036,  0.07796237,  0.03600102,  0.12530607,  0.00383628,\n",
      "        -0.11057282],\n",
      "       [ 0.04046465, -0.1896574 ,  0.08451101,  0.14003703, -0.25350618,\n",
      "         0.20555808],\n",
      "       [-0.00595391, -0.19087231, -0.23925875, -0.1500988 , -0.16826545,\n",
      "         0.04365677],\n",
      "       [ 0.12741989,  0.2278733 ,  0.22788832, -0.32015634, -0.01938707,\n",
      "        -0.17917079],\n",
      "       [ 0.04709297, -0.0214488 , -0.08737972,  0.06044824, -0.14847963,\n",
      "         0.24755043],\n",
      "       [-0.20930035, -0.06780084,  0.03396067,  0.12926826, -0.16464363,\n",
      "         0.21506222],\n",
      "       [-0.05861695,  0.11210576,  0.18083076, -0.08055409,  0.01415317,\n",
      "        -0.24266241],\n",
      "       [-0.02309473,  0.04581575,  0.0507758 ,  0.00055828,  0.01543727,\n",
      "         0.15331134],\n",
      "       [ 0.17002511, -0.15812576,  0.03231908,  0.03129776,  0.24727732,\n",
      "         0.0556788 ],\n",
      "       [-0.1852785 , -0.09831723,  0.15551877,  0.17925571,  0.25083098,\n",
      "        -0.04745422],\n",
      "       [ 0.17134775, -0.1406518 ,  0.0862748 , -0.18190464, -0.148198  ,\n",
      "         0.19115554],\n",
      "       [-0.18546666, -0.19497184,  0.00109375, -0.23397686, -0.06322344,\n",
      "         0.22474863],\n",
      "       [-0.02400218,  0.2605023 ,  0.09808926, -0.19733681, -0.16605434,\n",
      "         0.07228827],\n",
      "       [-0.17761901,  0.1858448 , -0.05395421,  0.05526584, -0.04213931,\n",
      "        -0.00389545],\n",
      "       [-0.14936484, -0.09898147, -0.13851915, -0.05184309,  0.02445503,\n",
      "         0.12215345],\n",
      "       [-0.03211388, -0.26409718,  0.02023534,  0.206029  ,  0.2415874 ,\n",
      "        -0.20128025],\n",
      "       [-0.16492927, -0.00975037,  0.06042663, -0.16181357,  0.23230816,\n",
      "        -0.2143812 ],\n",
      "       [-0.16325851,  0.04061354,  0.04774274, -0.23245083, -0.2717179 ,\n",
      "        -0.07837162],\n",
      "       [ 0.15502828,  0.12356224, -0.1361806 , -0.04036939, -0.12192893,\n",
      "        -0.194675  ],\n",
      "       [-0.11205108,  0.1459809 , -0.0481782 ,  0.03142156,  0.2140813 ,\n",
      "        -0.16065802],\n",
      "       [-0.16826804,  0.0185701 , -0.23725256, -0.1366201 ,  0.08341945,\n",
      "         0.09654531],\n",
      "       [ 0.1737456 ,  0.02645601, -0.01328658,  0.17767482, -0.2310027 ,\n",
      "         0.12349967],\n",
      "       [-0.10068219,  0.223622  ,  0.00550786,  0.05411229, -0.29384527,\n",
      "         0.23599231],\n",
      "       [ 0.08120354,  0.25929418, -0.16019076, -0.27629763, -0.2077126 ,\n",
      "        -0.10946585],\n",
      "       [ 0.01468507,  0.14424899,  0.12226578, -0.27031964, -0.11176138,\n",
      "         0.02268955],\n",
      "       [ 0.01294093,  0.13773465, -0.23349358,  0.13732927, -0.01033803,\n",
      "        -0.2653629 ],\n",
      "       [ 0.09013732,  0.04675443, -0.08707123,  0.23761456, -0.15123422,\n",
      "         0.22787504],\n",
      "       [-0.16001461,  0.1734763 ,  0.0009527 , -0.16308354, -0.29971576,\n",
      "         0.01128886],\n",
      "       [ 0.24079886, -0.16767117, -0.0768322 ,  0.17787437,  0.19094035,\n",
      "        -0.33130372],\n",
      "       [-0.10212304, -0.17335725,  0.06881206, -0.13587143, -0.09561912,\n",
      "         0.24777417],\n",
      "       [ 0.00062056,  0.09968469, -0.14505512,  0.1317068 , -0.14717302,\n",
      "        -0.20854504],\n",
      "       [-0.16160445, -0.27742407, -0.103719  , -0.01417934,  0.20860952,\n",
      "        -0.1966103 ],\n",
      "       [ 0.1868937 ,  0.01785465, -0.21909826, -0.26785305,  0.18271776,\n",
      "        -0.11515051],\n",
      "       [-0.00167463, -0.04414776, -0.17062752, -0.2082718 , -0.19296867,\n",
      "         0.13403265],\n",
      "       [-0.15224747,  0.099553  ,  0.18931893, -0.11409402, -0.11454552,\n",
      "        -0.00353628],\n",
      "       [ 0.03736521, -0.02374675, -0.07269681, -0.17262112, -0.26482147,\n",
      "         0.24192734],\n",
      "       [-0.01440637, -0.16724712, -0.11724071,  0.05014463, -0.14254126,\n",
      "        -0.29056606],\n",
      "       [ 0.0875458 ,  0.19940501, -0.01932099,  0.15645938,  0.17883515,\n",
      "        -0.04203866],\n",
      "       [ 0.14786896,  0.0236613 ,  0.00061816, -0.01856141, -0.03816325,\n",
      "         0.24606027],\n",
      "       [ 0.12817596,  0.02935112, -0.02876099,  0.04858553, -0.15009585,\n",
      "         0.09519633]], dtype=float32), array([ 0.0249266 , -0.0309101 ,  0.00151697, -0.01873199,  0.00378644,\n",
      "        0.01690189], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The average loss for epoch 1 is    0.71 and accuracy is    0.69.\n",
      "7352/7352 [==============================] - 20s 3ms/sample - loss: 0.7064 - accuracy: 0.6873\n",
      "Epoch 3/5\n",
      "INFO:tensorflow:For batch 0, loss is    0.70.\n",
      "INFO:tensorflow:For batch 0, accuracy is    0.69.\n",
      "  64/7352 [..............................] - ETA: 30s - loss: 0.6985 - accuracy: 0.6875INFO:tensorflow:For batch 1, loss is    0.81.\n",
      "INFO:tensorflow:For batch 1, accuracy is    0.66.\n",
      " 128/7352 [..............................] - ETA: 28s - loss: 0.7522 - accuracy: 0.6562INFO:tensorflow:For batch 2, loss is    0.74.\n",
      "INFO:tensorflow:For batch 2, accuracy is    0.66.\n",
      " 192/7352 [..............................] - ETA: 25s - loss: 0.7471 - accuracy: 0.6562INFO:tensorflow:For batch 3, loss is    0.66.\n",
      "INFO:tensorflow:For batch 3, accuracy is    0.66.\n",
      " 256/7352 [>.............................] - ETA: 23s - loss: 0.7264 - accuracy: 0.6641INFO:tensorflow:For batch 4, loss is    0.72.\n",
      "INFO:tensorflow:For batch 4, accuracy is    0.66.\n",
      " 320/7352 [>.............................] - ETA: 22s - loss: 0.7257 - accuracy: 0.6562INFO:tensorflow:For batch 5, loss is    0.54.\n",
      "INFO:tensorflow:For batch 5, accuracy is    0.68.\n",
      " 384/7352 [>.............................] - ETA: 23s - loss: 0.6940 - accuracy: 0.6823INFO:tensorflow:For batch 6, loss is    0.77.\n",
      "INFO:tensorflow:For batch 6, accuracy is    0.67.\n",
      " 448/7352 [>.............................] - ETA: 23s - loss: 0.7052 - accuracy: 0.6741INFO:tensorflow:For batch 7, loss is    0.68.\n",
      "INFO:tensorflow:For batch 7, accuracy is    0.68.\n",
      " 512/7352 [=>............................] - ETA: 23s - loss: 0.7024 - accuracy: 0.6816INFO:tensorflow:For batch 8, loss is    0.66.\n",
      "INFO:tensorflow:For batch 8, accuracy is    0.69.\n",
      " 576/7352 [=>............................] - ETA: 23s - loss: 0.6978 - accuracy: 0.6875INFO:tensorflow:For batch 9, loss is    0.66.\n",
      "INFO:tensorflow:For batch 9, accuracy is    0.69.\n",
      " 640/7352 [=>............................] - ETA: 22s - loss: 0.6937 - accuracy: 0.6891INFO:tensorflow:For batch 10, loss is    0.65.\n",
      "INFO:tensorflow:For batch 10, accuracy is    0.69.\n",
      " 704/7352 [=>............................] - ETA: 21s - loss: 0.6898 - accuracy: 0.6903INFO:tensorflow:For batch 11, loss is    0.73.\n",
      "INFO:tensorflow:For batch 11, accuracy is    0.69.\n",
      " 768/7352 [==>...........................] - ETA: 21s - loss: 0.6931 - accuracy: 0.6875INFO:tensorflow:For batch 12, loss is    0.79.\n",
      "INFO:tensorflow:For batch 12, accuracy is    0.68.\n",
      " 832/7352 [==>...........................] - ETA: 21s - loss: 0.7002 - accuracy: 0.6791INFO:tensorflow:For batch 13, loss is    0.67.\n",
      "INFO:tensorflow:For batch 13, accuracy is    0.68.\n",
      " 896/7352 [==>...........................] - ETA: 20s - loss: 0.6982 - accuracy: 0.6842INFO:tensorflow:For batch 14, loss is    0.55.\n",
      "INFO:tensorflow:For batch 14, accuracy is    0.69.\n",
      " 960/7352 [==>...........................] - ETA: 20s - loss: 0.6882 - accuracy: 0.6885INFO:tensorflow:For batch 15, loss is    0.60.\n",
      "INFO:tensorflow:For batch 15, accuracy is    0.69.\n",
      "1024/7352 [===>..........................] - ETA: 20s - loss: 0.6827 - accuracy: 0.6934INFO:tensorflow:For batch 16, loss is    0.65.\n",
      "INFO:tensorflow:For batch 16, accuracy is    0.69.\n",
      "1088/7352 [===>..........................] - ETA: 20s - loss: 0.6809 - accuracy: 0.6939INFO:tensorflow:For batch 17, loss is    0.62.\n",
      "INFO:tensorflow:For batch 17, accuracy is    0.70.\n",
      "1152/7352 [===>..........................] - ETA: 19s - loss: 0.6775 - accuracy: 0.6953INFO:tensorflow:For batch 18, loss is    0.70.\n",
      "INFO:tensorflow:For batch 18, accuracy is    0.70.\n",
      "1216/7352 [===>..........................] - ETA: 19s - loss: 0.6784 - accuracy: 0.6965INFO:tensorflow:For batch 19, loss is    0.57.\n",
      "INFO:tensorflow:For batch 19, accuracy is    0.70.\n",
      "1280/7352 [====>.........................] - ETA: 19s - loss: 0.6727 - accuracy: 0.7008INFO:tensorflow:For batch 20, loss is    0.64.\n",
      "INFO:tensorflow:For batch 20, accuracy is    0.70.\n",
      "1344/7352 [====>.........................] - ETA: 19s - loss: 0.6711 - accuracy: 0.7031INFO:tensorflow:For batch 21, loss is    0.49.\n",
      "INFO:tensorflow:For batch 21, accuracy is    0.71.\n",
      "1408/7352 [====>.........................] - ETA: 19s - loss: 0.6626 - accuracy: 0.7095INFO:tensorflow:For batch 22, loss is    1.30.\n",
      "INFO:tensorflow:For batch 22, accuracy is    0.70.\n",
      "1472/7352 [=====>........................] - ETA: 18s - loss: 0.6903 - accuracy: 0.7031INFO:tensorflow:For batch 23, loss is    2.10.\n",
      "INFO:tensorflow:For batch 23, accuracy is    0.69.\n",
      "1536/7352 [=====>........................] - ETA: 18s - loss: 0.7491 - accuracy: 0.6934INFO:tensorflow:For batch 24, loss is    2.25.\n",
      "INFO:tensorflow:For batch 24, accuracy is    0.68.\n",
      "1600/7352 [=====>........................] - ETA: 18s - loss: 0.8093 - accuracy: 0.6806INFO:tensorflow:For batch 25, loss is    2.95.\n",
      "INFO:tensorflow:For batch 25, accuracy is    0.67.\n",
      "1664/7352 [=====>........................] - ETA: 18s - loss: 0.8915 - accuracy: 0.6659INFO:tensorflow:For batch 26, loss is    1.86.\n",
      "INFO:tensorflow:For batch 26, accuracy is    0.66.\n",
      "1728/7352 [======>.......................] - ETA: 17s - loss: 0.9275 - accuracy: 0.6620INFO:tensorflow:For batch 27, loss is    1.78.\n",
      "INFO:tensorflow:For batch 27, accuracy is    0.65.\n",
      "1792/7352 [======>.......................] - ETA: 17s - loss: 0.9580 - accuracy: 0.6535INFO:tensorflow:For batch 28, loss is    1.30.\n",
      "INFO:tensorflow:For batch 28, accuracy is    0.65.\n",
      "1856/7352 [======>.......................] - ETA: 17s - loss: 0.9698 - accuracy: 0.6487INFO:tensorflow:For batch 29, loss is    1.44.\n",
      "INFO:tensorflow:For batch 29, accuracy is    0.64.\n",
      "1920/7352 [======>.......................] - ETA: 16s - loss: 0.9853 - accuracy: 0.6438INFO:tensorflow:For batch 30, loss is    1.62.\n",
      "INFO:tensorflow:For batch 30, accuracy is    0.63.\n",
      "1984/7352 [=======>......................] - ETA: 16s - loss: 1.0056 - accuracy: 0.6346INFO:tensorflow:For batch 31, loss is    1.15.\n",
      "INFO:tensorflow:For batch 31, accuracy is    0.63.\n",
      "2048/7352 [=======>......................] - ETA: 16s - loss: 1.0102 - accuracy: 0.6313INFO:tensorflow:For batch 32, loss is    1.26.\n",
      "INFO:tensorflow:For batch 32, accuracy is    0.63.\n",
      "2112/7352 [=======>......................] - ETA: 15s - loss: 1.0176 - accuracy: 0.6255INFO:tensorflow:For batch 33, loss is    1.12.\n",
      "INFO:tensorflow:For batch 33, accuracy is    0.62.\n",
      "2176/7352 [=======>......................] - ETA: 15s - loss: 1.0208 - accuracy: 0.6213INFO:tensorflow:For batch 34, loss is    1.23.\n",
      "INFO:tensorflow:For batch 34, accuracy is    0.62.\n",
      "2240/7352 [========>.....................] - ETA: 15s - loss: 1.0267 - accuracy: 0.6156INFO:tensorflow:For batch 35, loss is    1.14.\n",
      "INFO:tensorflow:For batch 35, accuracy is    0.61.\n",
      "2304/7352 [========>.....................] - ETA: 14s - loss: 1.0298 - accuracy: 0.6133INFO:tensorflow:For batch 36, loss is    1.22.\n",
      "INFO:tensorflow:For batch 36, accuracy is    0.61.\n",
      "2368/7352 [========>.....................] - ETA: 14s - loss: 1.0348 - accuracy: 0.6085INFO:tensorflow:For batch 37, loss is    1.23.\n",
      "INFO:tensorflow:For batch 37, accuracy is    0.61.\n",
      "2432/7352 [========>.....................] - ETA: 14s - loss: 1.0400 - accuracy: 0.6053INFO:tensorflow:For batch 38, loss is    0.96.\n",
      "INFO:tensorflow:For batch 38, accuracy is    0.60.\n",
      "2496/7352 [=========>....................] - ETA: 14s - loss: 1.0380 - accuracy: 0.6030INFO:tensorflow:For batch 39, loss is    0.80.\n",
      "INFO:tensorflow:For batch 39, accuracy is    0.60.\n",
      "2560/7352 [=========>....................] - ETA: 14s - loss: 1.0320 - accuracy: 0.6043INFO:tensorflow:For batch 40, loss is    0.90.\n",
      "INFO:tensorflow:For batch 40, accuracy is    0.61.\n",
      "2624/7352 [=========>....................] - ETA: 13s - loss: 1.0287 - accuracy: 0.6056INFO:tensorflow:For batch 41, loss is    1.04.\n",
      "INFO:tensorflow:For batch 41, accuracy is    0.60.\n",
      "2688/7352 [=========>....................] - ETA: 13s - loss: 1.0291 - accuracy: 0.6042INFO:tensorflow:For batch 42, loss is    0.91.\n",
      "INFO:tensorflow:For batch 42, accuracy is    0.60.\n",
      "2752/7352 [==========>...................] - ETA: 13s - loss: 1.0264 - accuracy: 0.6036INFO:tensorflow:For batch 43, loss is    0.80.\n",
      "INFO:tensorflow:For batch 43, accuracy is    0.60.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2816/7352 [==========>...................] - ETA: 13s - loss: 1.0213 - accuracy: 0.6040INFO:tensorflow:For batch 44, loss is    1.08.\n",
      "INFO:tensorflow:For batch 44, accuracy is    0.60.\n",
      "2880/7352 [==========>...................] - ETA: 13s - loss: 1.0225 - accuracy: 0.6021INFO:tensorflow:For batch 45, loss is    0.85.\n",
      "INFO:tensorflow:For batch 45, accuracy is    0.60.\n",
      "2944/7352 [===========>..................] - ETA: 13s - loss: 1.0187 - accuracy: 0.6033INFO:tensorflow:For batch 46, loss is    1.00.\n",
      "INFO:tensorflow:For batch 46, accuracy is    0.60.\n",
      "3008/7352 [===========>..................] - ETA: 12s - loss: 1.0183 - accuracy: 0.6017INFO:tensorflow:For batch 47, loss is    0.81.\n",
      "INFO:tensorflow:For batch 47, accuracy is    0.60.\n",
      "3072/7352 [===========>..................] - ETA: 12s - loss: 1.0140 - accuracy: 0.6035INFO:tensorflow:For batch 48, loss is    0.80.\n",
      "INFO:tensorflow:For batch 48, accuracy is    0.60.\n",
      "3136/7352 [===========>..................] - ETA: 12s - loss: 1.0096 - accuracy: 0.6040INFO:tensorflow:For batch 49, loss is    0.91.\n",
      "INFO:tensorflow:For batch 49, accuracy is    0.60.\n",
      "3200/7352 [============>.................] - ETA: 12s - loss: 1.0076 - accuracy: 0.6044INFO:tensorflow:For batch 50, loss is    0.94.\n",
      "INFO:tensorflow:For batch 50, accuracy is    0.60.\n",
      "3264/7352 [============>.................] - ETA: 11s - loss: 1.0063 - accuracy: 0.6048INFO:tensorflow:For batch 51, loss is    0.95.\n",
      "INFO:tensorflow:For batch 51, accuracy is    0.60.\n",
      "3328/7352 [============>.................] - ETA: 11s - loss: 1.0052 - accuracy: 0.6040INFO:tensorflow:For batch 52, loss is    0.78.\n",
      "INFO:tensorflow:For batch 52, accuracy is    0.60.\n",
      "3392/7352 [============>.................] - ETA: 11s - loss: 1.0009 - accuracy: 0.6047INFO:tensorflow:For batch 53, loss is    0.82.\n",
      "INFO:tensorflow:For batch 53, accuracy is    0.61.\n",
      "3456/7352 [=============>................] - ETA: 11s - loss: 0.9976 - accuracy: 0.6059INFO:tensorflow:For batch 54, loss is    0.83.\n",
      "INFO:tensorflow:For batch 54, accuracy is    0.61.\n",
      "3520/7352 [=============>................] - ETA: 10s - loss: 0.9946 - accuracy: 0.6062INFO:tensorflow:For batch 55, loss is    0.72.\n",
      "INFO:tensorflow:For batch 55, accuracy is    0.61.\n",
      "3584/7352 [=============>................] - ETA: 10s - loss: 0.9898 - accuracy: 0.6080INFO:tensorflow:For batch 56, loss is    0.67.\n",
      "INFO:tensorflow:For batch 56, accuracy is    0.61.\n",
      "3648/7352 [=============>................] - ETA: 10s - loss: 0.9841 - accuracy: 0.6105INFO:tensorflow:For batch 57, loss is    0.70.\n",
      "INFO:tensorflow:For batch 57, accuracy is    0.61.\n",
      "3712/7352 [==============>...............] - ETA: 10s - loss: 0.9792 - accuracy: 0.6123INFO:tensorflow:For batch 58, loss is    0.79.\n",
      "INFO:tensorflow:For batch 58, accuracy is    0.61.\n",
      "3776/7352 [==============>...............] - ETA: 10s - loss: 0.9760 - accuracy: 0.6144INFO:tensorflow:For batch 59, loss is    0.89.\n",
      "INFO:tensorflow:For batch 59, accuracy is    0.61.\n",
      "3840/7352 [==============>...............] - ETA: 9s - loss: 0.9746 - accuracy: 0.6148 INFO:tensorflow:For batch 60, loss is    0.75.\n",
      "INFO:tensorflow:For batch 60, accuracy is    0.62.\n",
      "3904/7352 [==============>...............] - ETA: 9s - loss: 0.9710 - accuracy: 0.6158INFO:tensorflow:For batch 61, loss is    0.97.\n",
      "INFO:tensorflow:For batch 61, accuracy is    0.62.\n",
      "3968/7352 [===============>..............] - ETA: 9s - loss: 0.9709 - accuracy: 0.6154INFO:tensorflow:For batch 62, loss is    0.54.\n",
      "INFO:tensorflow:For batch 62, accuracy is    0.62.\n",
      "4032/7352 [===============>..............] - ETA: 9s - loss: 0.9641 - accuracy: 0.6188INFO:tensorflow:For batch 63, loss is    0.61.\n",
      "INFO:tensorflow:For batch 63, accuracy is    0.62.\n",
      "4096/7352 [===============>..............] - ETA: 9s - loss: 0.9585 - accuracy: 0.6211INFO:tensorflow:For batch 64, loss is    0.81.\n",
      "INFO:tensorflow:For batch 64, accuracy is    0.62.\n",
      "4160/7352 [===============>..............] - ETA: 8s - loss: 0.9563 - accuracy: 0.6209INFO:tensorflow:For batch 65, loss is    0.80.\n",
      "INFO:tensorflow:For batch 65, accuracy is    0.62.\n",
      "4224/7352 [================>.............] - ETA: 8s - loss: 0.9540 - accuracy: 0.6217INFO:tensorflow:For batch 66, loss is    0.78.\n",
      "INFO:tensorflow:For batch 66, accuracy is    0.62.\n",
      "4288/7352 [================>.............] - ETA: 8s - loss: 0.9514 - accuracy: 0.6224INFO:tensorflow:For batch 67, loss is    0.92.\n",
      "INFO:tensorflow:For batch 67, accuracy is    0.62.\n",
      "4352/7352 [================>.............] - ETA: 8s - loss: 0.9509 - accuracy: 0.6213INFO:tensorflow:For batch 68, loss is    0.78.\n",
      "INFO:tensorflow:For batch 68, accuracy is    0.62.\n",
      "4416/7352 [=================>............] - ETA: 7s - loss: 0.9484 - accuracy: 0.6216INFO:tensorflow:For batch 69, loss is    0.78.\n",
      "INFO:tensorflow:For batch 69, accuracy is    0.62.\n",
      "4480/7352 [=================>............] - ETA: 7s - loss: 0.9461 - accuracy: 0.6223INFO:tensorflow:For batch 70, loss is    0.71.\n",
      "INFO:tensorflow:For batch 70, accuracy is    0.62.\n",
      "4544/7352 [=================>............] - ETA: 7s - loss: 0.9427 - accuracy: 0.6230INFO:tensorflow:For batch 71, loss is    0.69.\n",
      "INFO:tensorflow:For batch 71, accuracy is    0.62.\n",
      "4608/7352 [=================>............] - ETA: 7s - loss: 0.9392 - accuracy: 0.6235INFO:tensorflow:For batch 72, loss is    0.56.\n",
      "INFO:tensorflow:For batch 72, accuracy is    0.62.\n",
      "4672/7352 [==================>...........] - ETA: 7s - loss: 0.9341 - accuracy: 0.6248INFO:tensorflow:For batch 73, loss is    0.59.\n",
      "INFO:tensorflow:For batch 73, accuracy is    0.63.\n",
      "4736/7352 [==================>...........] - ETA: 7s - loss: 0.9294 - accuracy: 0.6265INFO:tensorflow:For batch 74, loss is    0.66.\n",
      "INFO:tensorflow:For batch 74, accuracy is    0.63.\n",
      "4800/7352 [==================>...........] - ETA: 6s - loss: 0.9258 - accuracy: 0.6277INFO:tensorflow:For batch 75, loss is    0.71.\n",
      "INFO:tensorflow:For batch 75, accuracy is    0.63.\n",
      "4864/7352 [==================>...........] - ETA: 6s - loss: 0.9230 - accuracy: 0.6283INFO:tensorflow:For batch 76, loss is    0.66.\n",
      "INFO:tensorflow:For batch 76, accuracy is    0.63.\n",
      "4928/7352 [===================>..........] - ETA: 6s - loss: 0.9196 - accuracy: 0.6295INFO:tensorflow:For batch 77, loss is    0.77.\n",
      "INFO:tensorflow:For batch 77, accuracy is    0.63.\n",
      "4992/7352 [===================>..........] - ETA: 6s - loss: 0.9177 - accuracy: 0.6302INFO:tensorflow:For batch 78, loss is    0.70.\n",
      "INFO:tensorflow:For batch 78, accuracy is    0.63.\n",
      "5056/7352 [===================>..........] - ETA: 6s - loss: 0.9149 - accuracy: 0.6311INFO:tensorflow:For batch 79, loss is    0.62.\n",
      "INFO:tensorflow:For batch 79, accuracy is    0.63.\n",
      "5120/7352 [===================>..........] - ETA: 5s - loss: 0.9113 - accuracy: 0.6334INFO:tensorflow:For batch 80, loss is    0.68.\n",
      "INFO:tensorflow:For batch 80, accuracy is    0.63.\n",
      "5184/7352 [====================>.........] - ETA: 5s - loss: 0.9084 - accuracy: 0.6337INFO:tensorflow:For batch 81, loss is    0.74.\n",
      "INFO:tensorflow:For batch 81, accuracy is    0.63.\n",
      "5248/7352 [====================>.........] - ETA: 5s - loss: 0.9064 - accuracy: 0.6341INFO:tensorflow:For batch 82, loss is    0.72.\n",
      "INFO:tensorflow:For batch 82, accuracy is    0.63.\n",
      "5312/7352 [====================>.........] - ETA: 5s - loss: 0.9042 - accuracy: 0.6340INFO:tensorflow:For batch 83, loss is    0.65.\n",
      "INFO:tensorflow:For batch 83, accuracy is    0.64.\n",
      "5376/7352 [====================>.........] - ETA: 5s - loss: 0.9011 - accuracy: 0.6352INFO:tensorflow:For batch 84, loss is    0.62.\n",
      "INFO:tensorflow:For batch 84, accuracy is    0.64.\n",
      "5440/7352 [=====================>........] - ETA: 4s - loss: 0.8978 - accuracy: 0.6369INFO:tensorflow:For batch 85, loss is    0.59.\n",
      "INFO:tensorflow:For batch 85, accuracy is    0.64.\n",
      "5504/7352 [=====================>........] - ETA: 4s - loss: 0.8943 - accuracy: 0.6386INFO:tensorflow:For batch 86, loss is    0.70.\n",
      "INFO:tensorflow:For batch 86, accuracy is    0.64.\n",
      "5568/7352 [=====================>........] - ETA: 4s - loss: 0.8920 - accuracy: 0.6397INFO:tensorflow:For batch 87, loss is    0.70.\n",
      "INFO:tensorflow:For batch 87, accuracy is    0.64.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632/7352 [=====================>........] - ETA: 4s - loss: 0.8898 - accuracy: 0.6404INFO:tensorflow:For batch 88, loss is    0.83.\n",
      "INFO:tensorflow:For batch 88, accuracy is    0.64.\n",
      "5696/7352 [======================>.......] - ETA: 4s - loss: 0.8891 - accuracy: 0.6404INFO:tensorflow:For batch 89, loss is    0.70.\n",
      "INFO:tensorflow:For batch 89, accuracy is    0.64.\n",
      "5760/7352 [======================>.......] - ETA: 4s - loss: 0.8870 - accuracy: 0.6410INFO:tensorflow:For batch 90, loss is    0.67.\n",
      "INFO:tensorflow:For batch 90, accuracy is    0.64.\n",
      "5824/7352 [======================>.......] - ETA: 3s - loss: 0.8846 - accuracy: 0.6420INFO:tensorflow:For batch 91, loss is    0.72.\n",
      "INFO:tensorflow:For batch 91, accuracy is    0.64.\n",
      "5888/7352 [=======================>......] - ETA: 3s - loss: 0.8828 - accuracy: 0.6422INFO:tensorflow:For batch 92, loss is    0.70.\n",
      "INFO:tensorflow:For batch 92, accuracy is    0.64.\n",
      "5952/7352 [=======================>......] - ETA: 3s - loss: 0.8808 - accuracy: 0.6426INFO:tensorflow:For batch 93, loss is    0.76.\n",
      "INFO:tensorflow:For batch 93, accuracy is    0.64.\n",
      "6016/7352 [=======================>......] - ETA: 3s - loss: 0.8796 - accuracy: 0.6435INFO:tensorflow:For batch 94, loss is    0.72.\n",
      "INFO:tensorflow:For batch 94, accuracy is    0.64.\n",
      "6080/7352 [=======================>......] - ETA: 3s - loss: 0.8778 - accuracy: 0.6439INFO:tensorflow:For batch 95, loss is    0.42.\n",
      "INFO:tensorflow:For batch 95, accuracy is    0.65.\n",
      "6144/7352 [========================>.....] - ETA: 3s - loss: 0.8731 - accuracy: 0.6462INFO:tensorflow:For batch 96, loss is    0.69.\n",
      "INFO:tensorflow:For batch 96, accuracy is    0.65.\n",
      "6208/7352 [========================>.....] - ETA: 2s - loss: 0.8712 - accuracy: 0.6471INFO:tensorflow:For batch 97, loss is    0.58.\n",
      "INFO:tensorflow:For batch 97, accuracy is    0.65.\n",
      "6272/7352 [========================>.....] - ETA: 2s - loss: 0.8682 - accuracy: 0.6480INFO:tensorflow:For batch 98, loss is    0.71.\n",
      "INFO:tensorflow:For batch 98, accuracy is    0.65.\n",
      "6336/7352 [========================>.....] - ETA: 2s - loss: 0.8666 - accuracy: 0.6482INFO:tensorflow:For batch 99, loss is    0.53.\n",
      "INFO:tensorflow:For batch 99, accuracy is    0.65.\n",
      "6400/7352 [=========================>....] - ETA: 2s - loss: 0.8632 - accuracy: 0.6498INFO:tensorflow:For batch 100, loss is    0.52.\n",
      "INFO:tensorflow:For batch 100, accuracy is    0.65.\n",
      "6464/7352 [=========================>....] - ETA: 2s - loss: 0.8598 - accuracy: 0.6508INFO:tensorflow:For batch 101, loss is    0.67.\n",
      "INFO:tensorflow:For batch 101, accuracy is    0.65.\n",
      "6528/7352 [=========================>....] - ETA: 2s - loss: 0.8579 - accuracy: 0.6515INFO:tensorflow:For batch 102, loss is    0.58.\n",
      "INFO:tensorflow:For batch 102, accuracy is    0.65.\n",
      "6592/7352 [=========================>....] - ETA: 2s - loss: 0.8553 - accuracy: 0.6523INFO:tensorflow:For batch 103, loss is    0.65.\n",
      "INFO:tensorflow:For batch 103, accuracy is    0.65.\n",
      "6656/7352 [==========================>...] - ETA: 1s - loss: 0.8533 - accuracy: 0.6526INFO:tensorflow:For batch 104, loss is    0.58.\n",
      "INFO:tensorflow:For batch 104, accuracy is    0.65.\n",
      "6720/7352 [==========================>...] - ETA: 1s - loss: 0.8507 - accuracy: 0.6533INFO:tensorflow:For batch 105, loss is    0.65.\n",
      "INFO:tensorflow:For batch 105, accuracy is    0.65.\n",
      "6784/7352 [==========================>...] - ETA: 1s - loss: 0.8488 - accuracy: 0.6542INFO:tensorflow:For batch 106, loss is    0.55.\n",
      "INFO:tensorflow:For batch 106, accuracy is    0.65.\n",
      "6848/7352 [==========================>...] - ETA: 1s - loss: 0.8460 - accuracy: 0.6544INFO:tensorflow:For batch 107, loss is    0.48.\n",
      "INFO:tensorflow:For batch 107, accuracy is    0.66.\n",
      "6912/7352 [===========================>..] - ETA: 1s - loss: 0.8427 - accuracy: 0.6555INFO:tensorflow:For batch 108, loss is    0.65.\n",
      "INFO:tensorflow:For batch 108, accuracy is    0.66.\n",
      "6976/7352 [===========================>..] - ETA: 1s - loss: 0.8409 - accuracy: 0.6558INFO:tensorflow:For batch 109, loss is    0.60.\n",
      "INFO:tensorflow:For batch 109, accuracy is    0.66.\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.8387 - accuracy: 0.6564INFO:tensorflow:For batch 110, loss is    0.51.\n",
      "INFO:tensorflow:For batch 110, accuracy is    0.66.\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.8358 - accuracy: 0.6575INFO:tensorflow:For batch 111, loss is    0.49.\n",
      "INFO:tensorflow:For batch 111, accuracy is    0.66.\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.8327 - accuracy: 0.6585INFO:tensorflow:For batch 112, loss is    0.49.\n",
      "INFO:tensorflow:For batch 112, accuracy is    0.66.\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.8297 - accuracy: 0.6597INFO:tensorflow:For batch 113, loss is    0.51.\n",
      "INFO:tensorflow:For batch 113, accuracy is    0.66.\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.8269 - accuracy: 0.6608INFO:tensorflow:For batch 114, loss is    0.60.\n",
      "INFO:tensorflow:For batch 114, accuracy is    0.66.\n",
      "INFO:tensorflow:weights of 1 layers for epoch2 is [array([[ 0.0025579 ,  0.0476046 , -0.05471374, ..., -0.11054987,\n",
      "        -0.07699066, -0.12749286],\n",
      "       [ 0.00243663, -0.10550641,  0.04557263, ...,  0.01138013,\n",
      "        -0.01886239,  0.06096701],\n",
      "       [-0.01525388,  0.07290805, -0.0721304 , ..., -0.0993301 ,\n",
      "        -0.0719621 , -0.02406269],\n",
      "       ...,\n",
      "       [-0.06823511, -0.04367474, -0.12354995, ..., -0.12054759,\n",
      "        -0.24952984,  0.03728886],\n",
      "       [ 0.01452417,  0.0156408 ,  0.07129108, ..., -0.04297839,\n",
      "         0.22151497, -0.00472194],\n",
      "       [-0.18628785,  0.1357153 , -0.04697465, ..., -0.17337146,\n",
      "         0.11357489, -0.06492875]], dtype=float32), array([[-0.03419933,  0.0609238 , -0.00121802, ..., -0.13952988,\n",
      "        -0.07708095, -0.02165006],\n",
      "       [-0.13053365,  0.1051646 , -0.0361954 , ...,  0.12876786,\n",
      "         0.02237402,  0.04946002],\n",
      "       [ 0.05119341, -0.04802753, -0.00053809, ..., -0.02364071,\n",
      "        -0.06022896, -0.02695918],\n",
      "       ...,\n",
      "       [-0.01705891,  0.06148989, -0.02448411, ...,  0.0617702 ,\n",
      "         0.04886625,  0.04360534],\n",
      "       [ 0.06380711,  0.03453282,  0.00593637, ...,  0.01240983,\n",
      "        -0.02428208, -0.00292242],\n",
      "       [-0.04525638, -0.04744138,  0.07220598, ..., -0.08184648,\n",
      "         0.03532135, -0.06831714]], dtype=float32), array([ 1.02576753e-03,  2.60410784e-03,  2.31077671e-02,  3.33451503e-03,\n",
      "        2.83239745e-02, -1.09001184e-02, -1.41107785e-02,  3.81744392e-02,\n",
      "       -8.47757701e-03, -3.97523306e-03,  1.49185862e-02,  1.36636915e-02,\n",
      "       -1.70329418e-02, -1.96885504e-03,  1.86895002e-02, -1.54287191e-02,\n",
      "       -5.98444697e-03,  5.90831216e-04,  2.58411607e-03,  1.71608832e-02,\n",
      "        1.20281447e-02,  3.34971286e-02,  2.50051413e-02, -5.70006622e-03,\n",
      "       -3.15013784e-03,  2.25592125e-02, -1.74809657e-02,  2.38106158e-02,\n",
      "        2.30099773e-03,  4.23033871e-02, -8.31667520e-03, -7.24941073e-03,\n",
      "       -5.51458495e-03,  2.83626653e-02,  2.05126386e-02, -6.85081910e-03,\n",
      "        2.15003211e-02,  2.68544015e-02,  2.32919287e-02,  4.32630442e-03,\n",
      "        1.25655690e-02,  1.64723601e-02,  1.63879376e-02,  2.24080086e-02,\n",
      "        2.69549862e-02, -2.46236604e-02,  1.25387656e-02,  2.13286076e-02,\n",
      "       -3.40110958e-02,  1.20310783e-02,  7.40802474e-03,  1.40849631e-02,\n",
      "        3.68792750e-02,  2.68669389e-02,  1.08380215e-02,  1.69384535e-02,\n",
      "        1.36324260e-02,  8.92369915e-03,  1.18056163e-02, -4.87724785e-04,\n",
      "       -2.26556398e-02,  1.37950322e-02, -1.69027541e-02,  2.06279512e-02,\n",
      "        2.26786919e-02,  9.32184793e-03,  1.14490958e-02,  2.36733258e-02,\n",
      "        1.72959827e-02,  1.02548981e-02,  5.48852282e-03,  4.13098969e-02,\n",
      "       -5.14301192e-03,  1.79389399e-02,  5.06310305e-03, -2.78826635e-02,\n",
      "        6.33612648e-03,  1.81484781e-02,  1.73027106e-02,  1.67430453e-02,\n",
      "        1.88965145e-02,  2.27665529e-02,  1.13968411e-02,  5.03860507e-03,\n",
      "       -2.66673435e-02,  3.81417051e-02,  5.97058702e-03,  2.33033765e-03,\n",
      "       -8.52334034e-03,  5.52977202e-03,  2.41624587e-03,  3.09808310e-02,\n",
      "        4.14913695e-04,  2.79338621e-02,  3.17088962e-02,  4.11585793e-02,\n",
      "        3.82458046e-03,  2.32829293e-03, -5.95679739e-05, -1.75276417e-02,\n",
      "        9.97089565e-01,  1.00453591e+00,  1.03393269e+00,  1.00892627e+00,\n",
      "        1.03368104e+00,  9.98644173e-01,  9.94162440e-01,  1.04910827e+00,\n",
      "        9.92098272e-01,  9.94444013e-01,  1.01354408e+00,  1.01327908e+00,\n",
      "        9.80351686e-01,  1.01588988e+00,  1.02642763e+00,  9.83321011e-01,\n",
      "        9.99586344e-01,  1.01294577e+00,  1.00127780e+00,  1.02448499e+00,\n",
      "        1.01855087e+00,  1.03573167e+00,  1.02606225e+00,  9.98291731e-01,\n",
      "        1.00427401e+00,  1.01746035e+00,  9.83620822e-01,  1.05357420e+00,\n",
      "        1.00379920e+00,  1.04385972e+00,  1.00199890e+00,  1.01547301e+00,\n",
      "        9.98905361e-01,  1.02877498e+00,  1.03161871e+00,  9.95156169e-01,\n",
      "        1.02038884e+00,  1.02917695e+00,  1.04853249e+00,  1.00907564e+00,\n",
      "        1.01350689e+00,  1.05486119e+00,  1.02115059e+00,  1.04230690e+00,\n",
      "        1.03627455e+00,  9.78077888e-01,  1.02367115e+00,  1.03790069e+00,\n",
      "        9.69101310e-01,  1.01759529e+00,  1.01495361e+00,  1.02505076e+00,\n",
      "        1.07507873e+00,  1.03447115e+00,  1.00958359e+00,  1.01868737e+00,\n",
      "        1.01594281e+00,  1.00802922e+00,  1.03538167e+00,  1.00323761e+00,\n",
      "        9.73084211e-01,  1.03214669e+00,  1.00816607e+00,  1.02413404e+00,\n",
      "        1.02563858e+00,  1.02692926e+00,  1.01181674e+00,  1.01619196e+00,\n",
      "        1.02426898e+00,  1.01354277e+00,  1.00531852e+00,  1.04712892e+00,\n",
      "        1.00273848e+00,  1.02687705e+00,  1.00664783e+00,  9.77949381e-01,\n",
      "        1.00912070e+00,  1.01776111e+00,  1.01547992e+00,  1.01780665e+00,\n",
      "        1.03093588e+00,  1.02534628e+00,  1.01539850e+00,  1.00600088e+00,\n",
      "        9.81957436e-01,  1.03644443e+00,  1.00763237e+00,  1.00702250e+00,\n",
      "        9.90595341e-01,  1.00047684e+00,  9.97609556e-01,  1.03151357e+00,\n",
      "        1.00333893e+00,  1.03017128e+00,  1.03949904e+00,  1.06230450e+00,\n",
      "        1.00749707e+00,  1.01230764e+00,  1.01674652e+00,  9.82496440e-01,\n",
      "       -9.50638950e-03, -2.68712873e-03,  1.58715136e-02,  8.31899513e-03,\n",
      "       -1.47527913e-02, -5.99526353e-02,  2.94605158e-02, -9.68326814e-04,\n",
      "       -2.81879511e-02,  1.82306468e-02, -2.62964219e-02, -6.95040263e-03,\n",
      "       -3.58578041e-02, -1.92696899e-02,  8.94398335e-03,  1.53708216e-02,\n",
      "        3.03129014e-02,  7.19011109e-03,  2.85910424e-02, -2.69729681e-02,\n",
      "       -8.23794212e-03, -2.14353204e-02, -6.02381071e-03, -1.00470986e-02,\n",
      "       -1.71874985e-02, -4.09455486e-02, -4.26598042e-02,  3.86641398e-02,\n",
      "       -4.10620123e-02,  1.23364385e-02, -2.46038865e-02,  1.32976882e-02,\n",
      "        9.11362877e-04, -2.71631759e-02,  9.66244191e-03,  2.09050421e-02,\n",
      "       -1.58333238e-02, -3.50748450e-02, -5.41178044e-03,  4.00980189e-02,\n",
      "       -1.39542297e-02, -6.25257194e-03,  9.33313556e-03, -1.67897046e-02,\n",
      "        1.05890902e-02, -4.52250503e-02, -1.01340236e-02,  1.03923948e-02,\n",
      "       -3.69982310e-02,  1.38756661e-02,  2.29745209e-02, -3.58146033e-03,\n",
      "        1.64447147e-02, -7.30349869e-03, -2.82087456e-02, -1.94080435e-02,\n",
      "       -2.60432735e-02,  3.09959687e-02,  1.32079916e-02,  4.23146039e-03,\n",
      "       -3.21254693e-02, -5.56074409e-03,  1.47128571e-03, -2.33837683e-02,\n",
      "       -2.38411538e-02,  2.18534321e-02,  7.92788621e-03, -3.17628980e-02,\n",
      "       -2.70803291e-02, -1.72262806e-02, -4.75980155e-02, -1.18282977e-02,\n",
      "       -2.60151494e-02, -2.09203120e-02,  3.25656161e-02,  2.45732125e-02,\n",
      "       -3.40589099e-02, -4.86113410e-03,  4.03510593e-03, -1.84248399e-03,\n",
      "       -1.59901585e-02, -6.37808349e-03, -1.60868987e-02,  1.27858678e-02,\n",
      "        1.95580628e-02, -1.27142314e-02, -2.03185566e-02,  3.34551558e-02,\n",
      "       -2.56309994e-02,  2.41404660e-02,  8.89132172e-03,  1.57348663e-02,\n",
      "        2.11941190e-02,  2.15595104e-02,  1.26737915e-02, -8.00042506e-03,\n",
      "        2.82823686e-02,  1.44385397e-02,  1.56392611e-03,  8.86239856e-03,\n",
      "        3.25939828e-03,  8.22040159e-03,  1.46426801e-02,  1.31056225e-03,\n",
      "        3.58394720e-02, -9.40968841e-03, -1.52626773e-02,  3.91163789e-02,\n",
      "       -1.31782396e-02, -5.36920642e-03,  1.36866383e-02,  1.96355283e-02,\n",
      "       -1.78729743e-02, -3.97738861e-03,  3.14036869e-02, -1.90041047e-02,\n",
      "        7.82763527e-05,  1.30410492e-02,  5.09323669e-04,  2.90108006e-02,\n",
      "        1.60649307e-02,  2.14191992e-02,  2.65347194e-02,  3.13711865e-03,\n",
      "       -3.45400744e-03,  1.99829061e-02, -1.58737879e-02,  6.61678463e-02,\n",
      "        7.38379080e-03,  3.85780819e-02, -1.36252120e-03,  1.38049712e-02,\n",
      "       -6.30856911e-03,  2.62790583e-02,  1.81382224e-02, -9.75069590e-03,\n",
      "        2.41666380e-02,  3.19173634e-02,  3.84896249e-02,  1.20684365e-02,\n",
      "        1.36203663e-02,  4.20092084e-02,  1.33249164e-02,  2.31546126e-02,\n",
      "        3.42794396e-02, -2.49538757e-02,  4.96878102e-03,  2.88460273e-02,\n",
      "       -3.26989144e-02,  1.61314048e-02,  1.07015148e-02,  1.71898659e-02,\n",
      "        7.08719715e-02,  3.21948081e-02,  1.49386581e-02,  2.08012629e-02,\n",
      "        2.99055912e-02,  7.48366211e-03,  3.14905122e-02, -1.24468864e-03,\n",
      "       -2.39446536e-02,  1.97174717e-02, -1.85955595e-03,  1.54376198e-02,\n",
      "        1.19629782e-02,  1.71172842e-02,  6.16680924e-03,  2.22082902e-02,\n",
      "        1.44990645e-02,  1.35101853e-02,  1.20547265e-02,  5.01473323e-02,\n",
      "       -1.61164941e-03,  2.26728935e-02,  1.43149840e-02, -2.36016922e-02,\n",
      "        1.08040683e-02,  1.13288928e-02,  1.78410765e-02,  2.19903719e-02,\n",
      "        2.52031125e-02,  1.39639210e-02,  1.57392230e-02, -4.79999604e-03,\n",
      "       -1.34034539e-02,  4.92750816e-02,  7.30656553e-03,  4.47532674e-03,\n",
      "       -6.95040869e-03,  4.95966664e-03,  1.48984441e-03,  2.60569640e-02,\n",
      "        2.34779669e-03,  2.69093495e-02,  4.60686348e-02,  6.40873164e-02,\n",
      "        5.92342857e-03,  3.10154492e-03,  3.46112601e-03, -1.87905133e-02],\n",
      "      dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:weights of 2 layers for epoch2 is []\n",
      "INFO:tensorflow:weights of 3 layers for epoch2 is [array([[-0.03027035,  0.15037489,  0.05924832, ..., -0.10179086,\n",
      "         0.01797631,  0.03865792],\n",
      "       [-0.04638569, -0.15528405, -0.08757195, ...,  0.0820201 ,\n",
      "        -0.15740865,  0.0700791 ],\n",
      "       [ 0.08098748,  0.2175524 , -0.06968189, ...,  0.13001941,\n",
      "         0.16675507, -0.03299479],\n",
      "       ...,\n",
      "       [ 0.14714745,  0.06715877, -0.22539295, ..., -0.11136068,\n",
      "         0.05120365,  0.10976861],\n",
      "       [ 0.01023075,  0.03899583, -0.13209642, ..., -0.11325189,\n",
      "         0.1021707 , -0.00755857],\n",
      "       [ 0.10243446,  0.17806819, -0.04939399, ...,  0.06495371,\n",
      "        -0.07117604,  0.05858503]], dtype=float32), array([-0.00288643,  0.00322332,  0.09194191,  0.10801987, -0.04420231,\n",
      "        0.02928804,  0.02425034, -0.03129919, -0.02911998, -0.0074983 ,\n",
      "        0.07915429,  0.06522533,  0.0032937 ,  0.01503648,  0.07541277,\n",
      "       -0.00554985,  0.0017826 ,  0.00648282,  0.11082613,  0.05050201,\n",
      "       -0.00537952,  0.09058273,  0.0044709 , -0.00747649,  0.03181936,\n",
      "        0.10095243,  0.05449577,  0.02268453,  0.03707619, -0.00314182,\n",
      "        0.01754292, -0.01091307, -0.00641311,  0.01143424,  0.03991254,\n",
      "       -0.03069192, -0.02877232,  0.06303477, -0.00191174, -0.01408351,\n",
      "        0.01806747,  0.04050561,  0.05270901, -0.01369561,  0.03789534,\n",
      "       -0.00596528,  0.08546412, -0.00173989, -0.01067161,  0.02971816,\n",
      "       -0.00191472,  0.02379184, -0.02604936,  0.02617664,  0.08212826,\n",
      "        0.04662405,  0.01014867,  0.02834938,  0.04861009, -0.01016666,\n",
      "       -0.03678493, -0.02320239, -0.01960984,  0.06030711,  0.01731288,\n",
      "        0.00589754,  0.0339807 ,  0.00815021,  0.02130567,  0.02245258,\n",
      "        0.05292961,  0.03146226,  0.01604138, -0.0723438 , -0.00590647,\n",
      "        0.04709685,  0.01090125,  0.0045881 ,  0.00484266,  0.01220129,\n",
      "        0.00450452,  0.00324179, -0.00526438,  0.04595933,  0.02464227,\n",
      "        0.01254811, -0.01379765, -0.0230126 ,  0.07635054,  0.00060804,\n",
      "       -0.00526321,  0.04615884,  0.06767095,  0.04945544, -0.02156581,\n",
      "        0.05222016,  0.01215448,  0.02956435,  0.06065044, -0.04925036],\n",
      "      dtype=float32)]\n",
      "INFO:tensorflow:weights of 4 layers for epoch2 is [array([[ 1.82351489e-02,  9.32330340e-02,  1.86898053e-01,\n",
      "        -7.38131627e-02, -9.85326897e-03, -1.77392453e-01],\n",
      "       [-2.08630532e-01, -1.32490978e-01, -4.36202921e-02,\n",
      "        -3.92610244e-02,  2.60038096e-02,  1.65902853e-01],\n",
      "       [ 1.55281812e-01,  1.14883803e-01,  1.58008084e-01,\n",
      "         1.18609697e-01,  1.88958198e-01, -2.47564256e-01],\n",
      "       [ 2.85795003e-01, -8.41978937e-03, -4.99245785e-02,\n",
      "        -2.32847646e-01,  2.78221313e-02, -3.36082876e-01],\n",
      "       [-5.38952537e-02,  9.30090770e-02, -2.43624613e-01,\n",
      "         1.13014698e-01, -8.69235098e-02,  2.39572644e-01],\n",
      "       [-6.58861846e-02,  1.08866587e-01,  1.39031053e-01,\n",
      "        -1.24542952e-01, -2.03967348e-01, -3.79985958e-01],\n",
      "       [ 1.00284414e-02,  6.09108806e-02, -8.11166763e-02,\n",
      "        -1.61387667e-01,  1.34235546e-01,  7.93353841e-02],\n",
      "       [-2.21770316e-01,  1.51013359e-02,  2.26787701e-01,\n",
      "        -1.46058127e-01, -2.37452704e-02,  2.94322744e-02],\n",
      "       [-6.82195574e-02, -1.29525930e-01,  2.27166086e-01,\n",
      "         2.85105556e-02, -5.81021383e-02, -2.25554481e-01],\n",
      "       [-2.37821341e-01,  2.04363853e-01,  9.70453098e-02,\n",
      "         6.14024550e-02,  1.31905638e-02,  2.47447178e-01],\n",
      "       [ 2.22025022e-01,  8.13166052e-02,  2.15084672e-01,\n",
      "        -9.74096656e-02,  1.18957490e-01,  6.92307809e-03],\n",
      "       [ 6.91528320e-02, -5.23038507e-02,  7.94539377e-02,\n",
      "        -2.80044138e-01, -2.06620827e-01, -3.42626154e-01],\n",
      "       [ 1.56154767e-01, -1.54809013e-01, -3.55356038e-02,\n",
      "        -1.21834747e-01, -9.02166665e-02,  2.11519629e-01],\n",
      "       [-2.19406411e-01, -2.12615997e-01, -3.14298533e-02,\n",
      "        -6.15868382e-02, -2.01716155e-01,  1.99259743e-01],\n",
      "       [ 2.18610764e-01, -1.11644447e-01,  1.92019224e-01,\n",
      "        -2.52269238e-01, -2.38634899e-01, -3.90011042e-01],\n",
      "       [-2.57826686e-01, -8.24937597e-02, -4.64510499e-03,\n",
      "         2.14953378e-01,  1.55413762e-01,  7.80157447e-02],\n",
      "       [-1.66806474e-01, -4.29839790e-02,  1.98413178e-01,\n",
      "         6.83401227e-02,  1.58488289e-01, -1.01666763e-01],\n",
      "       [ 9.65280905e-02,  1.35818765e-01, -6.87465519e-02,\n",
      "         1.62518904e-01, -6.67437837e-02, -2.80800968e-01],\n",
      "       [ 5.72071783e-02, -1.28741622e-01,  5.08491918e-02,\n",
      "        -8.30525607e-02, -3.60351317e-02, -3.74304712e-01],\n",
      "       [ 3.10835838e-02,  1.09345734e-01,  2.28466280e-02,\n",
      "        -4.78402115e-02,  2.49904662e-01, -2.91489869e-01],\n",
      "       [-1.57759607e-01,  6.99593574e-02, -3.97977717e-02,\n",
      "         1.22034311e-01, -1.98208958e-01,  1.24290407e-01],\n",
      "       [ 1.62409380e-01,  1.43288836e-01, -2.07310155e-01,\n",
      "        -4.83518876e-02,  1.14459589e-01, -3.31032276e-01],\n",
      "       [-1.81918666e-01, -1.70204207e-01, -1.35118514e-01,\n",
      "         6.45153448e-02, -6.13778597e-03, -2.35594407e-01],\n",
      "       [ 8.63547474e-02, -2.25321963e-01, -2.26615921e-01,\n",
      "         9.95241106e-02, -1.71651945e-01, -2.72528052e-01],\n",
      "       [-8.26662853e-02, -5.35026528e-02, -1.78638145e-01,\n",
      "         3.58180851e-02,  1.77224316e-02,  2.10958738e-02],\n",
      "       [ 2.10761249e-01, -6.62442744e-02,  1.84327841e-01,\n",
      "        -2.19272785e-02,  1.44043744e-01, -3.16529870e-01],\n",
      "       [ 1.44604832e-01, -7.19032213e-02, -2.63314098e-01,\n",
      "        -1.63441584e-01, -2.45114532e-03,  1.14551120e-01],\n",
      "       [ 2.44760364e-02,  8.20050687e-02,  1.91442743e-01,\n",
      "        -5.03056459e-02, -1.01843476e-01,  1.03376612e-01],\n",
      "       [-2.90269136e-01, -1.89720780e-01, -2.02381998e-01,\n",
      "        -1.13985896e-01,  7.64284730e-02,  7.55746812e-02],\n",
      "       [-1.16495945e-01,  1.39917821e-01,  1.07946433e-01,\n",
      "         9.33114961e-02,  2.23892838e-01, -3.85900922e-02],\n",
      "       [-5.58559895e-02,  1.59024462e-01, -1.93606138e-01,\n",
      "        -1.29042804e-01, -1.23457700e-01,  2.05128610e-01],\n",
      "       [-2.30029240e-01,  2.66443705e-04,  1.74918547e-01,\n",
      "         8.02669302e-02, -2.38573000e-01,  6.25554472e-02],\n",
      "       [-2.13955596e-01, -1.41879782e-01,  5.49116731e-02,\n",
      "         1.21476389e-01, -2.45465472e-01,  1.68239716e-02],\n",
      "       [-1.03959091e-01,  8.48196372e-02, -1.79086834e-01,\n",
      "         1.67788833e-01, -2.71193981e-01,  2.52310902e-01],\n",
      "       [ 8.52093548e-02, -1.46066204e-01,  7.13696256e-02,\n",
      "        -1.36917114e-01, -1.76825136e-01,  2.25802571e-01],\n",
      "       [ 7.29984604e-05,  1.62664026e-01, -1.29802793e-01,\n",
      "         1.02608211e-01, -1.66664258e-01, -9.15492773e-02],\n",
      "       [ 1.23895340e-01,  9.46152061e-02, -1.81656197e-01,\n",
      "         1.52221277e-01, -2.26169512e-01,  1.53180584e-01],\n",
      "       [ 2.55083799e-01,  1.54507697e-01,  6.54171705e-02,\n",
      "        -3.66870791e-01, -1.29020765e-01, -1.66981161e-01],\n",
      "       [ 8.53731111e-02, -2.00773835e-01, -2.84449756e-01,\n",
      "         1.88101009e-01, -2.22784355e-01,  2.15647474e-01],\n",
      "       [-3.92152704e-02, -1.13778524e-01,  7.81405531e-03,\n",
      "         2.21221656e-01, -2.19074823e-02,  5.22624701e-02],\n",
      "       [-1.99795678e-01, -5.57470508e-02, -2.32130542e-01,\n",
      "         2.09136248e-01,  2.70521402e-01, -2.16369376e-01],\n",
      "       [-7.29143918e-02, -3.25853974e-01, -1.71863511e-01,\n",
      "         1.61080286e-01,  5.33245392e-02,  4.65231854e-03],\n",
      "       [ 2.34291200e-02,  1.33006811e-01, -2.27683559e-01,\n",
      "        -2.11130932e-01,  1.00379176e-01,  7.63938054e-02],\n",
      "       [-2.94451982e-01, -1.51317030e-01, -2.94543475e-01,\n",
      "         2.29801148e-01, -2.02767819e-01, -1.24797665e-01],\n",
      "       [-1.71304494e-01, -2.53128916e-01, -2.86017984e-01,\n",
      "         7.48662576e-02,  1.13669857e-01, -3.12429935e-01],\n",
      "       [-4.49861884e-02,  2.53626883e-01,  1.80933565e-01,\n",
      "         1.08628377e-01,  1.42816052e-01, -1.48902401e-01],\n",
      "       [ 1.24974258e-01, -2.05186963e-01, -4.97053303e-02,\n",
      "         5.75618297e-02,  1.34771481e-01, -1.24214977e-01],\n",
      "       [ 2.35941783e-01,  1.50589600e-01, -3.91825242e-03,\n",
      "        -2.55119242e-02, -1.35507047e-01,  8.98606107e-02],\n",
      "       [ 8.19336716e-03,  2.24400327e-01, -6.96614683e-02,\n",
      "         8.49415064e-02, -2.57496864e-01, -1.18627138e-01],\n",
      "       [ 1.49097547e-01,  9.24159288e-02, -1.64187491e-01,\n",
      "         1.60299301e-01,  1.82555079e-01, -8.71064961e-02],\n",
      "       [-9.36234817e-02,  9.22759809e-03, -8.54081213e-02,\n",
      "        -2.32013792e-01,  1.46836743e-01,  1.45019874e-01],\n",
      "       [-9.78106931e-02, -5.90345450e-03, -2.07284823e-01,\n",
      "         1.18727975e-01, -1.04110859e-01,  2.60873049e-01],\n",
      "       [-1.32953092e-01,  8.36783126e-02, -1.73398152e-01,\n",
      "         1.64526001e-01, -2.41110682e-01,  5.54731488e-02],\n",
      "       [-2.40901466e-02, -7.73088783e-02, -2.15815917e-01,\n",
      "         4.60889824e-02,  1.23892158e-01,  6.22913837e-02],\n",
      "       [ 1.10138588e-01, -3.16348523e-02,  1.37112528e-01,\n",
      "        -1.31305233e-01, -3.20417546e-02, -2.75434315e-01],\n",
      "       [ 1.91174924e-01, -1.55577838e-01,  2.55809158e-01,\n",
      "         1.10657744e-01, -2.35307038e-01, -3.48475367e-01],\n",
      "       [-8.70144516e-02, -2.67073542e-01, -6.42490759e-02,\n",
      "         1.19529746e-01, -1.37427494e-01,  2.46898025e-01],\n",
      "       [ 1.64151475e-01, -5.10729142e-02, -2.13225801e-02,\n",
      "         7.72250304e-03, -5.28353490e-02,  2.91786846e-02],\n",
      "       [-1.40897974e-01, -6.13520332e-02, -2.89672226e-01,\n",
      "         7.06050247e-02,  7.79458806e-02,  4.53611985e-02],\n",
      "       [ 1.42569263e-02,  1.76344946e-01,  1.56603694e-01,\n",
      "        -8.26778859e-02, -9.95799974e-02, -2.31358245e-01],\n",
      "       [-2.11001217e-01,  5.99062815e-02,  4.14163880e-02,\n",
      "         1.39646471e-01, -8.19541421e-03, -1.07733920e-01],\n",
      "       [ 3.82004641e-02, -1.93464860e-01,  5.26427552e-02,\n",
      "         1.54569834e-01, -2.12500528e-01,  1.71148226e-01],\n",
      "       [-2.78452598e-02, -1.77871078e-01, -2.41191179e-01,\n",
      "        -1.53295070e-01, -1.75988600e-01,  5.12788780e-02],\n",
      "       [ 1.38555422e-01,  2.31251970e-01,  2.29343250e-01,\n",
      "        -3.50303233e-01, -3.22993211e-02, -2.12698549e-01],\n",
      "       [ 7.01708421e-02, -4.13976014e-02, -1.05617814e-01,\n",
      "         5.28052300e-02, -1.52133986e-01,  2.63225138e-01],\n",
      "       [-2.23581389e-01, -9.81437191e-02,  2.66789719e-02,\n",
      "         1.30105600e-01, -1.59208998e-01,  2.19574690e-01],\n",
      "       [-5.50543331e-02,  1.07120670e-01,  1.71770290e-01,\n",
      "        -7.36380890e-02,  3.07142418e-02, -3.20708513e-01],\n",
      "       [-4.64158468e-02,  4.21222076e-02,  6.39586449e-02,\n",
      "        -3.57116631e-04,  1.93940811e-02,  1.56083971e-01],\n",
      "       [ 1.60996035e-01, -1.65994212e-01,  3.32610607e-02,\n",
      "         2.85222419e-02,  2.60786295e-01,  3.75200100e-02],\n",
      "       [-1.99784145e-01, -9.92723480e-02,  1.45239949e-01,\n",
      "         1.78575903e-01,  2.63326198e-01, -6.57502413e-02],\n",
      "       [ 2.28877231e-01, -1.46792412e-01,  7.17810169e-02,\n",
      "        -1.96804732e-01, -1.67453781e-01,  1.91898718e-01],\n",
      "       [-2.17615530e-01, -2.02611789e-01,  3.06574516e-02,\n",
      "        -2.43585736e-01, -6.78856000e-02,  2.36241773e-01],\n",
      "       [-1.63859166e-02,  2.48350322e-01,  8.45891014e-02,\n",
      "        -1.82455823e-01, -1.47519216e-01,  2.46764831e-02],\n",
      "       [-2.30323911e-01,  1.98421791e-01, -2.52168830e-02,\n",
      "         3.24567594e-02, -7.22981393e-02,  1.51842628e-02],\n",
      "       [-1.29036531e-01, -1.18878298e-01, -1.02318004e-01,\n",
      "        -6.84191287e-02,  2.37373803e-02,  1.27276897e-01],\n",
      "       [-3.15782391e-02, -2.70149887e-01,  9.17968526e-03,\n",
      "         2.07037911e-01,  2.47856870e-01, -2.23505542e-01],\n",
      "       [-1.69816703e-01, -2.21966058e-02,  7.79961795e-02,\n",
      "        -1.54936939e-01,  2.28059188e-01, -2.32792705e-01],\n",
      "       [-1.48764074e-01,  3.01041249e-02,  4.80795242e-02,\n",
      "        -2.40586087e-01, -2.69362688e-01, -1.25336409e-01],\n",
      "       [ 1.80943578e-01,  1.27506107e-01, -1.61746398e-01,\n",
      "        -7.89499134e-02, -9.44325179e-02, -2.29857966e-01],\n",
      "       [-1.14293739e-01,  1.65557981e-01, -3.77504192e-02,\n",
      "         1.29282009e-02,  2.27160513e-01, -2.46783048e-01],\n",
      "       [-1.79105014e-01,  6.62944792e-03, -2.27394477e-01,\n",
      "        -1.33166045e-01,  7.86041915e-02,  1.00786924e-01],\n",
      "       [ 2.28159741e-01,  2.99719051e-02, -5.32571003e-02,\n",
      "         1.63590699e-01, -2.17264891e-01,  1.15051009e-01],\n",
      "       [-9.10423696e-02,  2.11596832e-01, -3.27461548e-02,\n",
      "         7.03782588e-02, -2.66608119e-01,  2.29217485e-01],\n",
      "       [ 9.06068534e-02,  2.45542377e-01, -1.83712766e-01,\n",
      "        -2.62034059e-01, -1.82678252e-01, -1.36693567e-01],\n",
      "       [ 2.98610572e-02,  1.32808149e-01,  1.09684251e-01,\n",
      "        -2.68922329e-01, -9.42987725e-02, -4.57887352e-02],\n",
      "       [ 2.66237464e-03,  1.63593054e-01, -2.27566913e-01,\n",
      "         1.32234752e-01, -3.89741315e-03, -3.01061213e-01],\n",
      "       [ 9.75986943e-02,  3.34433615e-02, -1.19662195e-01,\n",
      "         2.33449310e-01, -1.04741983e-01,  2.08668590e-01],\n",
      "       [-1.57510519e-01,  1.75787017e-01, -4.74690692e-04,\n",
      "        -1.76856577e-01, -3.11453819e-01,  2.02066693e-02],\n",
      "       [ 2.43751809e-01, -1.72482923e-01, -8.25236440e-02,\n",
      "         1.71796784e-01,  2.03308791e-01, -3.98498893e-01],\n",
      "       [-1.12298645e-01, -1.94631666e-01,  7.82513991e-02,\n",
      "        -1.29343599e-01, -7.27583095e-02,  2.35955268e-01],\n",
      "       [ 2.80954838e-02,  1.01961508e-01, -1.35955840e-01,\n",
      "         9.88568142e-02, -1.36426494e-01, -2.58847266e-01],\n",
      "       [-1.70458034e-01, -2.86616296e-01, -1.12375207e-01,\n",
      "        -1.65342316e-02,  2.22853228e-01, -2.27521524e-01],\n",
      "       [ 2.04994529e-01,  1.64021365e-02, -2.25999266e-01,\n",
      "        -2.83218861e-01,  1.87992215e-01, -1.64146245e-01],\n",
      "       [ 2.22572628e-02, -4.58731242e-02, -1.70840651e-01,\n",
      "        -2.31367096e-01, -2.11131543e-01,  1.42297417e-01],\n",
      "       [-1.51125476e-01,  9.63025838e-02,  1.78103879e-01,\n",
      "        -1.16792470e-01, -9.24926624e-02, -6.18987530e-02],\n",
      "       [ 7.07453638e-02, -4.49880622e-02, -5.33433482e-02,\n",
      "        -1.98529363e-01, -2.97914475e-01,  2.42891327e-01],\n",
      "       [ 1.97048709e-02, -1.61128059e-01, -1.31446093e-01,\n",
      "         3.60687003e-02, -1.36764973e-01, -3.54199797e-01],\n",
      "       [ 8.89055133e-02,  2.08201647e-01, -3.80391488e-03,\n",
      "         1.41131774e-01,  1.86026856e-01, -1.12161137e-01],\n",
      "       [ 1.73176974e-01,  3.21825454e-03, -2.37289397e-03,\n",
      "        -3.15402858e-02, -2.73125675e-02,  2.56998539e-01],\n",
      "       [ 1.09383792e-01,  5.88924484e-03, -4.94489372e-02,\n",
      "         6.09525517e-02, -9.71124247e-02,  7.85944462e-02]], dtype=float32), array([ 0.05304702, -0.01986416, -0.0040864 , -0.0492175 ,  0.02523704,\n",
      "       -0.0362945 ], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The average loss for epoch 2 is    0.83 and accuracy is    0.66.\n",
      "7352/7352 [==============================] - 20s 3ms/sample - loss: 0.8251 - accuracy: 0.6610\n",
      "Epoch 4/5\n",
      "INFO:tensorflow:For batch 0, loss is    0.47.\n",
      "INFO:tensorflow:For batch 0, accuracy is    0.84.\n",
      "  64/7352 [..............................] - ETA: 27s - loss: 0.4711 - accuracy: 0.8438INFO:tensorflow:For batch 1, loss is    0.62.\n",
      "INFO:tensorflow:For batch 1, accuracy is    0.79.\n",
      " 128/7352 [..............................] - ETA: 26s - loss: 0.5439 - accuracy: 0.7891INFO:tensorflow:For batch 2, loss is    0.49.\n",
      "INFO:tensorflow:For batch 2, accuracy is    0.80.\n",
      " 192/7352 [..............................] - ETA: 26s - loss: 0.5245 - accuracy: 0.8021INFO:tensorflow:For batch 3, loss is    0.57.\n",
      "INFO:tensorflow:For batch 3, accuracy is    0.80.\n",
      " 256/7352 [>.............................] - ETA: 26s - loss: 0.5351 - accuracy: 0.8008INFO:tensorflow:For batch 4, loss is    0.61.\n",
      "INFO:tensorflow:For batch 4, accuracy is    0.79.\n",
      " 320/7352 [>.............................] - ETA: 25s - loss: 0.5504 - accuracy: 0.7906INFO:tensorflow:For batch 5, loss is    0.51.\n",
      "INFO:tensorflow:For batch 5, accuracy is    0.79.\n",
      " 384/7352 [>.............................] - ETA: 25s - loss: 0.5428 - accuracy: 0.7865INFO:tensorflow:For batch 6, loss is    0.62.\n",
      "INFO:tensorflow:For batch 6, accuracy is    0.78.\n",
      " 448/7352 [>.............................] - ETA: 25s - loss: 0.5533 - accuracy: 0.7768INFO:tensorflow:For batch 7, loss is    0.52.\n",
      "INFO:tensorflow:For batch 7, accuracy is    0.78.\n",
      " 512/7352 [=>............................] - ETA: 25s - loss: 0.5491 - accuracy: 0.7773INFO:tensorflow:For batch 8, loss is    0.50.\n",
      "INFO:tensorflow:For batch 8, accuracy is    0.78.\n",
      " 576/7352 [=>............................] - ETA: 24s - loss: 0.5439 - accuracy: 0.7778INFO:tensorflow:For batch 9, loss is    0.58.\n",
      "INFO:tensorflow:For batch 9, accuracy is    0.78.\n",
      " 640/7352 [=>............................] - ETA: 24s - loss: 0.5473 - accuracy: 0.7766INFO:tensorflow:For batch 10, loss is    0.56.\n",
      "INFO:tensorflow:For batch 10, accuracy is    0.77.\n",
      " 704/7352 [=>............................] - ETA: 24s - loss: 0.5482 - accuracy: 0.7727INFO:tensorflow:For batch 11, loss is    0.63.\n",
      "INFO:tensorflow:For batch 11, accuracy is    0.77.\n",
      " 768/7352 [==>...........................] - ETA: 23s - loss: 0.5549 - accuracy: 0.7721INFO:tensorflow:For batch 12, loss is    0.50.\n",
      "INFO:tensorflow:For batch 12, accuracy is    0.78.\n",
      " 832/7352 [==>...........................] - ETA: 23s - loss: 0.5503 - accuracy: 0.7776INFO:tensorflow:For batch 13, loss is    0.53.\n",
      "INFO:tensorflow:For batch 13, accuracy is    0.78.\n",
      " 896/7352 [==>...........................] - ETA: 23s - loss: 0.5486 - accuracy: 0.7801INFO:tensorflow:For batch 14, loss is    0.50.\n",
      "INFO:tensorflow:For batch 14, accuracy is    0.78.\n",
      " 960/7352 [==>...........................] - ETA: 22s - loss: 0.5453 - accuracy: 0.7802INFO:tensorflow:For batch 15, loss is    0.50.\n",
      "INFO:tensorflow:For batch 15, accuracy is    0.79.\n",
      "1024/7352 [===>..........................] - ETA: 22s - loss: 0.5426 - accuracy: 0.7852INFO:tensorflow:For batch 16, loss is    0.72.\n",
      "INFO:tensorflow:For batch 16, accuracy is    0.78.\n",
      "1088/7352 [===>..........................] - ETA: 21s - loss: 0.5532 - accuracy: 0.7803INFO:tensorflow:For batch 17, loss is    0.45.\n",
      "INFO:tensorflow:For batch 17, accuracy is    0.78.\n",
      "1152/7352 [===>..........................] - ETA: 21s - loss: 0.5473 - accuracy: 0.7821INFO:tensorflow:For batch 18, loss is    0.43.\n",
      "INFO:tensorflow:For batch 18, accuracy is    0.79.\n",
      "1216/7352 [===>..........................] - ETA: 20s - loss: 0.5412 - accuracy: 0.7878INFO:tensorflow:For batch 19, loss is    0.45.\n",
      "INFO:tensorflow:For batch 19, accuracy is    0.79.\n",
      "1280/7352 [====>.........................] - ETA: 20s - loss: 0.5368 - accuracy: 0.7883INFO:tensorflow:For batch 20, loss is    0.51.\n",
      "INFO:tensorflow:For batch 20, accuracy is    0.79.\n",
      "1344/7352 [====>.........................] - ETA: 20s - loss: 0.5355 - accuracy: 0.7872INFO:tensorflow:For batch 21, loss is    0.59.\n",
      "INFO:tensorflow:For batch 21, accuracy is    0.78.\n",
      "1408/7352 [====>.........................] - ETA: 19s - loss: 0.5381 - accuracy: 0.7848INFO:tensorflow:For batch 22, loss is    0.51.\n",
      "INFO:tensorflow:For batch 22, accuracy is    0.79.\n",
      "1472/7352 [=====>........................] - ETA: 19s - loss: 0.5368 - accuracy: 0.7853INFO:tensorflow:For batch 23, loss is    0.52.\n",
      "INFO:tensorflow:For batch 23, accuracy is    0.79.\n",
      "1536/7352 [=====>........................] - ETA: 19s - loss: 0.5363 - accuracy: 0.7852INFO:tensorflow:For batch 24, loss is    0.55.\n",
      "INFO:tensorflow:For batch 24, accuracy is    0.78.\n",
      "1600/7352 [=====>........................] - ETA: 19s - loss: 0.5369 - accuracy: 0.7831INFO:tensorflow:For batch 25, loss is    0.48.\n",
      "INFO:tensorflow:For batch 25, accuracy is    0.78.\n",
      "1664/7352 [=====>........................] - ETA: 19s - loss: 0.5347 - accuracy: 0.7849INFO:tensorflow:For batch 26, loss is    0.60.\n",
      "INFO:tensorflow:For batch 26, accuracy is    0.78.\n",
      "1728/7352 [======>.......................] - ETA: 18s - loss: 0.5370 - accuracy: 0.7830INFO:tensorflow:For batch 27, loss is    0.46.\n",
      "INFO:tensorflow:For batch 27, accuracy is    0.78.\n",
      "1792/7352 [======>.......................] - ETA: 18s - loss: 0.5344 - accuracy: 0.7824INFO:tensorflow:For batch 28, loss is    0.55.\n",
      "INFO:tensorflow:For batch 28, accuracy is    0.78.\n",
      "1856/7352 [======>.......................] - ETA: 18s - loss: 0.5349 - accuracy: 0.7818INFO:tensorflow:For batch 29, loss is    0.50.\n",
      "INFO:tensorflow:For batch 29, accuracy is    0.78.\n",
      "1920/7352 [======>.......................] - ETA: 18s - loss: 0.5336 - accuracy: 0.7818INFO:tensorflow:For batch 30, loss is    0.54.\n",
      "INFO:tensorflow:For batch 30, accuracy is    0.78.\n",
      "1984/7352 [=======>......................] - ETA: 17s - loss: 0.5339 - accuracy: 0.7823INFO:tensorflow:For batch 31, loss is    0.52.\n",
      "INFO:tensorflow:For batch 31, accuracy is    0.78.\n",
      "2048/7352 [=======>......................] - ETA: 17s - loss: 0.5336 - accuracy: 0.7817INFO:tensorflow:For batch 32, loss is    0.51.\n",
      "INFO:tensorflow:For batch 32, accuracy is    0.78.\n",
      "2112/7352 [=======>......................] - ETA: 17s - loss: 0.5329 - accuracy: 0.7808INFO:tensorflow:For batch 33, loss is    0.40.\n",
      "INFO:tensorflow:For batch 33, accuracy is    0.78.\n",
      "2176/7352 [=======>......................] - ETA: 16s - loss: 0.5290 - accuracy: 0.7826INFO:tensorflow:For batch 34, loss is    0.38.\n",
      "INFO:tensorflow:For batch 34, accuracy is    0.78.\n",
      "2240/7352 [========>.....................] - ETA: 16s - loss: 0.5249 - accuracy: 0.7835INFO:tensorflow:For batch 35, loss is    0.61.\n",
      "INFO:tensorflow:For batch 35, accuracy is    0.78.\n",
      "2304/7352 [========>.....................] - ETA: 16s - loss: 0.5273 - accuracy: 0.7826INFO:tensorflow:For batch 36, loss is    0.46.\n",
      "INFO:tensorflow:For batch 36, accuracy is    0.78.\n",
      "2368/7352 [========>.....................] - ETA: 15s - loss: 0.5256 - accuracy: 0.7825INFO:tensorflow:For batch 37, loss is    0.67.\n",
      "INFO:tensorflow:For batch 37, accuracy is    0.78.\n",
      "2432/7352 [========>.....................] - ETA: 15s - loss: 0.5294 - accuracy: 0.7804INFO:tensorflow:For batch 38, loss is    0.40.\n",
      "INFO:tensorflow:For batch 38, accuracy is    0.78.\n",
      "2496/7352 [=========>....................] - ETA: 15s - loss: 0.5261 - accuracy: 0.7833INFO:tensorflow:For batch 39, loss is    0.48.\n",
      "INFO:tensorflow:For batch 39, accuracy is    0.78.\n",
      "2560/7352 [=========>....................] - ETA: 15s - loss: 0.5250 - accuracy: 0.7828INFO:tensorflow:For batch 40, loss is    0.46.\n",
      "INFO:tensorflow:For batch 40, accuracy is    0.78.\n",
      "2624/7352 [=========>....................] - ETA: 15s - loss: 0.5235 - accuracy: 0.7847INFO:tensorflow:For batch 41, loss is    0.58.\n",
      "INFO:tensorflow:For batch 41, accuracy is    0.79.\n",
      "2688/7352 [=========>....................] - ETA: 14s - loss: 0.5250 - accuracy: 0.7853INFO:tensorflow:For batch 42, loss is    0.49.\n",
      "INFO:tensorflow:For batch 42, accuracy is    0.79.\n",
      "2752/7352 [==========>...................] - ETA: 14s - loss: 0.5242 - accuracy: 0.7882INFO:tensorflow:For batch 43, loss is    0.56.\n",
      "INFO:tensorflow:For batch 43, accuracy is    0.79.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2816/7352 [==========>...................] - ETA: 14s - loss: 0.5251 - accuracy: 0.7873INFO:tensorflow:For batch 44, loss is    0.49.\n",
      "INFO:tensorflow:For batch 44, accuracy is    0.79.\n",
      "2880/7352 [==========>...................] - ETA: 14s - loss: 0.5244 - accuracy: 0.7872INFO:tensorflow:For batch 45, loss is    0.36.\n",
      "INFO:tensorflow:For batch 45, accuracy is    0.79.\n",
      "2944/7352 [===========>..................] - ETA: 13s - loss: 0.5207 - accuracy: 0.7877INFO:tensorflow:For batch 46, loss is    0.64.\n",
      "INFO:tensorflow:For batch 46, accuracy is    0.79.\n",
      "3008/7352 [===========>..................] - ETA: 13s - loss: 0.5233 - accuracy: 0.7872INFO:tensorflow:For batch 47, loss is    0.33.\n",
      "INFO:tensorflow:For batch 47, accuracy is    0.79.\n",
      "3072/7352 [===========>..................] - ETA: 13s - loss: 0.5193 - accuracy: 0.7894INFO:tensorflow:For batch 48, loss is    0.54.\n",
      "INFO:tensorflow:For batch 48, accuracy is    0.79.\n",
      "3136/7352 [===========>..................] - ETA: 13s - loss: 0.5198 - accuracy: 0.7895INFO:tensorflow:For batch 49, loss is    0.66.\n",
      "INFO:tensorflow:For batch 49, accuracy is    0.79.\n",
      "3200/7352 [============>.................] - ETA: 13s - loss: 0.5225 - accuracy: 0.7894INFO:tensorflow:For batch 50, loss is    0.41.\n",
      "INFO:tensorflow:For batch 50, accuracy is    0.79.\n",
      "3264/7352 [============>.................] - ETA: 12s - loss: 0.5203 - accuracy: 0.7901INFO:tensorflow:For batch 51, loss is    0.47.\n",
      "INFO:tensorflow:For batch 51, accuracy is    0.79.\n",
      "3328/7352 [============>.................] - ETA: 12s - loss: 0.5194 - accuracy: 0.7909INFO:tensorflow:For batch 52, loss is    0.50.\n",
      "INFO:tensorflow:For batch 52, accuracy is    0.79.\n",
      "3392/7352 [============>.................] - ETA: 12s - loss: 0.5192 - accuracy: 0.7922INFO:tensorflow:For batch 53, loss is    0.54.\n",
      "INFO:tensorflow:For batch 53, accuracy is    0.79.\n",
      "3456/7352 [=============>................] - ETA: 12s - loss: 0.5196 - accuracy: 0.7928INFO:tensorflow:For batch 54, loss is    0.45.\n",
      "INFO:tensorflow:For batch 54, accuracy is    0.79.\n",
      "3520/7352 [=============>................] - ETA: 12s - loss: 0.5184 - accuracy: 0.7937INFO:tensorflow:For batch 55, loss is    0.69.\n",
      "INFO:tensorflow:For batch 55, accuracy is    0.79.\n",
      "3584/7352 [=============>................] - ETA: 12s - loss: 0.5215 - accuracy: 0.7924INFO:tensorflow:For batch 56, loss is    0.55.\n",
      "INFO:tensorflow:For batch 56, accuracy is    0.79.\n",
      "3648/7352 [=============>................] - ETA: 11s - loss: 0.5220 - accuracy: 0.7908INFO:tensorflow:For batch 57, loss is    0.69.\n",
      "INFO:tensorflow:For batch 57, accuracy is    0.79.\n",
      "3712/7352 [==============>...............] - ETA: 11s - loss: 0.5250 - accuracy: 0.7904INFO:tensorflow:For batch 58, loss is    0.66.\n",
      "INFO:tensorflow:For batch 58, accuracy is    0.79.\n",
      "3776/7352 [==============>...............] - ETA: 11s - loss: 0.5273 - accuracy: 0.7897INFO:tensorflow:For batch 59, loss is    0.49.\n",
      "INFO:tensorflow:For batch 59, accuracy is    0.79.\n",
      "3840/7352 [==============>...............] - ETA: 11s - loss: 0.5267 - accuracy: 0.7896INFO:tensorflow:For batch 60, loss is    0.59.\n",
      "INFO:tensorflow:For batch 60, accuracy is    0.79.\n",
      "3904/7352 [==============>...............] - ETA: 11s - loss: 0.5278 - accuracy: 0.7892INFO:tensorflow:For batch 61, loss is    0.57.\n",
      "INFO:tensorflow:For batch 61, accuracy is    0.79.\n",
      "3968/7352 [===============>..............] - ETA: 11s - loss: 0.5284 - accuracy: 0.7893INFO:tensorflow:For batch 62, loss is    0.49.\n",
      "INFO:tensorflow:For batch 62, accuracy is    0.79.\n",
      "4032/7352 [===============>..............] - ETA: 10s - loss: 0.5278 - accuracy: 0.7907INFO:tensorflow:For batch 63, loss is    0.51.\n",
      "INFO:tensorflow:For batch 63, accuracy is    0.79.\n",
      "4096/7352 [===============>..............] - ETA: 10s - loss: 0.5276 - accuracy: 0.7903INFO:tensorflow:For batch 64, loss is    0.50.\n",
      "INFO:tensorflow:For batch 64, accuracy is    0.79.\n",
      "4160/7352 [===============>..............] - ETA: 10s - loss: 0.5271 - accuracy: 0.7913INFO:tensorflow:For batch 65, loss is    0.58.\n",
      "INFO:tensorflow:For batch 65, accuracy is    0.79.\n",
      "4224/7352 [================>.............] - ETA: 10s - loss: 0.5279 - accuracy: 0.7900INFO:tensorflow:For batch 66, loss is    0.52.\n",
      "INFO:tensorflow:For batch 66, accuracy is    0.79.\n",
      "4288/7352 [================>.............] - ETA: 9s - loss: 0.5278 - accuracy: 0.7899 INFO:tensorflow:For batch 67, loss is    0.50.\n",
      "INFO:tensorflow:For batch 67, accuracy is    0.79.\n",
      "4352/7352 [================>.............] - ETA: 9s - loss: 0.5273 - accuracy: 0.7898INFO:tensorflow:For batch 68, loss is    0.37.\n",
      "INFO:tensorflow:For batch 68, accuracy is    0.79.\n",
      "4416/7352 [=================>............] - ETA: 9s - loss: 0.5251 - accuracy: 0.7910INFO:tensorflow:For batch 69, loss is    0.51.\n",
      "INFO:tensorflow:For batch 69, accuracy is    0.79.\n",
      "4480/7352 [=================>............] - ETA: 9s - loss: 0.5250 - accuracy: 0.7911INFO:tensorflow:For batch 70, loss is    0.57.\n",
      "INFO:tensorflow:For batch 70, accuracy is    0.79.\n",
      "4544/7352 [=================>............] - ETA: 8s - loss: 0.5256 - accuracy: 0.7909INFO:tensorflow:For batch 71, loss is    0.40.\n",
      "INFO:tensorflow:For batch 71, accuracy is    0.79.\n",
      "4608/7352 [=================>............] - ETA: 8s - loss: 0.5239 - accuracy: 0.7914INFO:tensorflow:For batch 72, loss is    0.57.\n",
      "INFO:tensorflow:For batch 72, accuracy is    0.79.\n",
      "4672/7352 [==================>...........] - ETA: 8s - loss: 0.5245 - accuracy: 0.7909INFO:tensorflow:For batch 73, loss is    0.41.\n",
      "INFO:tensorflow:For batch 73, accuracy is    0.79.\n",
      "4736/7352 [==================>...........] - ETA: 8s - loss: 0.5230 - accuracy: 0.7922INFO:tensorflow:For batch 74, loss is    0.39.\n",
      "INFO:tensorflow:For batch 74, accuracy is    0.79.\n",
      "4800/7352 [==================>...........] - ETA: 8s - loss: 0.5212 - accuracy: 0.7929INFO:tensorflow:For batch 75, loss is    0.43.\n",
      "INFO:tensorflow:For batch 75, accuracy is    0.79.\n",
      "4864/7352 [==================>...........] - ETA: 7s - loss: 0.5201 - accuracy: 0.7934INFO:tensorflow:For batch 76, loss is    0.42.\n",
      "INFO:tensorflow:For batch 76, accuracy is    0.79.\n",
      "4928/7352 [===================>..........] - ETA: 7s - loss: 0.5188 - accuracy: 0.7936INFO:tensorflow:For batch 77, loss is    0.36.\n",
      "INFO:tensorflow:For batch 77, accuracy is    0.79.\n",
      "4992/7352 [===================>..........] - ETA: 7s - loss: 0.5168 - accuracy: 0.7947INFO:tensorflow:For batch 78, loss is    0.43.\n",
      "INFO:tensorflow:For batch 78, accuracy is    0.79.\n",
      "5056/7352 [===================>..........] - ETA: 7s - loss: 0.5158 - accuracy: 0.7945INFO:tensorflow:For batch 79, loss is    0.27.\n",
      "INFO:tensorflow:For batch 79, accuracy is    0.80.\n",
      "5120/7352 [===================>..........] - ETA: 6s - loss: 0.5127 - accuracy: 0.7957INFO:tensorflow:For batch 80, loss is    0.31.\n",
      "INFO:tensorflow:For batch 80, accuracy is    0.80.\n",
      "5184/7352 [====================>.........] - ETA: 6s - loss: 0.5102 - accuracy: 0.7969INFO:tensorflow:For batch 81, loss is    0.39.\n",
      "INFO:tensorflow:For batch 81, accuracy is    0.80.\n",
      "5248/7352 [====================>.........] - ETA: 6s - loss: 0.5088 - accuracy: 0.7978INFO:tensorflow:For batch 82, loss is    0.65.\n",
      "INFO:tensorflow:For batch 82, accuracy is    0.80.\n",
      "5312/7352 [====================>.........] - ETA: 6s - loss: 0.5105 - accuracy: 0.7974INFO:tensorflow:For batch 83, loss is    0.61.\n",
      "INFO:tensorflow:For batch 83, accuracy is    0.80.\n",
      "5376/7352 [====================>.........] - ETA: 6s - loss: 0.5116 - accuracy: 0.7971INFO:tensorflow:For batch 84, loss is    0.47.\n",
      "INFO:tensorflow:For batch 84, accuracy is    0.80.\n",
      "5440/7352 [=====================>........] - ETA: 5s - loss: 0.5112 - accuracy: 0.7976INFO:tensorflow:For batch 85, loss is    0.35.\n",
      "INFO:tensorflow:For batch 85, accuracy is    0.80.\n",
      "5504/7352 [=====================>........] - ETA: 5s - loss: 0.5093 - accuracy: 0.7985INFO:tensorflow:For batch 86, loss is    0.28.\n",
      "INFO:tensorflow:For batch 86, accuracy is    0.80.\n",
      "5568/7352 [=====================>........] - ETA: 5s - loss: 0.5067 - accuracy: 0.7999INFO:tensorflow:For batch 87, loss is    0.36.\n",
      "INFO:tensorflow:For batch 87, accuracy is    0.80.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632/7352 [=====================>........] - ETA: 5s - loss: 0.5050 - accuracy: 0.8004INFO:tensorflow:For batch 88, loss is    0.52.\n",
      "INFO:tensorflow:For batch 88, accuracy is    0.80.\n",
      "5696/7352 [======================>.......] - ETA: 5s - loss: 0.5051 - accuracy: 0.8006INFO:tensorflow:For batch 89, loss is    0.44.\n",
      "INFO:tensorflow:For batch 89, accuracy is    0.80.\n",
      "5760/7352 [======================>.......] - ETA: 4s - loss: 0.5043 - accuracy: 0.8012INFO:tensorflow:For batch 90, loss is    0.43.\n",
      "INFO:tensorflow:For batch 90, accuracy is    0.80.\n",
      "5824/7352 [======================>.......] - ETA: 4s - loss: 0.5036 - accuracy: 0.8020INFO:tensorflow:For batch 91, loss is    0.39.\n",
      "INFO:tensorflow:For batch 91, accuracy is    0.80.\n",
      "5888/7352 [=======================>......] - ETA: 4s - loss: 0.5024 - accuracy: 0.8028INFO:tensorflow:For batch 92, loss is    0.39.\n",
      "INFO:tensorflow:For batch 92, accuracy is    0.80.\n",
      "5952/7352 [=======================>......] - ETA: 4s - loss: 0.5012 - accuracy: 0.8033INFO:tensorflow:For batch 93, loss is    0.31.\n",
      "INFO:tensorflow:For batch 93, accuracy is    0.80.\n",
      "6016/7352 [=======================>......] - ETA: 4s - loss: 0.4992 - accuracy: 0.8040INFO:tensorflow:For batch 94, loss is    0.41.\n",
      "INFO:tensorflow:For batch 94, accuracy is    0.81.\n",
      "6080/7352 [=======================>......] - ETA: 3s - loss: 0.4982 - accuracy: 0.8051INFO:tensorflow:For batch 95, loss is    0.43.\n",
      "INFO:tensorflow:For batch 95, accuracy is    0.81.\n",
      "6144/7352 [========================>.....] - ETA: 3s - loss: 0.4975 - accuracy: 0.8055INFO:tensorflow:For batch 96, loss is    0.39.\n",
      "INFO:tensorflow:For batch 96, accuracy is    0.81.\n",
      "6208/7352 [========================>.....] - ETA: 3s - loss: 0.4964 - accuracy: 0.8064INFO:tensorflow:For batch 97, loss is    0.41.\n",
      "INFO:tensorflow:For batch 97, accuracy is    0.81.\n",
      "6272/7352 [========================>.....] - ETA: 3s - loss: 0.4956 - accuracy: 0.8068INFO:tensorflow:For batch 98, loss is    0.57.\n",
      "INFO:tensorflow:For batch 98, accuracy is    0.81.\n",
      "6336/7352 [========================>.....] - ETA: 3s - loss: 0.4963 - accuracy: 0.8070INFO:tensorflow:For batch 99, loss is    0.28.\n",
      "INFO:tensorflow:For batch 99, accuracy is    0.81.\n",
      "6400/7352 [=========================>....] - ETA: 2s - loss: 0.4942 - accuracy: 0.8083INFO:tensorflow:For batch 100, loss is    0.37.\n",
      "INFO:tensorflow:For batch 100, accuracy is    0.81.\n",
      "6464/7352 [=========================>....] - ETA: 2s - loss: 0.4930 - accuracy: 0.8093INFO:tensorflow:For batch 101, loss is    0.26.\n",
      "INFO:tensorflow:For batch 101, accuracy is    0.81.\n",
      "6528/7352 [=========================>....] - ETA: 2s - loss: 0.4907 - accuracy: 0.8105INFO:tensorflow:For batch 102, loss is    0.27.\n",
      "INFO:tensorflow:For batch 102, accuracy is    0.81.\n",
      "6592/7352 [=========================>....] - ETA: 2s - loss: 0.4885 - accuracy: 0.8114INFO:tensorflow:For batch 103, loss is    0.81.\n",
      "INFO:tensorflow:For batch 103, accuracy is    0.81.\n",
      "6656/7352 [==========================>...] - ETA: 2s - loss: 0.4917 - accuracy: 0.8108INFO:tensorflow:For batch 104, loss is    0.49.\n",
      "INFO:tensorflow:For batch 104, accuracy is    0.81.\n",
      "6720/7352 [==========================>...] - ETA: 1s - loss: 0.4917 - accuracy: 0.8110INFO:tensorflow:For batch 105, loss is    0.42.\n",
      "INFO:tensorflow:For batch 105, accuracy is    0.81.\n",
      "6784/7352 [==========================>...] - ETA: 1s - loss: 0.4910 - accuracy: 0.8113INFO:tensorflow:For batch 106, loss is    0.36.\n",
      "INFO:tensorflow:For batch 106, accuracy is    0.81.\n",
      "6848/7352 [==========================>...] - ETA: 1s - loss: 0.4898 - accuracy: 0.8115INFO:tensorflow:For batch 107, loss is    0.35.\n",
      "INFO:tensorflow:For batch 107, accuracy is    0.81.\n",
      "6912/7352 [===========================>..] - ETA: 1s - loss: 0.4885 - accuracy: 0.8118INFO:tensorflow:For batch 108, loss is    0.33.\n",
      "INFO:tensorflow:For batch 108, accuracy is    0.81.\n",
      "6976/7352 [===========================>..] - ETA: 1s - loss: 0.4870 - accuracy: 0.8124INFO:tensorflow:For batch 109, loss is    0.51.\n",
      "INFO:tensorflow:For batch 109, accuracy is    0.81.\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.4872 - accuracy: 0.8126INFO:tensorflow:For batch 110, loss is    0.44.\n",
      "INFO:tensorflow:For batch 110, accuracy is    0.81.\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.4868 - accuracy: 0.8133INFO:tensorflow:For batch 111, loss is    0.39.\n",
      "INFO:tensorflow:For batch 111, accuracy is    0.81.\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.4860 - accuracy: 0.8139INFO:tensorflow:For batch 112, loss is    0.45.\n",
      "INFO:tensorflow:For batch 112, accuracy is    0.81.\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.4857 - accuracy: 0.8143INFO:tensorflow:For batch 113, loss is    0.20.\n",
      "INFO:tensorflow:For batch 113, accuracy is    0.82.\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.4831 - accuracy: 0.8154INFO:tensorflow:For batch 114, loss is    0.29.\n",
      "INFO:tensorflow:For batch 114, accuracy is    0.82.\n",
      "INFO:tensorflow:weights of 1 layers for epoch3 is [array([[ 0.01541703,  0.05644186, -0.06443509, ..., -0.11225262,\n",
      "        -0.08069751, -0.11958282],\n",
      "       [-0.01590716, -0.11695508,  0.0420356 , ..., -0.00382745,\n",
      "        -0.01945987,  0.05445759],\n",
      "       [-0.01168702,  0.09347037, -0.07746843, ..., -0.07264017,\n",
      "        -0.05910154, -0.04183715],\n",
      "       ...,\n",
      "       [-0.0953946 , -0.05652858, -0.15357777, ..., -0.15720303,\n",
      "        -0.27758327,  0.04752925],\n",
      "       [-0.00495449,  0.04827505,  0.07087573, ..., -0.05006232,\n",
      "         0.23446004, -0.02424429],\n",
      "       [-0.15725166,  0.1497463 , -0.01816055, ..., -0.15064244,\n",
      "         0.11563577, -0.00969248]], dtype=float32), array([[-0.03968421,  0.06622737, -0.01136174, ..., -0.14591564,\n",
      "        -0.07630021, -0.01878406],\n",
      "       [-0.12512158,  0.10902546, -0.02232343, ...,  0.1432309 ,\n",
      "         0.02361507,  0.05649266],\n",
      "       [ 0.05212017, -0.03179686, -0.00560337, ..., -0.02826653,\n",
      "        -0.05291735, -0.01258252],\n",
      "       ...,\n",
      "       [-0.01328169,  0.07788332, -0.03380188, ...,  0.06022986,\n",
      "         0.05865992,  0.05191214],\n",
      "       [ 0.07223333,  0.03887476,  0.0137551 , ...,  0.0225316 ,\n",
      "        -0.02320734, -0.00106053],\n",
      "       [-0.06153502, -0.04975236,  0.08395734, ..., -0.07027033,\n",
      "         0.0412082 , -0.05830571]], dtype=float32), array([ 1.19739184e-02,  1.14637101e-02,  1.74093712e-02,  7.60928309e-03,\n",
      "        3.32038216e-02, -8.15261342e-03, -7.02006463e-03,  3.47756408e-02,\n",
      "        1.22892717e-03,  3.66400171e-04,  2.01880075e-02,  9.28899925e-03,\n",
      "       -1.31344199e-02, -6.11453550e-04,  1.75517518e-02, -1.22047439e-02,\n",
      "       -8.93942919e-03,  3.65069369e-03,  2.82230880e-03,  1.00258803e-02,\n",
      "        1.46267442e-02,  4.36210781e-02,  1.73545331e-02, -8.92486889e-03,\n",
      "        4.75228066e-03,  4.59309816e-02, -1.61120296e-02,  3.60318124e-02,\n",
      "        2.32415413e-03,  4.19603772e-02, -1.18016368e-02,  7.80840055e-04,\n",
      "       -3.88445193e-03,  2.62009408e-02,  2.07756329e-02, -3.68529069e-03,\n",
      "        1.75644904e-02,  3.38604227e-02,  2.72216965e-02,  6.41813455e-03,\n",
      "        1.06215375e-02,  1.83685701e-02,  1.52750863e-02,  2.21299864e-02,\n",
      "        2.29475256e-02, -2.03335211e-02,  1.06721735e-02,  1.24513255e-02,\n",
      "       -3.58466059e-02,  1.11758951e-02,  9.47876088e-03,  2.20596008e-02,\n",
      "        3.57634984e-02,  2.60263607e-02,  1.78118255e-02,  3.25347334e-02,\n",
      "        2.55445559e-02,  1.17132571e-02,  1.90760531e-02,  6.49115443e-03,\n",
      "       -1.77297257e-02,  1.50283948e-02, -4.46504215e-04,  2.23048590e-02,\n",
      "        3.19663808e-02,  1.21509936e-02,  1.15595674e-02,  3.08813471e-02,\n",
      "        4.58883587e-03,  1.14335995e-02,  1.07547622e-02,  4.62779775e-02,\n",
      "        8.14166665e-03,  4.62072492e-02,  2.10850853e-02, -2.43405495e-02,\n",
      "        4.18426003e-03,  2.37342939e-02,  2.26887092e-02,  2.80089732e-02,\n",
      "        3.44922468e-02,  2.72224210e-02,  1.30036352e-02,  5.45696402e-03,\n",
      "       -3.03760078e-02,  4.00995910e-02,  8.42397101e-03,  3.63207213e-03,\n",
      "       -1.05205644e-02,  6.29073847e-03,  1.86989596e-03,  3.09052300e-02,\n",
      "        5.44324750e-03,  2.80561503e-02,  2.88924016e-02,  4.74062599e-02,\n",
      "        1.97938830e-03,  3.22016422e-04, -2.09855777e-03, -8.97149835e-03,\n",
      "        9.99529541e-01,  1.01248205e+00,  1.02853215e+00,  1.01593578e+00,\n",
      "        1.03890145e+00,  1.00897837e+00,  9.99296427e-01,  1.05184305e+00,\n",
      "        1.00117409e+00,  9.99454618e-01,  1.02357829e+00,  1.01171803e+00,\n",
      "        9.85355675e-01,  1.01286352e+00,  1.02392626e+00,  9.89068449e-01,\n",
      "        9.98016059e-01,  1.01770270e+00,  1.00003636e+00,  1.01770496e+00,\n",
      "        1.01734912e+00,  1.04821897e+00,  1.02544546e+00,  9.96407986e-01,\n",
      "        1.01617742e+00,  1.02446437e+00,  9.84480202e-01,  1.07089412e+00,\n",
      "        1.00648522e+00,  1.04420996e+00,  9.96503174e-01,  1.02128851e+00,\n",
      "        1.00579953e+00,  1.02522707e+00,  1.03327894e+00,  9.99024630e-01,\n",
      "        1.01909113e+00,  1.02922940e+00,  1.05047846e+00,  1.01007533e+00,\n",
      "        1.01426613e+00,  1.06530225e+00,  1.01948571e+00,  1.03735077e+00,\n",
      "        1.03251421e+00,  9.84206498e-01,  1.02226841e+00,  1.02502108e+00,\n",
      "        9.64195192e-01,  1.01757109e+00,  1.01660073e+00,  1.03166473e+00,\n",
      "        1.09125626e+00,  1.03533077e+00,  1.01567352e+00,  1.04497445e+00,\n",
      "        1.01754904e+00,  1.00700331e+00,  1.05062258e+00,  1.01209188e+00,\n",
      "        9.78777528e-01,  1.03390110e+00,  1.02722788e+00,  1.02468765e+00,\n",
      "        1.04130244e+00,  1.02719223e+00,  1.01068640e+00,  1.01797915e+00,\n",
      "        1.02068222e+00,  1.01502597e+00,  1.01205659e+00,  1.04540670e+00,\n",
      "        1.01213551e+00,  1.05404592e+00,  1.02622080e+00,  9.80450749e-01,\n",
      "        1.00616050e+00,  1.01748216e+00,  1.01913941e+00,  1.02032983e+00,\n",
      "        1.05371904e+00,  1.03135157e+00,  1.01764643e+00,  1.00273609e+00,\n",
      "        9.79194999e-01,  1.03384638e+00,  1.00858951e+00,  1.00723886e+00,\n",
      "        9.88439322e-01,  1.00188410e+00,  9.97912109e-01,  1.03332841e+00,\n",
      "        1.00854588e+00,  1.02783382e+00,  1.04457843e+00,  1.06297779e+00,\n",
      "        1.00542521e+00,  1.01131880e+00,  1.01832938e+00,  9.92882192e-01,\n",
      "       -4.84641083e-03, -1.13553950e-03,  1.24925990e-02,  1.10791903e-02,\n",
      "       -1.29759302e-02, -5.96873462e-02,  2.91637369e-02,  6.27815782e-04,\n",
      "       -2.81629376e-02,  1.68491174e-02, -2.70840414e-02, -6.18030375e-04,\n",
      "       -3.92121188e-02, -1.43796792e-02,  8.50336277e-04,  1.68297272e-02,\n",
      "        3.68212797e-02,  7.24404026e-03,  2.71993335e-02, -2.89308261e-02,\n",
      "       -9.67407972e-03, -1.98485926e-02,  9.69340373e-03, -1.20336320e-02,\n",
      "       -1.53400498e-02, -4.51930314e-02, -3.88982221e-02,  4.10195962e-02,\n",
      "       -4.34926972e-02,  1.28864450e-02, -2.39147786e-02,  1.21203288e-02,\n",
      "       -6.08006632e-03, -3.53263803e-02,  8.94176867e-03,  1.96744837e-02,\n",
      "       -2.31029298e-02, -3.08807995e-02, -4.45390027e-03,  3.73354256e-02,\n",
      "       -1.79716926e-02, -4.23848582e-03,  8.90898891e-03, -1.69354808e-02,\n",
      "        1.17955133e-02, -4.87593748e-02, -9.84722003e-03,  1.09150950e-02,\n",
      "       -3.03289350e-02,  1.34397987e-02,  2.23675184e-02,  8.88860319e-04,\n",
      "        1.87332798e-02, -5.42625040e-03, -3.20686363e-02, -1.79293249e-02,\n",
      "       -2.32539810e-02,  2.54693236e-02,  2.02610493e-02,  7.67704053e-03,\n",
      "       -2.81053092e-02, -7.23352004e-03, -8.38100817e-03, -2.17667017e-02,\n",
      "       -2.21334565e-02,  2.19033547e-02,  1.04450127e-02, -3.62500362e-02,\n",
      "       -2.94921733e-02, -2.49132998e-02, -4.86284085e-02, -1.71296205e-02,\n",
      "       -2.77158991e-02, -2.85471678e-02,  3.72305401e-02,  2.42992062e-02,\n",
      "       -3.52120548e-02, -7.54194194e-03, -4.89970855e-03, -4.58011357e-03,\n",
      "       -2.54510920e-02, -5.01847453e-03, -1.90675762e-02,  1.30180921e-02,\n",
      "        1.79337449e-02, -1.26505410e-02, -2.22253297e-02,  3.62087786e-02,\n",
      "       -2.95415390e-02,  2.62078214e-02,  1.03046410e-02,  1.91431362e-02,\n",
      "        1.95758156e-02,  2.30714381e-02,  1.39491754e-02, -6.99469773e-03,\n",
      "        3.06832436e-02,  1.34833874e-02, -5.74581092e-04,  1.22388164e-02,\n",
      "        1.38981529e-02,  1.67558752e-02,  8.49296153e-03,  2.46517570e-03,\n",
      "        3.78972217e-02, -6.86050509e-04, -8.64330959e-03,  4.79124188e-02,\n",
      "       -1.89997838e-03, -7.23192468e-04,  1.63321290e-02,  1.75276194e-02,\n",
      "       -1.46598453e-02, -6.91662589e-03,  2.81823147e-02, -1.56628937e-02,\n",
      "       -1.75366318e-03,  1.80256907e-02, -1.56312180e-03,  2.49022115e-02,\n",
      "        2.07115728e-02,  2.69452725e-02,  2.38830410e-02,  2.57337186e-03,\n",
      "        6.12503104e-03,  4.36407328e-02, -1.39310015e-02,  6.98477402e-02,\n",
      "        8.87348596e-03,  3.80255543e-02, -5.67351049e-03,  1.44803254e-02,\n",
      "       -2.53857905e-03,  2.48835310e-02,  1.33233145e-02, -5.86001249e-03,\n",
      "        2.21316740e-02,  4.41282764e-02,  3.94634195e-02,  1.21307708e-02,\n",
      "        1.37285823e-02,  5.14842942e-02,  1.40979951e-02,  2.08514407e-02,\n",
      "        3.44720371e-02, -2.02906914e-02,  1.34223537e-03,  1.53836906e-02,\n",
      "       -3.63873914e-02,  1.54154720e-02,  1.26195159e-02,  2.29480453e-02,\n",
      "        9.39943269e-02,  3.32812406e-02,  2.47041993e-02,  5.14534861e-02,\n",
      "        3.44453640e-02,  9.03356355e-03,  4.74716648e-02,  1.12184715e-02,\n",
      "       -1.99449621e-02,  1.78187843e-02,  5.34432009e-03,  1.60032324e-02,\n",
      "        2.39586066e-02,  2.90672611e-02,  6.28592540e-03,  2.77859699e-02,\n",
      "        8.52544326e-03,  1.68913100e-02,  1.65090859e-02,  6.55780137e-02,\n",
      "        1.12929996e-02,  5.21613061e-02,  3.10129859e-02, -2.05948893e-02,\n",
      "        6.04083668e-03,  2.21103206e-02,  3.34263742e-02,  3.29812542e-02,\n",
      "        5.04862070e-02,  1.62535943e-02,  1.90435927e-02, -5.24359755e-03,\n",
      "       -1.57112498e-02,  4.90417257e-02,  7.71338912e-03,  6.72988920e-03,\n",
      "       -9.62234940e-03,  5.32530574e-03,  3.99950426e-04,  2.68595573e-02,\n",
      "        7.41306553e-03,  2.60762647e-02,  5.76867796e-02,  6.40409291e-02,\n",
      "        6.29611872e-03,  3.26172775e-03,  2.08540354e-03, -8.78018793e-03],\n",
      "      dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:weights of 2 layers for epoch3 is []\n",
      "INFO:tensorflow:weights of 3 layers for epoch3 is [array([[-3.0456902e-02,  1.5542634e-01,  4.5327496e-02, ...,\n",
      "        -9.4074801e-02,  1.1843340e-02,  2.9965062e-02],\n",
      "       [-4.1801225e-02, -1.6539745e-01, -9.5677659e-02, ...,\n",
      "         8.0343522e-02, -1.5894511e-01,  7.4927665e-02],\n",
      "       [ 6.8851098e-02,  2.1126425e-01, -7.5571492e-02, ...,\n",
      "         1.4444014e-01,  1.6718878e-01, -2.7111182e-02],\n",
      "       ...,\n",
      "       [ 1.6228192e-01,  5.7283830e-02, -2.2026555e-01, ...,\n",
      "        -1.0085244e-01,  4.9940892e-02,  1.0825603e-01],\n",
      "       [ 2.8529311e-02,  2.3114657e-02, -1.1955846e-01, ...,\n",
      "        -1.1994332e-01,  1.0797707e-01,  3.0610659e-05],\n",
      "       [ 8.2743809e-02,  1.6548571e-01, -4.6655875e-02, ...,\n",
      "         8.9702316e-02, -5.6247603e-02,  5.2254852e-02]], dtype=float32), array([ 1.84556637e-02,  4.74519984e-05,  1.09289549e-01,  1.11102097e-01,\n",
      "       -3.89611088e-02,  5.49902581e-02,  2.41730344e-02,  5.58441412e-03,\n",
      "       -8.32186453e-03,  1.80407334e-02,  9.76096690e-02,  8.50884244e-02,\n",
      "        1.52630527e-02,  1.93128735e-02,  9.50680822e-02,  4.42466047e-03,\n",
      "        9.99670010e-03,  1.22589897e-02,  1.29250795e-01,  4.65118363e-02,\n",
      "       -6.30098279e-04,  9.21173468e-02,  1.01478491e-02, -4.19328455e-03,\n",
      "        4.40002754e-02,  1.16498232e-01,  5.45279533e-02,  3.70995142e-02,\n",
      "        4.42892276e-02, -2.44839024e-03,  3.36944126e-02,  2.23376546e-02,\n",
      "       -3.82387568e-03,  5.31070586e-03,  2.59233937e-02, -2.95073036e-02,\n",
      "       -3.47161293e-02,  7.98566639e-02, -3.37597146e-03, -1.24673890e-02,\n",
      "        2.80999914e-02,  5.09573668e-02,  8.21511075e-02, -9.15695168e-03,\n",
      "        4.61581424e-02,  1.37613546e-02,  9.44801718e-02,  1.10701658e-02,\n",
      "        5.39641781e-03,  4.51043621e-02,  5.33152465e-03,  2.63594370e-02,\n",
      "       -2.88156439e-02,  4.21333238e-02,  1.03053153e-01,  6.17343672e-02,\n",
      "        1.05638904e-02,  2.77326535e-02,  6.01820946e-02,  9.96994786e-03,\n",
      "       -3.33998278e-02, -1.32960891e-02, -2.96436027e-02,  7.96439424e-02,\n",
      "        2.21098717e-02,  9.62685607e-03,  5.65312617e-02,  2.47433316e-02,\n",
      "        2.85159498e-02,  2.85095908e-02,  5.79174682e-02,  2.12027002e-02,\n",
      "        3.48053128e-02, -7.21077994e-02, -1.82374958e-02,  5.41237891e-02,\n",
      "        1.48294801e-02,  2.08311453e-02,  1.64877623e-02,  8.63442849e-03,\n",
      "        4.74005286e-03,  2.42601186e-02,  1.38876298e-02,  6.22550845e-02,\n",
      "        4.09588665e-02,  1.17054209e-02, -1.46676274e-02,  1.31272594e-03,\n",
      "        8.76329914e-02, -1.76805770e-05,  1.96126755e-03,  5.12364060e-02,\n",
      "        6.55642524e-02,  7.11754933e-02,  8.86932772e-04,  6.43673167e-02,\n",
      "        1.47367595e-02,  2.95782778e-02,  7.36031383e-02, -5.37995882e-02],\n",
      "      dtype=float32)]\n",
      "INFO:tensorflow:weights of 4 layers for epoch3 is [array([[-2.93901027e-03,  1.01204537e-01,  2.06708595e-01,\n",
      "        -8.10799077e-02, -2.25296523e-02, -2.02059492e-01],\n",
      "       [-2.05016583e-01, -1.28215998e-01, -5.10497168e-02,\n",
      "        -4.38542068e-02,  3.56349386e-02,  1.64888352e-01],\n",
      "       [ 1.65041298e-01,  8.60162899e-02,  1.86214432e-01,\n",
      "         1.25548422e-01,  1.76205322e-01, -2.68574566e-01],\n",
      "       [ 2.90986151e-01, -1.31388353e-02, -3.40775624e-02,\n",
      "        -2.38851860e-01,  1.72913130e-02, -3.53300840e-01],\n",
      "       [-6.10316508e-02,  1.05488271e-01, -2.53135920e-01,\n",
      "         1.10707603e-01, -8.31367224e-02,  2.41244197e-01],\n",
      "       [-7.51785561e-02,  1.18117526e-01,  1.55507624e-01,\n",
      "        -1.39375538e-01, -2.18739301e-01, -4.16231662e-01],\n",
      "       [-5.82707464e-04,  6.94017634e-02, -8.73051360e-02,\n",
      "        -1.55417815e-01,  1.30948216e-01,  7.90562928e-02],\n",
      "       [-2.75716424e-01,  3.08786165e-02,  2.65842527e-01,\n",
      "        -1.51811019e-01, -3.03394105e-02,  1.28835579e-02],\n",
      "       [-1.01640835e-01, -1.23789564e-01,  2.54003733e-01,\n",
      "         2.80986764e-02, -7.04408959e-02, -2.34670356e-01],\n",
      "       [-2.64157146e-01,  2.36335546e-01,  9.04706568e-02,\n",
      "         5.04112430e-02, -5.37015917e-03,  2.40077898e-01],\n",
      "       [ 2.34662011e-01,  8.06246698e-02,  2.20938176e-01,\n",
      "        -1.07701093e-01,  1.06476381e-01, -2.10026577e-02],\n",
      "       [ 7.41055533e-02, -5.85995801e-02,  1.02057412e-01,\n",
      "        -2.86075383e-01, -2.24037364e-01, -3.66325647e-01],\n",
      "       [ 1.88543424e-01, -1.59277841e-01, -5.85003346e-02,\n",
      "        -1.23945832e-01, -1.00546613e-01,  2.13403270e-01],\n",
      "       [-2.31316984e-01, -2.22912639e-01, -4.06272523e-02,\n",
      "        -6.30786344e-02, -1.95067540e-01,  2.04401240e-01],\n",
      "       [ 2.28636771e-01, -1.13403194e-01,  2.06311315e-01,\n",
      "        -2.59353489e-01, -2.55884141e-01, -4.18942869e-01],\n",
      "       [-2.75798380e-01, -9.39581022e-02, -2.57906355e-02,\n",
      "         2.17025086e-01,  1.64757863e-01,  7.54298344e-02],\n",
      "       [-1.65901437e-01, -6.87172338e-02,  1.99783087e-01,\n",
      "         7.19319880e-02,  1.64367184e-01, -1.06794983e-01],\n",
      "       [ 9.09743160e-02,  1.64104879e-01, -6.27612025e-02,\n",
      "         1.55209705e-01, -8.38395134e-02, -3.24861676e-01],\n",
      "       [ 6.73257709e-02, -1.50678918e-01,  7.71241710e-02,\n",
      "        -7.87384212e-02, -5.13056256e-02, -3.90447587e-01],\n",
      "       [ 3.72879505e-02,  1.02190219e-01,  2.00690888e-02,\n",
      "        -4.19683792e-02,  2.46221244e-01, -2.99021274e-01],\n",
      "       [-1.67944849e-01,  6.69548884e-02, -3.43843400e-02,\n",
      "         1.20285161e-01, -1.92878127e-01,  1.24261364e-01],\n",
      "       [ 1.79960266e-01,  1.43407330e-01, -2.08193988e-01,\n",
      "        -4.94127050e-02,  1.04036391e-01, -3.53323847e-01],\n",
      "       [-1.91366345e-01, -1.77988723e-01, -1.48620188e-01,\n",
      "         7.14125261e-02, -4.09192732e-03, -2.39148691e-01],\n",
      "       [ 1.03527039e-01, -2.55778313e-01, -2.19540462e-01,\n",
      "         1.03364542e-01, -1.76551059e-01, -2.77228504e-01],\n",
      "       [-9.83315930e-02, -6.40581027e-02, -2.03249767e-01,\n",
      "         4.40865904e-02,  1.88350137e-02,  1.94895603e-02],\n",
      "       [ 2.20063746e-01, -8.36829245e-02,  1.98461846e-01,\n",
      "        -1.73623860e-02,  1.35886744e-01, -3.29547495e-01],\n",
      "       [ 1.63036779e-01, -5.63352890e-02, -2.72169113e-01,\n",
      "        -1.69285432e-01, -2.13341136e-02,  1.03881374e-01],\n",
      "       [ 4.14100522e-03,  9.21741128e-02,  2.04549327e-01,\n",
      "        -5.48432060e-02, -1.06331766e-01,  9.29315388e-02],\n",
      "       [-3.18451792e-01, -1.88744813e-01, -2.16269791e-01,\n",
      "        -1.14004739e-01,  8.61507356e-02,  7.69588947e-02],\n",
      "       [-1.23161159e-01,  1.28257662e-01,  1.01250067e-01,\n",
      "         9.97332707e-02,  2.25300431e-01, -4.14112322e-02],\n",
      "       [-6.04122467e-02,  1.91059336e-01, -2.05429330e-01,\n",
      "        -1.45085007e-01, -1.33479774e-01,  1.93179101e-01],\n",
      "       [-2.98775524e-01, -5.28946938e-03,  2.35330850e-01,\n",
      "         8.65297765e-02, -2.42621228e-01,  6.04863316e-02],\n",
      "       [-2.22709328e-01, -1.51908860e-01,  3.58679332e-02,\n",
      "         1.22156337e-01, -2.39722580e-01,  1.57240666e-02],\n",
      "       [-1.06505282e-01,  6.51219487e-02, -1.84215933e-01,\n",
      "         1.63085550e-01, -2.58952111e-01,  2.57443190e-01],\n",
      "       [ 6.38027340e-02, -1.34422526e-01,  6.83917776e-02,\n",
      "        -1.36913583e-01, -1.90631285e-01,  2.29363605e-01],\n",
      "       [ 2.43833661e-02,  1.65431857e-01, -1.37492284e-01,\n",
      "         9.78218764e-02, -1.88634217e-01, -1.09911323e-01],\n",
      "       [ 1.17956378e-01,  1.00787386e-01, -1.84788898e-01,\n",
      "         1.48485646e-01, -2.18407720e-01,  1.52667284e-01],\n",
      "       [ 2.55080581e-01,  1.58917829e-01,  7.29072690e-02,\n",
      "        -3.82777482e-01, -1.42749846e-01, -1.94386676e-01],\n",
      "       [ 7.31168464e-02, -2.08487794e-01, -2.91455984e-01,\n",
      "         1.90275341e-01, -2.20012888e-01,  2.16097102e-01],\n",
      "       [-4.36672121e-02, -1.22664958e-01, -1.10887969e-02,\n",
      "         2.19683126e-01, -1.23646846e-02,  4.72253971e-02],\n",
      "       [-2.07999706e-01, -6.84844777e-02, -2.65422493e-01,\n",
      "         2.15102538e-01,  2.75136173e-01, -2.23323792e-01],\n",
      "       [-8.35591182e-02, -3.32399487e-01, -1.89628094e-01,\n",
      "         1.66316688e-01,  5.56700677e-02,  1.75972830e-03],\n",
      "       [ 6.37746528e-02,  1.48050055e-01, -2.79361933e-01,\n",
      "        -2.13764429e-01,  9.33857709e-02,  6.41779974e-02],\n",
      "       [-3.06869924e-01, -1.57826081e-01, -3.10577452e-01,\n",
      "         2.34214514e-01, -2.00465739e-01, -1.25390038e-01],\n",
      "       [-1.82748735e-01, -2.64238626e-01, -2.91918993e-01,\n",
      "         8.08728859e-02,  1.15523122e-01, -3.19584876e-01],\n",
      "       [-6.95267096e-02,  2.83981204e-01,  1.99456841e-01,\n",
      "         9.63801295e-02,  1.27953038e-01, -1.83379665e-01],\n",
      "       [ 1.31165504e-01, -2.24329278e-01, -4.96588312e-02,\n",
      "         6.36480674e-02,  1.31847367e-01, -1.29550055e-01],\n",
      "       [ 2.42469266e-01,  1.65739030e-01, -7.10428413e-03,\n",
      "        -3.32807489e-02, -1.43944204e-01,  6.44154027e-02],\n",
      "       [ 2.56828777e-03,  2.41989225e-01, -6.17904849e-02,\n",
      "         6.61291257e-02, -2.76931792e-01, -1.53262794e-01],\n",
      "       [ 1.57943472e-01,  8.73408765e-02, -1.77918240e-01,\n",
      "         1.59887373e-01,  1.86427981e-01, -9.99467000e-02],\n",
      "       [-1.09760962e-01,  3.16505618e-02, -8.42251182e-02,\n",
      "        -2.39588767e-01,  1.47264391e-01,  1.43561915e-01],\n",
      "       [-1.12217262e-01, -1.06725032e-02, -2.16129035e-01,\n",
      "         1.19430780e-01, -1.00542277e-01,  2.62034327e-01],\n",
      "       [-1.44526124e-01,  7.64054209e-02, -1.72100365e-01,\n",
      "         1.63878232e-01, -2.35622123e-01,  5.42829409e-02],\n",
      "       [-6.13395870e-03, -1.11804835e-01, -2.51344532e-01,\n",
      "         5.08504026e-02,  1.28870249e-01,  5.62681518e-02],\n",
      "       [ 1.14032850e-01, -3.45218107e-02,  1.58196703e-01,\n",
      "        -1.33843601e-01, -5.09114563e-02, -2.99489945e-01],\n",
      "       [ 1.88035786e-01, -1.59936845e-01,  2.69991726e-01,\n",
      "         1.04229711e-01, -2.41051868e-01, -3.75457913e-01],\n",
      "       [-9.67733860e-02, -2.70848334e-01, -7.85982981e-02,\n",
      "         1.18510276e-01, -1.32066712e-01,  2.49052003e-01],\n",
      "       [ 1.55045137e-01, -4.97147851e-02, -1.24247663e-03,\n",
      "        -6.42745616e-03, -6.04567751e-02,  1.95535123e-02],\n",
      "       [-1.60344124e-01, -8.19840655e-02, -3.20585877e-01,\n",
      "         7.77796954e-02,  8.23543221e-02,  4.40933444e-02],\n",
      "       [-4.60499246e-03,  1.91681117e-01,  1.71312973e-01,\n",
      "        -9.23286006e-02, -1.08855188e-01, -2.64181107e-01],\n",
      "       [-2.20120251e-01,  5.93987741e-02,  4.52274904e-02,\n",
      "         1.46897554e-01, -1.03083169e-02, -1.13204584e-01],\n",
      "       [ 5.01386411e-02, -1.98931441e-01,  4.86019775e-02,\n",
      "         1.58444360e-01, -2.17521310e-01,  1.71819657e-01],\n",
      "       [-3.84918042e-02, -1.54535800e-01, -2.57484704e-01,\n",
      "        -1.58967286e-01, -1.62517861e-01,  5.24083078e-02],\n",
      "       [ 1.37990505e-01,  2.33393475e-01,  2.38472551e-01,\n",
      "        -3.59762490e-01, -5.16631007e-02, -2.44664386e-01],\n",
      "       [ 8.12897459e-02, -5.22360764e-02, -1.14200413e-01,\n",
      "         5.20093814e-02, -1.51816934e-01,  2.68857926e-01],\n",
      "       [-2.41381258e-01, -1.05649672e-01,  1.90465879e-02,\n",
      "         1.33660436e-01, -1.58144400e-01,  2.21685395e-01],\n",
      "       [-6.80813640e-02,  1.18914664e-01,  1.91810191e-01,\n",
      "        -8.52224454e-02,  1.67262573e-02, -3.59457582e-01],\n",
      "       [-7.25840628e-02,  5.62585257e-02,  7.49079734e-02,\n",
      "        -4.17230418e-03,  1.14855869e-02,  1.51124552e-01],\n",
      "       [ 1.82358176e-01, -1.65733889e-01, -3.51777970e-04,\n",
      "         3.16866264e-02,  2.60111064e-01,  3.19667831e-02],\n",
      "       [-2.10959435e-01, -1.09913737e-01,  1.24581367e-01,\n",
      "         1.84031844e-01,  2.67617047e-01, -7.01068193e-02],\n",
      "       [ 2.70196795e-01, -1.55337691e-01,  6.14772066e-02,\n",
      "        -2.01120585e-01, -2.06860960e-01,  1.88114494e-01],\n",
      "       [-2.28751600e-01, -1.73016593e-01,  2.01131683e-02,\n",
      "        -2.46140078e-01, -7.72841200e-02,  2.29851589e-01],\n",
      "       [-9.64266062e-03,  2.58223236e-01,  8.69724154e-02,\n",
      "        -1.97856396e-01, -1.60639599e-01, -1.27548911e-02],\n",
      "       [-2.36931875e-01,  2.23911762e-01, -4.20437790e-02,\n",
      "         2.02285647e-02, -7.78263435e-02,  6.69645052e-03],\n",
      "       [-1.45096675e-01, -1.02342330e-01, -1.06747448e-01,\n",
      "        -6.98875710e-02,  1.40710426e-02,  1.30134687e-01],\n",
      "       [-3.66475731e-02, -2.78630167e-01,  8.85029510e-03,\n",
      "         2.11880758e-01,  2.47384250e-01, -2.27721587e-01],\n",
      "       [-1.87366039e-01, -3.17271426e-02,  1.02234043e-01,\n",
      "        -1.45251900e-01,  2.21987173e-01, -2.45889246e-01],\n",
      "       [-1.51671514e-01,  3.39598358e-02,  5.70991747e-02,\n",
      "        -2.56818086e-01, -2.83955783e-01, -1.48462415e-01],\n",
      "       [ 2.12529823e-01,  1.31921768e-01, -1.79215774e-01,\n",
      "        -9.53797251e-02, -1.00950763e-01, -2.69820601e-01],\n",
      "       [-1.24005750e-01,  1.62683278e-01, -3.57800163e-02,\n",
      "         1.86164398e-02,  2.29244649e-01, -2.62651235e-01],\n",
      "       [-1.91286951e-01,  8.08787439e-03, -2.25344002e-01,\n",
      "        -1.31133914e-01,  7.86536559e-02,  1.01209298e-01],\n",
      "       [ 2.58301467e-01,  1.61397625e-02, -6.02329373e-02,\n",
      "         1.67519093e-01, -2.34804481e-01,  1.13270178e-01],\n",
      "       [-9.35211107e-02,  2.41899714e-01, -5.05665615e-02,\n",
      "         6.27904534e-02, -2.73215413e-01,  2.12788314e-01],\n",
      "       [ 9.56073180e-02,  2.61399001e-01, -1.86259404e-01,\n",
      "        -2.72730261e-01, -1.94127232e-01, -1.66377187e-01],\n",
      "       [ 3.39114480e-02,  1.38506696e-01,  1.15963966e-01,\n",
      "        -2.86510348e-01, -1.08580753e-01, -7.97393396e-02],\n",
      "       [-4.59742779e-03,  1.64729834e-01, -2.21361592e-01,\n",
      "         1.35823652e-01, -5.25336340e-03, -3.07546675e-01],\n",
      "       [ 8.08959305e-02,  3.45516354e-02, -1.15976416e-01,\n",
      "         2.35726520e-01, -1.04348801e-01,  2.09646076e-01],\n",
      "       [-1.70740962e-01,  2.03311056e-01, -9.58492327e-03,\n",
      "        -1.88169822e-01, -3.32903028e-01,  8.68430082e-03],\n",
      "       [ 2.48746529e-01, -1.90425456e-01, -8.85304511e-02,\n",
      "         1.79025173e-01,  2.01699257e-01, -4.12384331e-01],\n",
      "       [-1.18091121e-01, -1.91539198e-01,  8.60962346e-02,\n",
      "        -1.39046684e-01, -7.35422522e-02,  2.27348924e-01],\n",
      "       [ 3.18531245e-02,  1.04145452e-01, -1.17057636e-01,\n",
      "         8.18235427e-02, -1.50107175e-01, -2.75529087e-01],\n",
      "       [-1.81236923e-01, -2.88818568e-01, -1.19928986e-01,\n",
      "        -1.20957932e-02,  2.25507364e-01, -2.33895168e-01],\n",
      "       [ 2.31767461e-01,  2.09830292e-02, -2.44649500e-01,\n",
      "        -2.88003087e-01,  1.76675454e-01, -1.82648510e-01],\n",
      "       [ 5.45618944e-02, -4.27096300e-02, -1.90303579e-01,\n",
      "        -2.36750484e-01, -2.44523093e-01,  1.39391199e-01],\n",
      "       [-1.78063288e-01,  1.12898089e-01,  1.99545577e-01,\n",
      "        -1.24725677e-01, -1.02882296e-01, -7.59720951e-02],\n",
      "       [ 9.03310776e-02, -5.54677397e-02, -4.55244184e-02,\n",
      "        -2.11378932e-01, -3.31844300e-01,  2.42758706e-01],\n",
      "       [ 2.64612231e-02, -1.74603969e-01, -1.22403696e-01,\n",
      "         4.11526747e-02, -1.41435817e-01, -3.71387750e-01],\n",
      "       [ 9.29694399e-02,  2.04317555e-01, -4.33726795e-03,\n",
      "         1.46171361e-01,  1.82670236e-01, -1.22540139e-01],\n",
      "       [ 2.06899390e-01,  1.27307279e-02, -2.99246758e-02,\n",
      "        -3.86677533e-02, -4.85571735e-02,  2.55558461e-01],\n",
      "       [ 9.81639549e-02,  1.65497754e-02, -4.85861599e-02,\n",
      "         5.65439723e-02, -9.65284258e-02,  7.79930055e-02]], dtype=float32), array([ 0.05286798, -0.01317228,  0.01066925, -0.05321366,  0.01504791,\n",
      "       -0.04826809], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The average loss for epoch 3 is    0.48 and accuracy is    0.82.\n",
      "7352/7352 [==============================] - 22s 3ms/sample - loss: 0.4817 - accuracy: 0.8161\n",
      "Epoch 5/5\n",
      "INFO:tensorflow:For batch 0, loss is    0.41.\n",
      "INFO:tensorflow:For batch 0, accuracy is    0.89.\n",
      "  64/7352 [..............................] - ETA: 23s - loss: 0.4066 - accuracy: 0.8906INFO:tensorflow:For batch 1, loss is    0.46.\n",
      "INFO:tensorflow:For batch 1, accuracy is    0.87.\n",
      " 128/7352 [..............................] - ETA: 22s - loss: 0.4327 - accuracy: 0.8672INFO:tensorflow:For batch 2, loss is    0.52.\n",
      "INFO:tensorflow:For batch 2, accuracy is    0.84.\n",
      " 192/7352 [..............................] - ETA: 20s - loss: 0.4605 - accuracy: 0.8385INFO:tensorflow:For batch 3, loss is    0.49.\n",
      "INFO:tensorflow:For batch 3, accuracy is    0.84.\n",
      " 256/7352 [>.............................] - ETA: 18s - loss: 0.4667 - accuracy: 0.8398INFO:tensorflow:For batch 4, loss is    0.32.\n",
      "INFO:tensorflow:For batch 4, accuracy is    0.85.\n",
      " 320/7352 [>.............................] - ETA: 18s - loss: 0.4382 - accuracy: 0.8500INFO:tensorflow:For batch 5, loss is    0.31.\n",
      "INFO:tensorflow:For batch 5, accuracy is    0.86.\n",
      " 384/7352 [>.............................] - ETA: 20s - loss: 0.4173 - accuracy: 0.8568INFO:tensorflow:For batch 6, loss is    0.28.\n",
      "INFO:tensorflow:For batch 6, accuracy is    0.86.\n",
      " 448/7352 [>.............................] - ETA: 19s - loss: 0.3976 - accuracy: 0.8616INFO:tensorflow:For batch 7, loss is    0.36.\n",
      "INFO:tensorflow:For batch 7, accuracy is    0.86.\n",
      " 512/7352 [=>............................] - ETA: 18s - loss: 0.3925 - accuracy: 0.8633INFO:tensorflow:For batch 8, loss is    0.20.\n",
      "INFO:tensorflow:For batch 8, accuracy is    0.87.\n",
      " 576/7352 [=>............................] - ETA: 18s - loss: 0.3717 - accuracy: 0.8733INFO:tensorflow:For batch 9, loss is    0.34.\n",
      "INFO:tensorflow:For batch 9, accuracy is    0.88.\n",
      " 640/7352 [=>............................] - ETA: 18s - loss: 0.3681 - accuracy: 0.8766INFO:tensorflow:For batch 10, loss is    0.28.\n",
      "INFO:tensorflow:For batch 10, accuracy is    0.88.\n",
      " 704/7352 [=>............................] - ETA: 18s - loss: 0.3599 - accuracy: 0.8821INFO:tensorflow:For batch 11, loss is    0.26.\n",
      "INFO:tensorflow:For batch 11, accuracy is    0.88.\n",
      " 768/7352 [==>...........................] - ETA: 17s - loss: 0.3518 - accuracy: 0.8828INFO:tensorflow:For batch 12, loss is    0.45.\n",
      "INFO:tensorflow:For batch 12, accuracy is    0.88.\n",
      " 832/7352 [==>...........................] - ETA: 17s - loss: 0.3597 - accuracy: 0.8774INFO:tensorflow:For batch 13, loss is    0.21.\n",
      "INFO:tensorflow:For batch 13, accuracy is    0.88.\n",
      " 896/7352 [==>...........................] - ETA: 17s - loss: 0.3491 - accuracy: 0.8817INFO:tensorflow:For batch 14, loss is    0.43.\n",
      "INFO:tensorflow:For batch 14, accuracy is    0.88.\n",
      " 960/7352 [==>...........................] - ETA: 17s - loss: 0.3546 - accuracy: 0.8802INFO:tensorflow:For batch 15, loss is    0.29.\n",
      "INFO:tensorflow:For batch 15, accuracy is    0.88.\n",
      "1024/7352 [===>..........................] - ETA: 17s - loss: 0.3502 - accuracy: 0.8828INFO:tensorflow:For batch 16, loss is    0.26.\n",
      "INFO:tensorflow:For batch 16, accuracy is    0.89.\n",
      "1088/7352 [===>..........................] - ETA: 17s - loss: 0.3447 - accuracy: 0.8860INFO:tensorflow:For batch 17, loss is    0.34.\n",
      "INFO:tensorflow:For batch 17, accuracy is    0.89.\n",
      "1152/7352 [===>..........................] - ETA: 17s - loss: 0.3443 - accuracy: 0.8854INFO:tensorflow:For batch 18, loss is    0.43.\n",
      "INFO:tensorflow:For batch 18, accuracy is    0.88.\n",
      "1216/7352 [===>..........................] - ETA: 16s - loss: 0.3488 - accuracy: 0.8840INFO:tensorflow:For batch 19, loss is    0.49.\n",
      "INFO:tensorflow:For batch 19, accuracy is    0.88.\n",
      "1280/7352 [====>.........................] - ETA: 17s - loss: 0.3558 - accuracy: 0.8820INFO:tensorflow:For batch 20, loss is    0.45.\n",
      "INFO:tensorflow:For batch 20, accuracy is    0.88.\n",
      "1344/7352 [====>.........................] - ETA: 16s - loss: 0.3601 - accuracy: 0.8817INFO:tensorflow:For batch 21, loss is    0.38.\n",
      "INFO:tensorflow:For batch 21, accuracy is    0.88.\n",
      "1408/7352 [====>.........................] - ETA: 16s - loss: 0.3613 - accuracy: 0.8807INFO:tensorflow:For batch 22, loss is    0.35.\n",
      "INFO:tensorflow:For batch 22, accuracy is    0.88.\n",
      "1472/7352 [=====>........................] - ETA: 16s - loss: 0.3606 - accuracy: 0.8798INFO:tensorflow:For batch 23, loss is    0.41.\n",
      "INFO:tensorflow:For batch 23, accuracy is    0.88.\n",
      "1536/7352 [=====>........................] - ETA: 16s - loss: 0.3626 - accuracy: 0.8802INFO:tensorflow:For batch 24, loss is    0.31.\n",
      "INFO:tensorflow:For batch 24, accuracy is    0.88.\n",
      "1600/7352 [=====>........................] - ETA: 15s - loss: 0.3604 - accuracy: 0.8806INFO:tensorflow:For batch 25, loss is    0.23.\n",
      "INFO:tensorflow:For batch 25, accuracy is    0.88.\n",
      "1664/7352 [=====>........................] - ETA: 16s - loss: 0.3553 - accuracy: 0.8822INFO:tensorflow:For batch 26, loss is    0.20.\n",
      "INFO:tensorflow:For batch 26, accuracy is    0.88.\n",
      "1728/7352 [======>.......................] - ETA: 15s - loss: 0.3497 - accuracy: 0.8843INFO:tensorflow:For batch 27, loss is    0.30.\n",
      "INFO:tensorflow:For batch 27, accuracy is    0.88.\n",
      "1792/7352 [======>.......................] - ETA: 15s - loss: 0.3479 - accuracy: 0.8828INFO:tensorflow:For batch 28, loss is    0.24.\n",
      "INFO:tensorflow:For batch 28, accuracy is    0.89.\n",
      "1856/7352 [======>.......................] - ETA: 15s - loss: 0.3443 - accuracy: 0.8852INFO:tensorflow:For batch 29, loss is    0.21.\n",
      "INFO:tensorflow:For batch 29, accuracy is    0.89.\n",
      "1920/7352 [======>.......................] - ETA: 15s - loss: 0.3396 - accuracy: 0.8880INFO:tensorflow:For batch 30, loss is    0.24.\n",
      "INFO:tensorflow:For batch 30, accuracy is    0.89.\n",
      "1984/7352 [=======>......................] - ETA: 15s - loss: 0.3364 - accuracy: 0.8896INFO:tensorflow:For batch 31, loss is    0.21.\n",
      "INFO:tensorflow:For batch 31, accuracy is    0.89.\n",
      "2048/7352 [=======>......................] - ETA: 14s - loss: 0.3325 - accuracy: 0.8916INFO:tensorflow:For batch 32, loss is    0.23.\n",
      "INFO:tensorflow:For batch 32, accuracy is    0.89.\n",
      "2112/7352 [=======>......................] - ETA: 14s - loss: 0.3294 - accuracy: 0.8930INFO:tensorflow:For batch 33, loss is    0.14.\n",
      "INFO:tensorflow:For batch 33, accuracy is    0.89.\n",
      "2176/7352 [=======>......................] - ETA: 14s - loss: 0.3239 - accuracy: 0.8948INFO:tensorflow:For batch 34, loss is    0.18.\n",
      "INFO:tensorflow:For batch 34, accuracy is    0.90.\n",
      "2240/7352 [========>.....................] - ETA: 14s - loss: 0.3199 - accuracy: 0.8969INFO:tensorflow:For batch 35, loss is    0.25.\n",
      "INFO:tensorflow:For batch 35, accuracy is    0.90.\n",
      "2304/7352 [========>.....................] - ETA: 14s - loss: 0.3179 - accuracy: 0.8971INFO:tensorflow:For batch 36, loss is    0.40.\n",
      "INFO:tensorflow:For batch 36, accuracy is    0.90.\n",
      "2368/7352 [========>.....................] - ETA: 14s - loss: 0.3201 - accuracy: 0.8965INFO:tensorflow:For batch 37, loss is    0.62.\n",
      "INFO:tensorflow:For batch 37, accuracy is    0.89.\n",
      "2432/7352 [========>.....................] - ETA: 14s - loss: 0.3279 - accuracy: 0.8935INFO:tensorflow:For batch 38, loss is    0.35.\n",
      "INFO:tensorflow:For batch 38, accuracy is    0.89.\n",
      "2496/7352 [=========>....................] - ETA: 14s - loss: 0.3285 - accuracy: 0.8938INFO:tensorflow:For batch 39, loss is    0.26.\n",
      "INFO:tensorflow:For batch 39, accuracy is    0.89.\n",
      "2560/7352 [=========>....................] - ETA: 13s - loss: 0.3268 - accuracy: 0.8930INFO:tensorflow:For batch 40, loss is    0.14.\n",
      "INFO:tensorflow:For batch 40, accuracy is    0.89.\n",
      "2624/7352 [=========>....................] - ETA: 13s - loss: 0.3224 - accuracy: 0.8948INFO:tensorflow:For batch 41, loss is    0.23.\n",
      "INFO:tensorflow:For batch 41, accuracy is    0.90.\n",
      "2688/7352 [=========>....................] - ETA: 13s - loss: 0.3202 - accuracy: 0.8958INFO:tensorflow:For batch 42, loss is    0.26.\n",
      "INFO:tensorflow:For batch 42, accuracy is    0.90.\n",
      "2752/7352 [==========>...................] - ETA: 13s - loss: 0.3187 - accuracy: 0.8961INFO:tensorflow:For batch 43, loss is    0.49.\n",
      "INFO:tensorflow:For batch 43, accuracy is    0.89.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2816/7352 [==========>...................] - ETA: 13s - loss: 0.3227 - accuracy: 0.8942INFO:tensorflow:For batch 44, loss is    0.21.\n",
      "INFO:tensorflow:For batch 44, accuracy is    0.90.\n",
      "2880/7352 [==========>...................] - ETA: 13s - loss: 0.3203 - accuracy: 0.8951INFO:tensorflow:For batch 45, loss is    0.18.\n",
      "INFO:tensorflow:For batch 45, accuracy is    0.90.\n",
      "2944/7352 [===========>..................] - ETA: 12s - loss: 0.3173 - accuracy: 0.8967INFO:tensorflow:For batch 46, loss is    0.19.\n",
      "INFO:tensorflow:For batch 46, accuracy is    0.90.\n",
      "3008/7352 [===========>..................] - ETA: 12s - loss: 0.3144 - accuracy: 0.8979INFO:tensorflow:For batch 47, loss is    0.34.\n",
      "INFO:tensorflow:For batch 47, accuracy is    0.90.\n",
      "3072/7352 [===========>..................] - ETA: 12s - loss: 0.3149 - accuracy: 0.8975INFO:tensorflow:For batch 48, loss is    0.33.\n",
      "INFO:tensorflow:For batch 48, accuracy is    0.90.\n",
      "3136/7352 [===========>..................] - ETA: 12s - loss: 0.3153 - accuracy: 0.8976INFO:tensorflow:For batch 49, loss is    0.13.\n",
      "INFO:tensorflow:For batch 49, accuracy is    0.90.\n",
      "3200/7352 [============>.................] - ETA: 11s - loss: 0.3116 - accuracy: 0.8991INFO:tensorflow:For batch 50, loss is    0.22.\n",
      "INFO:tensorflow:For batch 50, accuracy is    0.90.\n",
      "3264/7352 [============>.................] - ETA: 11s - loss: 0.3098 - accuracy: 0.8992INFO:tensorflow:For batch 51, loss is    0.38.\n",
      "INFO:tensorflow:For batch 51, accuracy is    0.90.\n",
      "3328/7352 [============>.................] - ETA: 11s - loss: 0.3111 - accuracy: 0.8984INFO:tensorflow:For batch 52, loss is    0.33.\n",
      "INFO:tensorflow:For batch 52, accuracy is    0.90.\n",
      "3392/7352 [============>.................] - ETA: 11s - loss: 0.3115 - accuracy: 0.8977INFO:tensorflow:For batch 53, loss is    0.22.\n",
      "INFO:tensorflow:For batch 53, accuracy is    0.90.\n",
      "3456/7352 [=============>................] - ETA: 11s - loss: 0.3098 - accuracy: 0.8987INFO:tensorflow:For batch 54, loss is    0.22.\n",
      "INFO:tensorflow:For batch 54, accuracy is    0.90.\n",
      "3520/7352 [=============>................] - ETA: 10s - loss: 0.3081 - accuracy: 0.8991INFO:tensorflow:For batch 55, loss is    0.26.\n",
      "INFO:tensorflow:For batch 55, accuracy is    0.90.\n",
      "3584/7352 [=============>................] - ETA: 10s - loss: 0.3071 - accuracy: 0.8998INFO:tensorflow:For batch 56, loss is    0.30.\n",
      "INFO:tensorflow:For batch 56, accuracy is    0.90.\n",
      "3648/7352 [=============>................] - ETA: 10s - loss: 0.3071 - accuracy: 0.8997INFO:tensorflow:For batch 57, loss is    0.22.\n",
      "INFO:tensorflow:For batch 57, accuracy is    0.90.\n",
      "3712/7352 [==============>...............] - ETA: 10s - loss: 0.3055 - accuracy: 0.9003INFO:tensorflow:For batch 58, loss is    0.28.\n",
      "INFO:tensorflow:For batch 58, accuracy is    0.90.\n",
      "3776/7352 [==============>...............] - ETA: 10s - loss: 0.3050 - accuracy: 0.8996INFO:tensorflow:For batch 59, loss is    0.32.\n",
      "INFO:tensorflow:For batch 59, accuracy is    0.90.\n",
      "3840/7352 [==============>...............] - ETA: 9s - loss: 0.3052 - accuracy: 0.8992 INFO:tensorflow:For batch 60, loss is    0.27.\n",
      "INFO:tensorflow:For batch 60, accuracy is    0.90.\n",
      "3904/7352 [==============>...............] - ETA: 9s - loss: 0.3047 - accuracy: 0.8993INFO:tensorflow:For batch 61, loss is    0.24.\n",
      "INFO:tensorflow:For batch 61, accuracy is    0.90.\n",
      "3968/7352 [===============>..............] - ETA: 9s - loss: 0.3037 - accuracy: 0.8997INFO:tensorflow:For batch 62, loss is    0.29.\n",
      "INFO:tensorflow:For batch 62, accuracy is    0.90.\n",
      "4032/7352 [===============>..............] - ETA: 9s - loss: 0.3036 - accuracy: 0.8998INFO:tensorflow:For batch 63, loss is    0.24.\n",
      "INFO:tensorflow:For batch 63, accuracy is    0.90.\n",
      "4096/7352 [===============>..............] - ETA: 9s - loss: 0.3025 - accuracy: 0.9009INFO:tensorflow:For batch 64, loss is    0.21.\n",
      "INFO:tensorflow:For batch 64, accuracy is    0.90.\n",
      "4160/7352 [===============>..............] - ETA: 8s - loss: 0.3011 - accuracy: 0.9012INFO:tensorflow:For batch 65, loss is    0.30.\n",
      "INFO:tensorflow:For batch 65, accuracy is    0.90.\n",
      "4224/7352 [================>.............] - ETA: 8s - loss: 0.3012 - accuracy: 0.9013INFO:tensorflow:For batch 66, loss is    0.20.\n",
      "INFO:tensorflow:For batch 66, accuracy is    0.90.\n",
      "4288/7352 [================>.............] - ETA: 8s - loss: 0.2996 - accuracy: 0.9018INFO:tensorflow:For batch 67, loss is    0.24.\n",
      "INFO:tensorflow:For batch 67, accuracy is    0.90.\n",
      "4352/7352 [================>.............] - ETA: 8s - loss: 0.2988 - accuracy: 0.9019INFO:tensorflow:For batch 68, loss is    0.15.\n",
      "INFO:tensorflow:For batch 68, accuracy is    0.90.\n",
      "4416/7352 [=================>............] - ETA: 8s - loss: 0.2967 - accuracy: 0.9024INFO:tensorflow:For batch 69, loss is    0.19.\n",
      "INFO:tensorflow:For batch 69, accuracy is    0.90.\n",
      "4480/7352 [=================>............] - ETA: 7s - loss: 0.2952 - accuracy: 0.9027INFO:tensorflow:For batch 70, loss is    0.27.\n",
      "INFO:tensorflow:For batch 70, accuracy is    0.90.\n",
      "4544/7352 [=================>............] - ETA: 7s - loss: 0.2948 - accuracy: 0.9025INFO:tensorflow:For batch 71, loss is    0.17.\n",
      "INFO:tensorflow:For batch 71, accuracy is    0.90.\n",
      "4608/7352 [=================>............] - ETA: 7s - loss: 0.2930 - accuracy: 0.9030INFO:tensorflow:For batch 72, loss is    0.28.\n",
      "INFO:tensorflow:For batch 72, accuracy is    0.90.\n",
      "4672/7352 [==================>...........] - ETA: 7s - loss: 0.2929 - accuracy: 0.9028INFO:tensorflow:For batch 73, loss is    0.47.\n",
      "INFO:tensorflow:For batch 73, accuracy is    0.90.\n",
      "4736/7352 [==================>...........] - ETA: 7s - loss: 0.2953 - accuracy: 0.9020INFO:tensorflow:For batch 74, loss is    0.24.\n",
      "INFO:tensorflow:For batch 74, accuracy is    0.90.\n",
      "4800/7352 [==================>...........] - ETA: 7s - loss: 0.2945 - accuracy: 0.9021INFO:tensorflow:For batch 75, loss is    0.27.\n",
      "INFO:tensorflow:For batch 75, accuracy is    0.90.\n",
      "4864/7352 [==================>...........] - ETA: 6s - loss: 0.2942 - accuracy: 0.9015INFO:tensorflow:For batch 76, loss is    0.21.\n",
      "INFO:tensorflow:For batch 76, accuracy is    0.90.\n",
      "4928/7352 [===================>..........] - ETA: 6s - loss: 0.2931 - accuracy: 0.9020INFO:tensorflow:For batch 77, loss is    0.33.\n",
      "INFO:tensorflow:For batch 77, accuracy is    0.90.\n",
      "4992/7352 [===================>..........] - ETA: 6s - loss: 0.2935 - accuracy: 0.9022INFO:tensorflow:For batch 78, loss is    0.19.\n",
      "INFO:tensorflow:For batch 78, accuracy is    0.90.\n",
      "5056/7352 [===================>..........] - ETA: 6s - loss: 0.2922 - accuracy: 0.9027INFO:tensorflow:For batch 79, loss is    0.54.\n",
      "INFO:tensorflow:For batch 79, accuracy is    0.90.\n",
      "5120/7352 [===================>..........] - ETA: 6s - loss: 0.2953 - accuracy: 0.9021INFO:tensorflow:For batch 80, loss is    0.29.\n",
      "INFO:tensorflow:For batch 80, accuracy is    0.90.\n",
      "5184/7352 [====================>.........] - ETA: 5s - loss: 0.2952 - accuracy: 0.9020INFO:tensorflow:For batch 81, loss is    0.18.\n",
      "INFO:tensorflow:For batch 81, accuracy is    0.90.\n",
      "5248/7352 [====================>.........] - ETA: 5s - loss: 0.2939 - accuracy: 0.9022INFO:tensorflow:For batch 82, loss is    0.19.\n",
      "INFO:tensorflow:For batch 82, accuracy is    0.90.\n",
      "5312/7352 [====================>.........] - ETA: 5s - loss: 0.2926 - accuracy: 0.9029INFO:tensorflow:For batch 83, loss is    0.29.\n",
      "INFO:tensorflow:For batch 83, accuracy is    0.90.\n",
      "5376/7352 [====================>.........] - ETA: 5s - loss: 0.2926 - accuracy: 0.9027INFO:tensorflow:For batch 84, loss is    0.28.\n",
      "INFO:tensorflow:For batch 84, accuracy is    0.90.\n",
      "5440/7352 [=====================>........] - ETA: 5s - loss: 0.2924 - accuracy: 0.9026INFO:tensorflow:For batch 85, loss is    0.16.\n",
      "INFO:tensorflow:For batch 85, accuracy is    0.90.\n",
      "5504/7352 [=====================>........] - ETA: 5s - loss: 0.2909 - accuracy: 0.9028INFO:tensorflow:For batch 86, loss is    0.26.\n",
      "INFO:tensorflow:For batch 86, accuracy is    0.90.\n",
      "5568/7352 [=====================>........] - ETA: 4s - loss: 0.2905 - accuracy: 0.9028INFO:tensorflow:For batch 87, loss is    0.26.\n",
      "INFO:tensorflow:For batch 87, accuracy is    0.90.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632/7352 [=====================>........] - ETA: 4s - loss: 0.2902 - accuracy: 0.9029INFO:tensorflow:For batch 88, loss is    0.21.\n",
      "INFO:tensorflow:For batch 88, accuracy is    0.90.\n",
      "5696/7352 [======================>.......] - ETA: 4s - loss: 0.2893 - accuracy: 0.9033INFO:tensorflow:For batch 89, loss is    0.25.\n",
      "INFO:tensorflow:For batch 89, accuracy is    0.90.\n",
      "5760/7352 [======================>.......] - ETA: 4s - loss: 0.2889 - accuracy: 0.9033INFO:tensorflow:For batch 90, loss is    0.21.\n",
      "INFO:tensorflow:For batch 90, accuracy is    0.90.\n",
      "5824/7352 [======================>.......] - ETA: 4s - loss: 0.2880 - accuracy: 0.9037INFO:tensorflow:For batch 91, loss is    0.11.\n",
      "INFO:tensorflow:For batch 91, accuracy is    0.90.\n",
      "5888/7352 [=======================>......] - ETA: 3s - loss: 0.2861 - accuracy: 0.9044INFO:tensorflow:For batch 92, loss is    0.23.\n",
      "INFO:tensorflow:For batch 92, accuracy is    0.90.\n",
      "5952/7352 [=======================>......] - ETA: 3s - loss: 0.2854 - accuracy: 0.9044INFO:tensorflow:For batch 93, loss is    0.15.\n",
      "INFO:tensorflow:For batch 93, accuracy is    0.90.\n",
      "6016/7352 [=======================>......] - ETA: 3s - loss: 0.2840 - accuracy: 0.9049INFO:tensorflow:For batch 94, loss is    0.27.\n",
      "INFO:tensorflow:For batch 94, accuracy is    0.90.\n",
      "6080/7352 [=======================>......] - ETA: 3s - loss: 0.2838 - accuracy: 0.9049INFO:tensorflow:For batch 95, loss is    0.27.\n",
      "INFO:tensorflow:For batch 95, accuracy is    0.91.\n",
      "6144/7352 [========================>.....] - ETA: 3s - loss: 0.2837 - accuracy: 0.9053INFO:tensorflow:For batch 96, loss is    0.43.\n",
      "INFO:tensorflow:For batch 96, accuracy is    0.90.\n",
      "6208/7352 [========================>.....] - ETA: 3s - loss: 0.2851 - accuracy: 0.9050INFO:tensorflow:For batch 97, loss is    0.31.\n",
      "INFO:tensorflow:For batch 97, accuracy is    0.91.\n",
      "6272/7352 [========================>.....] - ETA: 2s - loss: 0.2854 - accuracy: 0.9051INFO:tensorflow:For batch 98, loss is    0.16.\n",
      "INFO:tensorflow:For batch 98, accuracy is    0.91.\n",
      "6336/7352 [========================>.....] - ETA: 2s - loss: 0.2841 - accuracy: 0.9058INFO:tensorflow:For batch 99, loss is    0.12.\n",
      "INFO:tensorflow:For batch 99, accuracy is    0.91.\n",
      "6400/7352 [=========================>....] - ETA: 2s - loss: 0.2825 - accuracy: 0.9064INFO:tensorflow:For batch 100, loss is    0.26.\n",
      "INFO:tensorflow:For batch 100, accuracy is    0.91.\n",
      "6464/7352 [=========================>....] - ETA: 2s - loss: 0.2823 - accuracy: 0.9064INFO:tensorflow:For batch 101, loss is    0.11.\n",
      "INFO:tensorflow:For batch 101, accuracy is    0.91.\n",
      "6528/7352 [=========================>....] - ETA: 2s - loss: 0.2806 - accuracy: 0.9072INFO:tensorflow:For batch 102, loss is    0.17.\n",
      "INFO:tensorflow:For batch 102, accuracy is    0.91.\n",
      "6592/7352 [=========================>....] - ETA: 2s - loss: 0.2795 - accuracy: 0.9073INFO:tensorflow:For batch 103, loss is    0.23.\n",
      "INFO:tensorflow:For batch 103, accuracy is    0.91.\n",
      "6656/7352 [==========================>...] - ETA: 1s - loss: 0.2791 - accuracy: 0.9078INFO:tensorflow:For batch 104, loss is    0.19.\n",
      "INFO:tensorflow:For batch 104, accuracy is    0.91.\n",
      "6720/7352 [==========================>...] - ETA: 1s - loss: 0.2783 - accuracy: 0.9079INFO:tensorflow:For batch 105, loss is    0.21.\n",
      "INFO:tensorflow:For batch 105, accuracy is    0.91.\n",
      "6784/7352 [==========================>...] - ETA: 1s - loss: 0.2776 - accuracy: 0.9080INFO:tensorflow:For batch 106, loss is    0.17.\n",
      "INFO:tensorflow:For batch 106, accuracy is    0.91.\n",
      "6848/7352 [==========================>...] - ETA: 1s - loss: 0.2766 - accuracy: 0.9083INFO:tensorflow:For batch 107, loss is    0.20.\n",
      "INFO:tensorflow:For batch 107, accuracy is    0.91.\n",
      "6912/7352 [===========================>..] - ETA: 1s - loss: 0.2759 - accuracy: 0.9084INFO:tensorflow:For batch 108, loss is    0.14.\n",
      "INFO:tensorflow:For batch 108, accuracy is    0.91.\n",
      "6976/7352 [===========================>..] - ETA: 1s - loss: 0.2746 - accuracy: 0.9088INFO:tensorflow:For batch 109, loss is    0.17.\n",
      "INFO:tensorflow:For batch 109, accuracy is    0.91.\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.2737 - accuracy: 0.9088INFO:tensorflow:For batch 110, loss is    0.21.\n",
      "INFO:tensorflow:For batch 110, accuracy is    0.91.\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.2731 - accuracy: 0.9086INFO:tensorflow:For batch 111, loss is    0.08.\n",
      "INFO:tensorflow:For batch 111, accuracy is    0.91.\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.2714 - accuracy: 0.9093INFO:tensorflow:For batch 112, loss is    0.07.\n",
      "INFO:tensorflow:For batch 112, accuracy is    0.91.\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.2697 - accuracy: 0.9101INFO:tensorflow:For batch 113, loss is    0.13.\n",
      "INFO:tensorflow:For batch 113, accuracy is    0.91.\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.2685 - accuracy: 0.9105INFO:tensorflow:For batch 114, loss is    0.13.\n",
      "INFO:tensorflow:For batch 114, accuracy is    0.91.\n",
      "INFO:tensorflow:weights of 1 layers for epoch4 is [array([[ 0.03507403,  0.0488102 , -0.06708954, ..., -0.11654224,\n",
      "        -0.08119091, -0.10899276],\n",
      "       [-0.05426738, -0.11601762,  0.04823067, ..., -0.00674819,\n",
      "        -0.01502777,  0.055912  ],\n",
      "       [-0.01014902,  0.10459638, -0.07741244, ..., -0.04832231,\n",
      "        -0.05593392, -0.05677256],\n",
      "       ...,\n",
      "       [-0.04124802, -0.0549587 , -0.16291165, ..., -0.16974643,\n",
      "        -0.28657618,  0.04524269],\n",
      "       [-0.00069547,  0.07297212,  0.07826004, ..., -0.05246703,\n",
      "         0.25074318, -0.00926732],\n",
      "       [-0.1584935 ,  0.14417766,  0.00316331, ..., -0.13312757,\n",
      "         0.13236564,  0.04567106]], dtype=float32), array([[-0.03651263,  0.07863253, -0.0034133 , ..., -0.1479446 ,\n",
      "        -0.07062086,  0.00671507],\n",
      "       [-0.11331627,  0.1036936 , -0.03220894, ...,  0.1433405 ,\n",
      "         0.01986539,  0.06189055],\n",
      "       [ 0.0398689 , -0.03544417, -0.00692765, ..., -0.02902936,\n",
      "        -0.06041261, -0.01660094],\n",
      "       ...,\n",
      "       [-0.01310402,  0.0674362 , -0.04305484, ...,  0.0599024 ,\n",
      "         0.05640565,  0.04072689],\n",
      "       [ 0.08478287,  0.03011799,  0.00836716, ...,  0.02183385,\n",
      "        -0.01951405, -0.00291901],\n",
      "       [-0.10582038, -0.05488774,  0.08589648, ..., -0.07153662,\n",
      "         0.04303051, -0.05512044]], dtype=float32), array([ 2.89773848e-02,  5.41647151e-03,  1.73661783e-02,  4.56719287e-03,\n",
      "        3.84264924e-02, -1.25322910e-02, -8.89675319e-03,  2.95181423e-02,\n",
      "        6.45771157e-03,  5.16505679e-04,  2.78471969e-02,  1.17980549e-02,\n",
      "       -9.50010121e-03, -6.17404189e-03,  1.92885213e-02, -1.24297701e-02,\n",
      "       -1.37927721e-03,  2.88835168e-03,  4.26313933e-03,  8.94045085e-03,\n",
      "        2.00323630e-02,  4.07855436e-02,  1.78033169e-02, -8.96463078e-03,\n",
      "        1.99791044e-03,  4.53026555e-02, -1.57564674e-02,  3.49670462e-02,\n",
      "        5.02539333e-03,  4.46193255e-02, -1.48371151e-02, -2.10824050e-03,\n",
      "        1.37892750e-03,  1.46215400e-02,  2.18971465e-02, -4.44850372e-03,\n",
      "        1.77720226e-02,  4.48170714e-02,  2.86006518e-02,  3.85364937e-03,\n",
      "        1.03074117e-02,  1.04040205e-02,  1.81862246e-02,  1.89071670e-02,\n",
      "        2.33256873e-02, -1.79450307e-02,  1.23993773e-02,  8.43974948e-03,\n",
      "       -2.53840480e-02,  1.55688012e-02,  1.22557580e-02,  2.99924128e-02,\n",
      "        3.73319574e-02,  2.74818223e-02,  1.77727789e-02,  2.99783628e-02,\n",
      "        2.91488897e-02,  1.19367121e-02,  2.67914515e-02,  8.78578797e-03,\n",
      "       -1.54078007e-02,  1.86581146e-02,  8.49258061e-03,  2.56629474e-02,\n",
      "        2.89121810e-02,  9.17605590e-03,  1.49612641e-02,  2.43068896e-02,\n",
      "        4.02648514e-03,  1.51490197e-02,  1.17254732e-02,  5.11792712e-02,\n",
      "        9.93815996e-03,  4.69177552e-02,  1.63997933e-02, -2.05746926e-02,\n",
      "       -9.61195037e-04,  2.88727395e-02,  2.06645615e-02,  1.90038383e-02,\n",
      "        3.20982300e-02,  2.38146521e-02,  1.76600367e-02,  5.50465286e-03,\n",
      "       -3.34020369e-02,  3.91917415e-02,  1.49561111e-02,  4.44685778e-04,\n",
      "       -1.08403694e-02,  5.71432570e-03,  1.21048326e-02,  3.12767625e-02,\n",
      "        7.74612231e-03,  3.41303200e-02,  2.60859057e-02,  4.99251410e-02,\n",
      "        5.20894770e-03, -2.31540296e-03, -3.04454734e-05,  3.23018129e-03,\n",
      "        1.00784266e+00,  1.00599635e+00,  1.03455412e+00,  1.01376688e+00,\n",
      "        1.04515481e+00,  1.01553369e+00,  9.97754514e-01,  1.05244195e+00,\n",
      "        1.01073575e+00,  1.00056434e+00,  1.03388393e+00,  1.01626539e+00,\n",
      "        9.90813553e-01,  1.00943565e+00,  1.02756691e+00,  9.90510523e-01,\n",
      "        1.00636137e+00,  1.01940227e+00,  1.00011420e+00,  1.01970458e+00,\n",
      "        1.02436352e+00,  1.04777908e+00,  1.03148663e+00,  9.97007370e-01,\n",
      "        1.01612747e+00,  1.02483046e+00,  9.83981192e-01,  1.07028186e+00,\n",
      "        1.01306379e+00,  1.04926646e+00,  9.95551527e-01,  1.01786697e+00,\n",
      "        1.01402116e+00,  1.01709235e+00,  1.03620636e+00,  1.00002337e+00,\n",
      "        1.02180648e+00,  1.03776789e+00,  1.05308497e+00,  1.00648963e+00,\n",
      "        1.01777387e+00,  1.06354022e+00,  1.02199900e+00,  1.03280902e+00,\n",
      "        1.03783166e+00,  9.85684156e-01,  1.02278697e+00,  1.02015388e+00,\n",
      "        9.66121376e-01,  1.02307820e+00,  1.01976228e+00,  1.03846049e+00,\n",
      "        1.10011160e+00,  1.03959405e+00,  1.01563203e+00,  1.05024433e+00,\n",
      "        1.01717067e+00,  1.00550878e+00,  1.04853606e+00,  1.01696467e+00,\n",
      "        9.82085049e-01,  1.04108620e+00,  1.03166163e+00,  1.02773750e+00,\n",
      "        1.03923881e+00,  1.02797580e+00,  1.01512301e+00,  1.00957477e+00,\n",
      "        1.02835202e+00,  1.02006710e+00,  1.01538599e+00,  1.05368292e+00,\n",
      "        1.01227820e+00,  1.05722582e+00,  1.01998878e+00,  9.84720886e-01,\n",
      "        1.00315356e+00,  1.02205563e+00,  1.02449965e+00,  1.01399326e+00,\n",
      "        1.06479228e+00,  1.02834547e+00,  1.02292442e+00,  1.00172460e+00,\n",
      "        9.76669908e-01,  1.03442597e+00,  1.01402175e+00,  1.00371563e+00,\n",
      "        9.87775028e-01,  1.00325775e+00,  1.00606441e+00,  1.02893925e+00,\n",
      "        1.01137257e+00,  1.03425455e+00,  1.04504561e+00,  1.06849253e+00,\n",
      "        1.00634968e+00,  1.01019967e+00,  1.02520704e+00,  1.00633359e+00,\n",
      "       -1.55323243e-03, -6.84958766e-04,  1.15575092e-02,  7.41309114e-03,\n",
      "       -1.51432091e-02, -6.24328554e-02,  2.72435397e-02,  1.77578349e-03,\n",
      "       -3.15308310e-02,  2.06304938e-02, -2.73056291e-02,  1.60399731e-03,\n",
      "       -3.81252468e-02, -1.30903134e-02, -2.72596604e-04,  1.81708541e-02,\n",
      "        4.17932458e-02,  7.88475573e-03,  2.77637709e-02, -2.82189101e-02,\n",
      "       -9.47584584e-03, -1.91155672e-02,  1.25035010e-02, -1.33777708e-02,\n",
      "       -2.87789125e-02, -4.56940793e-02, -3.79247330e-02,  4.08980772e-02,\n",
      "       -4.90524620e-02,  1.27406204e-02, -2.34276075e-02,  1.44167263e-02,\n",
      "       -4.76771314e-03, -3.10509149e-02,  7.56002171e-03,  2.06058677e-02,\n",
      "       -2.50968505e-02, -3.16414982e-02, -6.04027091e-03,  4.05362211e-02,\n",
      "       -2.23163720e-02, -8.32698587e-03,  1.19581288e-02, -1.51240537e-02,\n",
      "        1.44506013e-02, -4.29247804e-02, -1.33781852e-02,  7.61684123e-03,\n",
      "       -3.41717117e-02,  1.21852532e-02,  2.45592128e-02,  1.42002967e-03,\n",
      "        1.38991456e-02, -7.83493556e-03, -3.87236290e-02, -1.38347093e-02,\n",
      "       -1.80635974e-02,  2.51005627e-02,  2.72670574e-02,  1.03462879e-02,\n",
      "       -2.34852117e-02, -7.03920936e-03, -1.22835729e-02, -2.42007822e-02,\n",
      "       -2.60997247e-02,  2.26118080e-02,  9.96934995e-03, -4.33481187e-02,\n",
      "       -2.85152476e-02, -2.64906958e-02, -4.94699515e-02, -2.06160359e-02,\n",
      "       -2.22098269e-02, -3.33242379e-02,  3.82541679e-02,  2.48439964e-02,\n",
      "       -3.35256234e-02, -9.46200080e-03, -8.37346725e-03, -5.73262339e-03,\n",
      "       -2.78903190e-02, -5.62839443e-03, -2.07758080e-02,  9.94090643e-03,\n",
      "        1.68433972e-02, -1.30822342e-02, -1.96473692e-02,  4.16475348e-02,\n",
      "       -2.92369816e-02,  2.78015528e-02,  1.29334712e-02,  1.88361965e-02,\n",
      "        2.25450620e-02,  2.23979652e-02,  1.09314192e-02, -8.04590248e-03,\n",
      "        3.28322537e-02,  1.28413681e-02, -4.24918951e-03,  1.43098030e-02,\n",
      "        3.25393304e-02,  9.50002298e-03,  6.70702616e-03, -1.03423576e-04,\n",
      "        4.17278185e-02,  4.75425739e-03, -1.04555152e-02,  4.33383211e-02,\n",
      "        8.65390524e-03, -2.53335136e-04,  2.06156597e-02,  1.91213638e-02,\n",
      "       -1.12055643e-02, -1.28364814e-02,  2.77855173e-02, -1.55494744e-02,\n",
      "        5.93976304e-03,  1.89713556e-02, -1.68822904e-03,  2.50263456e-02,\n",
      "        2.43116599e-02,  2.30931882e-02,  2.75223255e-02,  2.11116509e-03,\n",
      "        4.29769419e-03,  4.84114587e-02, -1.19365389e-02,  7.26243034e-02,\n",
      "        1.35727990e-02,  4.07960564e-02, -8.24858248e-03,  5.79054002e-03,\n",
      "        2.04669152e-04,  1.75314173e-02,  1.54535640e-02, -5.50338672e-03,\n",
      "        2.38953326e-02,  6.11740611e-02,  4.05939035e-02,  6.49120100e-03,\n",
      "        1.51720736e-02,  5.43079562e-02,  1.74872316e-02,  1.67275555e-02,\n",
      "        3.77597064e-02, -1.79495513e-02,  1.81573466e-03,  1.12461587e-02,\n",
      "       -2.34932583e-02,  1.80313829e-02,  1.55041246e-02,  2.52630413e-02,\n",
      "        1.12716943e-01,  3.67506482e-02,  2.47806832e-02,  6.33108988e-02,\n",
      "        3.56467627e-02,  8.61176755e-03,  5.65385967e-02,  1.87082998e-02,\n",
      "       -1.72062330e-02,  1.84188113e-02,  9.36262123e-03,  1.92705709e-02,\n",
      "        3.37389708e-02,  3.03211436e-02,  9.69390757e-03,  2.38373335e-02,\n",
      "        1.06337331e-02,  2.02025566e-02,  1.71800684e-02,  7.73094818e-02,\n",
      "        1.31837288e-02,  5.71695827e-02,  3.14406417e-02, -1.72363371e-02,\n",
      "        2.92285415e-03,  2.70963181e-02,  4.09812145e-02,  2.70194951e-02,\n",
      "        5.06317466e-02,  1.21545577e-02,  2.68729795e-02, -6.13669492e-03,\n",
      "       -1.98676549e-02,  5.18302470e-02,  1.30844470e-02,  5.54216420e-03,\n",
      "       -9.80112329e-03,  4.64214664e-03,  7.81021733e-03,  2.54318137e-02,\n",
      "        9.63630062e-03,  3.13170776e-02,  4.96356152e-02,  6.39167875e-02,\n",
      "        1.02473237e-02,  6.33994467e-04,  3.33613763e-03,  3.06077860e-03],\n",
      "      dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:weights of 2 layers for epoch4 is []\n",
      "INFO:tensorflow:weights of 3 layers for epoch4 is [array([[-0.04996726,  0.15325978,  0.02750788, ..., -0.08094353,\n",
      "         0.01557807,  0.02685143],\n",
      "       [-0.03489072, -0.15696429, -0.10236818, ...,  0.08197119,\n",
      "        -0.16556898,  0.07022159],\n",
      "       [ 0.04911748,  0.2103134 , -0.08593546, ...,  0.14599553,\n",
      "         0.17170377, -0.02734803],\n",
      "       ...,\n",
      "       [ 0.17355657,  0.05241349, -0.22537103, ..., -0.10164401,\n",
      "         0.03599732,  0.11160706],\n",
      "       [ 0.05122318,  0.02423824, -0.11206194, ..., -0.12498829,\n",
      "         0.10656281,  0.00074325],\n",
      "       [ 0.06873391,  0.16110247, -0.05934371, ...,  0.09850153,\n",
      "        -0.0411213 ,  0.0534974 ]], dtype=float32), array([ 0.03719037, -0.00435611,  0.117798  ,  0.10981219, -0.02770588,\n",
      "        0.0717684 ,  0.02734701,  0.03886426,  0.00782489,  0.04921881,\n",
      "        0.09772774,  0.09246364,  0.0252832 ,  0.01524582,  0.10199089,\n",
      "        0.00383658,  0.02165579,  0.01761933,  0.13925445,  0.04743363,\n",
      "       -0.0017802 ,  0.1021194 ,  0.0101568 , -0.00047496,  0.06139348,\n",
      "        0.12679918,  0.05447932,  0.0502009 ,  0.04848015, -0.00128806,\n",
      "        0.0437298 ,  0.05396354, -0.00504394,  0.0059085 ,  0.01995086,\n",
      "       -0.02390169, -0.04326982,  0.08782852, -0.00268385, -0.01049448,\n",
      "        0.02987912,  0.0540532 ,  0.10168858, -0.00806234,  0.05263263,\n",
      "        0.02715928,  0.10169038,  0.0155646 ,  0.01521674,  0.07674588,\n",
      "       -0.00088801,  0.02245205, -0.02717316,  0.05604053,  0.11185877,\n",
      "        0.07176918,  0.00447119,  0.02792016,  0.07100084,  0.02557625,\n",
      "       -0.02849628, -0.00869731, -0.04079179,  0.09194088,  0.02097601,\n",
      "        0.0114131 ,  0.07427362,  0.04983989,  0.03650508,  0.02310197,\n",
      "        0.06343234,  0.01730704,  0.04342378, -0.06388032, -0.02103459,\n",
      "        0.05818293,  0.02165235,  0.03154083,  0.02882475,  0.00897273,\n",
      "        0.00609251,  0.02617658,  0.02450969,  0.06927752,  0.05125462,\n",
      "        0.02298681, -0.01369646,  0.02050712,  0.10275697,  0.00249159,\n",
      "        0.01135813,  0.05010324,  0.07794166,  0.07708243,  0.02068656,\n",
      "        0.06931698,  0.02177998,  0.0365257 ,  0.07549864, -0.05372484],\n",
      "      dtype=float32)]\n",
      "INFO:tensorflow:weights of 4 layers for epoch4 is [array([[-2.18148008e-02,  9.98969898e-02,  2.29234472e-01,\n",
      "        -8.59042406e-02, -3.23000625e-02, -2.14906245e-01],\n",
      "       [-2.19112933e-01, -1.21677384e-01, -5.57419658e-02,\n",
      "        -3.85965593e-02,  3.63954604e-02,  1.62296921e-01],\n",
      "       [ 1.65642068e-01,  7.23999366e-02,  2.03460515e-01,\n",
      "         1.23301759e-01,  1.75192744e-01, -2.79783547e-01],\n",
      "       [ 2.99698472e-01, -1.27991503e-02, -3.51714417e-02,\n",
      "        -2.42388129e-01,  1.17592970e-02, -3.59457284e-01],\n",
      "       [-7.20522553e-02,  1.22245938e-01, -2.70335883e-01,\n",
      "         1.12691224e-01, -8.78290534e-02,  2.43319616e-01],\n",
      "       [-9.28265750e-02,  1.25205755e-01,  1.68924913e-01,\n",
      "        -1.46119013e-01, -2.23882526e-01, -4.37029332e-01],\n",
      "       [ 5.93423378e-03,  8.38955268e-02, -1.23435043e-01,\n",
      "        -1.50568694e-01,  1.27163500e-01,  7.86385089e-02],\n",
      "       [-3.26611280e-01,  2.64936760e-02,  3.14301908e-01,\n",
      "        -1.55135244e-01, -3.80796120e-02,  5.08763781e-03],\n",
      "       [-1.12244688e-01, -1.30222842e-01,  2.74123102e-01,\n",
      "         2.13486012e-02, -7.74309412e-02, -2.38046288e-01],\n",
      "       [-2.84647703e-01,  2.42857233e-01,  1.01530321e-01,\n",
      "         4.15213890e-02, -3.84733942e-03,  2.31719747e-01],\n",
      "       [ 2.47178823e-01,  7.77064189e-02,  2.20949739e-01,\n",
      "        -1.06384225e-01,  9.46601555e-02, -2.91079301e-02],\n",
      "       [ 7.44735450e-02, -5.97453490e-02,  1.13463037e-01,\n",
      "        -2.88175583e-01, -2.35582501e-01, -3.73544633e-01],\n",
      "       [ 2.06478670e-01, -1.62945241e-01, -7.87896961e-02,\n",
      "        -1.26179203e-01, -1.04285143e-01,  2.17163727e-01],\n",
      "       [-2.38350287e-01, -2.33024567e-01, -5.03823236e-02,\n",
      "        -6.39120713e-02, -1.88902989e-01,  2.08296895e-01],\n",
      "       [ 2.32201472e-01, -1.14356034e-01,  2.13951007e-01,\n",
      "        -2.63659298e-01, -2.65283734e-01, -4.27276760e-01],\n",
      "       [-2.91863769e-01, -1.02495864e-01, -3.98117900e-02,\n",
      "         2.14141369e-01,  1.76087216e-01,  6.90768436e-02],\n",
      "       [-1.75371096e-01, -8.48196596e-02,  2.11451069e-01,\n",
      "         7.53898770e-02,  1.66418150e-01, -1.12880446e-01],\n",
      "       [ 8.10905322e-02,  1.82388604e-01, -6.06859140e-02,\n",
      "         1.53022543e-01, -9.59572569e-02, -3.56958359e-01],\n",
      "       [ 7.56303519e-02, -1.63741663e-01,  9.01116133e-02,\n",
      "        -7.87300095e-02, -5.92748150e-02, -3.97513479e-01],\n",
      "       [ 4.49782498e-02,  1.02230832e-01,  7.18823122e-03,\n",
      "        -4.46878634e-02,  2.50938267e-01, -3.04467916e-01],\n",
      "       [-1.76168784e-01,  6.42133504e-02, -3.22999135e-02,\n",
      "         1.19309604e-01, -1.87698349e-01,  1.24773711e-01],\n",
      "       [ 1.96907714e-01,  1.51148602e-01, -2.28292853e-01,\n",
      "        -4.81785648e-02,  9.83119830e-02, -3.68852437e-01],\n",
      "       [-1.94863275e-01, -1.84228495e-01, -1.63268045e-01,\n",
      "         7.18291402e-02,  1.94823381e-03, -2.47007757e-01],\n",
      "       [ 1.27936542e-01, -2.60382175e-01, -2.39923924e-01,\n",
      "         1.04499429e-01, -1.78947255e-01, -2.85561115e-01],\n",
      "       [-1.04457721e-01, -5.05409501e-02, -2.46171102e-01,\n",
      "         4.76810224e-02,  2.16215402e-02,  1.27736591e-02],\n",
      "       [ 2.31388852e-01, -9.34061185e-02,  2.00270876e-01,\n",
      "        -1.47381006e-02,  1.30384892e-01, -3.36766034e-01],\n",
      "       [ 1.69557840e-01, -5.50128333e-02, -2.73366421e-01,\n",
      "        -1.72072604e-01, -2.36400496e-02,  9.67305601e-02],\n",
      "       [-1.01977251e-02,  8.96021277e-02,  2.19600588e-01,\n",
      "        -5.61682172e-02, -1.08901002e-01,  8.92863348e-02],\n",
      "       [-3.41918200e-01, -1.95655167e-01, -2.35082343e-01,\n",
      "        -1.10465609e-01,  8.98874402e-02,  7.84685016e-02],\n",
      "       [-1.34231389e-01,  1.22102171e-01,  9.84606743e-02,\n",
      "         9.71856713e-02,  2.33933195e-01, -4.39008214e-02],\n",
      "       [-7.09195212e-02,  2.09848717e-01, -2.14395583e-01,\n",
      "        -1.54487625e-01, -1.33239269e-01,  1.83050379e-01],\n",
      "       [-3.39014083e-01, -1.26317665e-02,  2.79340237e-01,\n",
      "         8.46506432e-02, -2.41496518e-01,  5.39043732e-02],\n",
      "       [-2.40317732e-01, -1.47707731e-01,  2.59562116e-02,\n",
      "         1.27579525e-01, -2.39398643e-01,  1.20008569e-02],\n",
      "       [-1.18972056e-01,  4.77919839e-02, -1.91763774e-01,\n",
      "         1.61668509e-01, -2.50585198e-01,  2.62892693e-01],\n",
      "       [ 5.39567284e-02, -1.34478554e-01,  6.34658262e-02,\n",
      "        -1.31109342e-01, -2.16530472e-01,  2.32045352e-01],\n",
      "       [ 3.13718058e-02,  1.80553719e-01, -1.51179358e-01,\n",
      "         9.84491780e-02, -2.03878671e-01, -1.19650565e-01],\n",
      "       [ 1.09174363e-01,  9.66788605e-02, -1.76434055e-01,\n",
      "         1.45633817e-01, -2.12501228e-01,  1.53370231e-01],\n",
      "       [ 2.63456047e-01,  1.62100106e-01,  6.94246739e-02,\n",
      "        -3.90397996e-01, -1.52834594e-01, -2.12722883e-01],\n",
      "       [ 5.32354601e-02, -2.13098049e-01, -2.96942592e-01,\n",
      "         1.94574282e-01, -2.19860837e-01,  2.16817424e-01],\n",
      "       [-5.21722957e-02, -1.17012627e-01, -2.54527256e-02,\n",
      "         2.20163420e-01, -6.45223586e-03,  3.81737202e-02],\n",
      "       [-2.12133467e-01, -8.01219568e-02, -2.96280444e-01,\n",
      "         2.13912666e-01,  2.84457564e-01, -2.39454985e-01],\n",
      "       [-9.30356830e-02, -3.23195249e-01, -2.12298676e-01,\n",
      "         1.67272225e-01,  6.07195385e-02, -4.21307469e-03],\n",
      "       [ 1.08495608e-01,  1.52218759e-01, -3.26237321e-01,\n",
      "        -2.12758452e-01,  7.84570277e-02,  5.19514047e-02],\n",
      "       [-3.15399081e-01, -1.53500229e-01, -3.31124395e-01,\n",
      "         2.32291818e-01, -1.92775279e-01, -1.29650742e-01],\n",
      "       [-1.81144118e-01, -2.70986855e-01, -3.15227687e-01,\n",
      "         8.04651752e-02,  1.21644147e-01, -3.31904829e-01],\n",
      "       [-9.86973718e-02,  3.11335266e-01,  2.05998704e-01,\n",
      "         8.57737362e-02,  1.24762446e-01, -2.02495471e-01],\n",
      "       [ 1.47986561e-01, -2.32558593e-01, -6.90666437e-02,\n",
      "         6.17067255e-02,  1.35407791e-01, -1.37536362e-01],\n",
      "       [ 2.51384616e-01,  1.74464270e-01, -1.39433704e-02,\n",
      "        -3.63761298e-02, -1.49717465e-01,  4.83169630e-02],\n",
      "       [-9.67741944e-03,  2.56308198e-01, -5.72603755e-02,\n",
      "         5.84296249e-02, -2.86775470e-01, -1.77731737e-01],\n",
      "       [ 1.90856189e-01,  7.74972588e-02, -2.18919694e-01,\n",
      "         1.57865912e-01,  1.90421268e-01, -1.12383194e-01],\n",
      "       [-1.14396378e-01,  2.74078585e-02, -7.40139484e-02,\n",
      "        -2.36520946e-01,  1.45822793e-01,  1.40628189e-01],\n",
      "       [-1.21239893e-01, -2.50656605e-02, -2.21146941e-01,\n",
      "         1.18419692e-01, -9.49116126e-02,  2.63491362e-01],\n",
      "       [-1.56608820e-01,  6.57726377e-02, -1.77487224e-01,\n",
      "         1.68138400e-01, -2.34621078e-01,  5.29125743e-02],\n",
      "       [ 7.59538589e-03, -1.21958882e-01, -2.88337708e-01,\n",
      "         5.11787497e-02,  1.34628311e-01,  4.95128743e-02],\n",
      "       [ 1.13051243e-01, -3.73760276e-02,  1.71441212e-01,\n",
      "        -1.35893017e-01, -6.06778264e-02, -3.06634337e-01],\n",
      "       [ 1.86754361e-01, -1.65529609e-01,  2.79538780e-01,\n",
      "         1.05610229e-01, -2.47565240e-01, -3.88493359e-01],\n",
      "       [-1.16081201e-01, -2.74784446e-01, -7.98598453e-02,\n",
      "         1.20170504e-01, -1.29311517e-01,  2.49308184e-01],\n",
      "       [ 1.71734154e-01, -5.48690483e-02, -4.73259855e-03,\n",
      "        -2.92069628e-03, -6.99565485e-02,  1.66674927e-02],\n",
      "       [-1.74359187e-01, -8.84077251e-02, -3.58488619e-01,\n",
      "         7.98976421e-02,  8.92309323e-02,  3.69854197e-02],\n",
      "       [-1.73868183e-02,  1.98772579e-01,  1.81615114e-01,\n",
      "        -9.81600136e-02, -1.13127194e-01, -2.87279695e-01],\n",
      "       [-2.25082263e-01,  6.01077490e-02,  4.56668213e-02,\n",
      "         1.48966268e-01, -8.23464338e-03, -1.19937658e-01],\n",
      "       [ 4.96977232e-02, -1.92960426e-01,  4.55805175e-02,\n",
      "         1.65791065e-01, -2.26038471e-01,  1.71245635e-01],\n",
      "       [-3.61566767e-02, -1.62874222e-01, -2.54739046e-01,\n",
      "        -1.59184113e-01, -1.60204947e-01,  5.42341881e-02],\n",
      "       [ 1.36454523e-01,  2.36956879e-01,  2.42364034e-01,\n",
      "        -3.60050499e-01, -6.68654144e-02, -2.62915909e-01],\n",
      "       [ 8.37058946e-02, -4.96691540e-02, -1.31815657e-01,\n",
      "         5.74323274e-02, -1.58178166e-01,  2.73095638e-01],\n",
      "       [-2.53740668e-01, -1.15449570e-01,  1.26228696e-02,\n",
      "         1.36162832e-01, -1.56511933e-01,  2.23381549e-01],\n",
      "       [-8.65844786e-02,  1.19719639e-01,  2.14819551e-01,\n",
      "        -9.24307704e-02,  1.10881925e-02, -3.79305631e-01],\n",
      "       [-8.48625153e-02,  5.60656898e-02,  8.97296369e-02,\n",
      "        -4.06126538e-03, -1.87450700e-04,  1.46521553e-01],\n",
      "       [ 2.20952168e-01, -1.74370885e-01, -4.17783000e-02,\n",
      "         3.81513350e-02,  2.52752215e-01,  2.71430742e-02],\n",
      "       [-2.20231518e-01, -1.15735091e-01,  1.08079828e-01,\n",
      "         1.83125705e-01,  2.76015788e-01, -7.87038803e-02],\n",
      "       [ 2.93696314e-01, -1.64829209e-01,  5.48111200e-02,\n",
      "        -1.98861510e-01, -2.34650955e-01,  1.87535614e-01],\n",
      "       [-2.31992424e-01, -1.72374845e-01,  2.21477300e-02,\n",
      "        -2.37163439e-01, -8.85537118e-02,  2.26202235e-01],\n",
      "       [-1.47149581e-02,  2.67309994e-01,  8.86501372e-02,\n",
      "        -2.02960089e-01, -1.66190162e-01, -3.12019866e-02],\n",
      "       [-2.35864133e-01,  2.31215060e-01, -4.93541770e-02,\n",
      "         1.69433895e-02, -7.68059194e-02,  7.89140351e-04],\n",
      "       [-1.47942171e-01, -9.77971405e-02, -1.08361945e-01,\n",
      "        -7.27888420e-02,  1.54743306e-02,  1.31468192e-01],\n",
      "       [-3.02561540e-02, -2.83988923e-01, -8.26370995e-03,\n",
      "         2.12749451e-01,  2.50088215e-01, -2.37319991e-01],\n",
      "       [-1.94602609e-01, -3.65453772e-02,  1.16645381e-01,\n",
      "        -1.40012130e-01,  2.15362206e-01, -2.57356822e-01],\n",
      "       [-1.59448087e-01,  3.36780921e-02,  6.66438267e-02,\n",
      "        -2.60496140e-01, -2.89593399e-01, -1.57786414e-01],\n",
      "       [ 2.29161739e-01,  1.43668488e-01, -2.02260002e-01,\n",
      "        -1.00938506e-01, -1.05704814e-01, -2.97720999e-01],\n",
      "       [-1.27218589e-01,  1.59265101e-01, -4.16883491e-02,\n",
      "         1.79303996e-02,  2.36553684e-01, -2.75149077e-01],\n",
      "       [-1.97377384e-01, -2.09490507e-04, -2.27341652e-01,\n",
      "        -1.19140051e-01,  6.64831847e-02,  1.02758676e-01],\n",
      "       [ 2.76265532e-01,  1.22881662e-02, -7.09374249e-02,\n",
      "         1.62477165e-01, -2.31206939e-01,  1.09449022e-01],\n",
      "       [-1.05371825e-01,  2.62156934e-01, -5.86525463e-02,\n",
      "         5.78778349e-02, -2.74099737e-01,  1.96551993e-01],\n",
      "       [ 9.49807018e-02,  2.70793915e-01, -1.90632194e-01,\n",
      "        -2.77760565e-01, -1.96012720e-01, -1.81811705e-01],\n",
      "       [ 2.84387879e-02,  1.42196774e-01,  1.23415567e-01,\n",
      "        -2.93612868e-01, -1.15127183e-01, -1.01548277e-01],\n",
      "       [-1.72463851e-03,  1.63864568e-01, -2.31944740e-01,\n",
      "         1.37435079e-01, -3.21046216e-03, -3.13812882e-01],\n",
      "       [ 7.90091902e-02,  2.85928547e-02, -1.23801149e-01,\n",
      "         2.42320165e-01, -1.05109841e-01,  2.07851276e-01],\n",
      "       [-1.85235456e-01,  2.20406279e-01, -1.40047921e-02,\n",
      "        -1.95694521e-01, -3.30916494e-01, -6.33659773e-03],\n",
      "       [ 2.68958569e-01, -2.02016011e-01, -1.12792656e-01,\n",
      "         1.80021405e-01,  2.03234732e-01, -4.30192143e-01],\n",
      "       [-1.24859780e-01, -1.90243125e-01,  9.01301801e-02,\n",
      "        -1.31655186e-01, -7.70909488e-02,  2.22795844e-01],\n",
      "       [ 4.57627475e-02,  1.11567333e-01, -1.25912264e-01,\n",
      "         7.81535208e-02, -1.61610022e-01, -2.86942393e-01],\n",
      "       [-1.84722230e-01, -2.89897054e-01, -1.35755956e-01,\n",
      "        -1.18762022e-02,  2.30735973e-01, -2.43458226e-01],\n",
      "       [ 2.54713356e-01,  3.18209007e-02, -2.72736788e-01,\n",
      "        -2.86171645e-01,  1.66418627e-01, -2.02338636e-01],\n",
      "       [ 5.95189892e-02, -3.27551626e-02, -2.02700570e-01,\n",
      "        -2.40087107e-01, -2.58757263e-01,  1.39242202e-01],\n",
      "       [-2.03782633e-01,  1.17536366e-01,  2.20255405e-01,\n",
      "        -1.31801113e-01, -1.06105179e-01, -8.20630640e-02],\n",
      "       [ 1.16824448e-01, -6.38856217e-02, -5.43568283e-02,\n",
      "        -2.12649912e-01, -3.54745239e-01,  2.42425293e-01],\n",
      "       [ 3.48119959e-02, -1.82195082e-01, -1.26547575e-01,\n",
      "         3.92827056e-02, -1.35414645e-01, -3.87961715e-01],\n",
      "       [ 1.00255564e-01,  2.06166923e-01, -1.64091419e-02,\n",
      "         1.46765634e-01,  1.84595168e-01, -1.33208215e-01],\n",
      "       [ 2.16293082e-01,  1.44797638e-02, -3.85292433e-02,\n",
      "        -4.42280285e-02, -4.83362079e-02,  2.55509347e-01],\n",
      "       [ 9.75972638e-02,  1.96940042e-02, -5.03601655e-02,\n",
      "         5.62773272e-02, -9.59784761e-02,  7.51326978e-02]], dtype=float32), array([ 0.04951829, -0.01027011,  0.01687691, -0.05434727,  0.0130837 ,\n",
      "       -0.05449597], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The average loss for epoch 4 is    0.27 and accuracy is    0.91.\n",
      "7352/7352 [==============================] - 20s 3ms/sample - loss: 0.2674 - accuracy: 0.9108\n",
      "2947/2947 [==============================] - 4s 1ms/sample - loss: 0.4066 - accuracy: 0.8704\n",
      ">#1: 87.038\n",
      "[87.03766465187073]\n",
      "Accuracy: 87.038% (+/-0.000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "            \n",
    "\n",
    "# #Hyperparameter Tuning with the HParams Dashboard\n",
    "# from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n",
    "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "# METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "# \thp.hparams_config(\n",
    "# \t\thparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "# \t\tmetrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "# \t)\n",
    "\n",
    "    \n",
    "# def train_test_model(hparams):\n",
    "# \tmodel = tf.keras.models.Sequential([\n",
    "# \t\ttf.keras.layers.LSTM(100, input_shape=(n_timesteps,n_features)),\n",
    "# \t\ttf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "# \t\ttf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "# \t\ttf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "# \t])\n",
    "# \tmodel.compile(\n",
    "# \t\toptimizer=hparams[HP_OPTIMIZER],\n",
    "# \t\tloss='sparse_categorical_crossentropy',\n",
    "# \t\tmetrics=['accuracy'],\n",
    "# \t)\n",
    "\n",
    "# def run(run_dir, hparams):\n",
    "# \twith tf.summary.create_file_writer(run_dir).as_default():\n",
    "# \t\thp.hparams(hparams)  # record the values used in this trial\n",
    "# \t\taccuracy = train_test_model(hparams)\n",
    "# \t\ttf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "\n",
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values\n",
    "\n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "\tloaded = list()\n",
    "\tfor name in filenames:\n",
    "\t\tdata = load_file(prefix + name)\n",
    "\t\tloaded.append(data)\n",
    "\t# stack group so that features are the 3rd dimension\n",
    "\tloaded = dstack(loaded)\n",
    "\treturn loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "\tfilepath = prefix + group + '/Inertial Signals/'\n",
    "\t# load all 9 files as a single array\n",
    "\tfilenames = list()\n",
    "\t# total acceleration\n",
    "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "\t# body acceleration\n",
    "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "\t# body gyroscope\n",
    "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "\t# load input data\n",
    "\tX = load_group(filenames, filepath)\n",
    "\t# load class output\n",
    "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "\treturn X, y\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "\t# load all train\n",
    "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
    "\tprint(trainX.shape, trainy.shape)\n",
    "\t# load all test\n",
    "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
    "\tprint(testX.shape, testy.shape)\n",
    "\t# zero-offset class values\n",
    "\ttrainy = trainy - 1\n",
    "\ttesty = testy - 1\n",
    "\t# one hot encode y\n",
    "\ttrainy = to_categorical(trainy)\n",
    "\ttesty = to_categorical(testy)\n",
    "\tprint(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "\treturn trainX, trainy, testX, testy\n",
    "\n",
    "\n",
    "def create_model(n_timesteps,n_features,n_outputs):\n",
    "\treturn tf.keras.models.Sequential([\n",
    "\t\ttf.keras.layers.LSTM(100, input_shape=(n_timesteps,n_features)),\n",
    "\t\ttf.keras.layers.Dropout(0.5),\n",
    "\t\ttf.keras.layers.Dense(100, activation='relu'),\n",
    "\t\ttf.keras.layers.Dense(n_outputs, activation='softmax')\n",
    "\t])\n",
    "\n",
    "\n",
    "# # fit and evaluate a model\n",
    "# def evaluate_model(trainX, trainy, testX, testy):\n",
    "# \t# define model\n",
    "# \tverbose, epochs, batch_size = 0, 25, 64\n",
    "# \tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "# \t# reshape data into time steps of sub-sequences\n",
    "# \tn_steps, n_length = 4, 32\n",
    "# \ttrainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "# \ttestX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "# \t# define model\n",
    "# #\tmodel = Sequential()\n",
    "# \t#model = tf.keras.Sequential(n_length, n_features)\n",
    "# \tmodel = create_model(n_length, n_features, n_outputs)\n",
    "\n",
    "# #\tmodel.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "# #\tmodel.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "# #\tmodel.add(TimeDistributed(Dropout(0.5)))\n",
    "# #\tmodel.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "# #\tmodel.add(TimeDistributed(Flatten()))\n",
    "# #\tmodel.add(LSTM(100))\n",
    "# #\tmodel.add(Dropout(0.5))\n",
    "# #\tmodel.add(Dense(100, activation='relu'))\n",
    "# #\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "# \tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# \tprint(\"FIT ==================================================1 \");\n",
    "# \tlog_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# \ttensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# \t# fit network\n",
    "# # \tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "# # \tprint(\"FIT ==================================================2 \");\n",
    "# # \t# evaluate model\n",
    "# # \t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "#     ## epoches = how many times run - changed to for statement.\n",
    "#     ## verbose = log depth; 0=small amount logging. 1= show Epoch 1/1 7352/7352\n",
    "#     ## batch_size == \n",
    "# \tfor i in range(epochs):\n",
    "# \t\tprint(\"FIT ==================================================2 \");\n",
    "# \t\t#model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "# #model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "# #\t\tmodel.fit(trainX, trainy, batch_size=batch_size, verbose=1)\n",
    "# \t\tmodel.fit(trainX, trainy, batch_size=batch_size, verbose=1, callbacks=[tensorboard_callback])\n",
    "# # \t\t##model.reset_states()\n",
    "# \t\tprint(\"FIT ==================================================3 \");\n",
    "# \tprint(\"Evalutate ================================================== \");\n",
    "# \t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "# \tprint(\"Evalutate ================================================== \");\n",
    "# \treturn accuracy\n",
    "\n",
    "\n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "#\tverbose, epochs, batch_size = 0, 15, 64\n",
    "\tverbose, epochs, batch_size = 0, 5, 64\n",
    "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "# \tmodel = Sequential()\n",
    "# \tmodel.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "# \tmodel.add(Dropout(0.5))\n",
    "# \tmodel.add(Dense(100, activation='relu'))\n",
    "# \tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "#for graph1\n",
    "\tmodel = create_model(n_timesteps,n_features,n_outputs)\n",
    "# \tmodel= tf.keras.models.Sequential([\n",
    "# \t\ttf.keras.layers.LSTM(100, input_shape=(n_timesteps,n_features)),\n",
    "# \t\ttf.keras.layers.Dropout(0.5),\n",
    "# \t\ttf.keras.layers.Dense(100, activation='relu'),\n",
    "# \t\ttf.keras.layers.Dense(n_outputs, activation='softmax')\n",
    "# \t])\n",
    "\n",
    "\n",
    "# get TF logger\n",
    "\tlog = logging.getLogger('tensorflow')\n",
    "\tlog.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter and add it to the handlers\n",
    "#\tformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "#\tlog_dir = \"logs/test/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "#\tlog_file = '{}/dashboard.log'.format(log_loc)\n",
    "#\tDir = os.path.join(os.path.dirname(os.path.abspath(logname.dname)), 'logs')\n",
    "\tformatter = logging.Formatter('%(asctime)s %(levelname)s:%(name)s %(message)s')\n",
    "\tlogFile = 'Log %s.log' % (datetime.datetime.now().strftime('%d-%m-%Y %H:%M:%S'))\n",
    "\tDirfilelog = os.path.join('logs/', logFile)\n",
    "    \n",
    "# create file handler which logs even debug messages\n",
    "\tfh = logging.FileHandler(Dirfilelog)\n",
    "\tfh.setLevel(logging.DEBUG)\n",
    "\tfh.setFormatter(formatter)\n",
    "\tlog.addHandler(fh)\n",
    "\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    #for Graph1\n",
    "\t#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    #for Graph2\n",
    "#\ttensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "\n",
    "\tdef get_model_summary(model):\n",
    "\t\tstream = io.StringIO()\n",
    "\t\tmodel.summary(print_fn=lambda x: stream.write(x + '\\n'))\n",
    "\t\tsummary_string = stream.getvalue()\n",
    "\t\tstream.close()\n",
    "\t\treturn summary_string\n",
    "\n",
    "\tmodel_summary_string = get_model_summary(model)\n",
    "\tlog.info(model_summary_string)\n",
    "\n",
    "    #for customGraph\n",
    "\tclass MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "#\t\tdef set_model(self, batch, logs=None):\n",
    "# \t\t\tmodel_summary_string = get_model_summary(model)\n",
    "# \t\t\tlog.info(model_summary_string)\n",
    "\t\tdef on_train_batch_end(self, batch, logs=None):\n",
    "\t\t\tlog.info('For batch {}, loss is {:7.2f}.'.format(batch, logs['loss']))\n",
    "\t\t\tlog.info('For batch {}, accuracy is {:7.2f}.'.format(batch, logs['accuracy']))\n",
    "\t\tdef on_test_batch_end(self, batch, logs=None):\n",
    "\t\t\tlog.info('For batch {}, loss is {:7.2f}.'.format(batch, logs['loss']))\n",
    "\t\t\tlog.info('For batch {}, accuracy is {:7.2f}.'.format(batch, logs['accuracy']))\n",
    "\t\tdef on_epoch_end(self, epoch, logs=None):\n",
    "\t\t\t#np.testing.assert_allclose(np.squeeze(out), np.squeeze(out2), atol=1e-05)\n",
    "\t\t\tfor i in range(len(model.layers)):\n",
    "\t\t\t\tnew_weights = model.layers[i].get_weights()\n",
    "\t\t\t\tlog.info('weights of {} layers for epoch{} is {}'.format(i+1, epoch, new_weights))     \n",
    "\t\t\t\t#for j in range(len(new_weights)):\n",
    "\t\t\t\t\t#if old_weights[i]:\n",
    "\t\t\t\t\t\t#np.testing.assert_allclose(old_weights[i][j], new_weights[j], atol=1e-05)     \n",
    "\t\t\tlog.info('The average loss for epoch {} is {:7.2f} and accuracy is {:7.2f}.'.format(epoch, logs['loss'], logs['accuracy']))\n",
    "\n",
    "           \n",
    "\n",
    "\t# fit network\n",
    "# \tfor i in range(epochs):\n",
    "# \t\tmodel.fit(trainX, trainy, batch_size=batch_size, verbose=1)\n",
    "        \n",
    "    #For graph1\n",
    "\t#model.fit(x=trainX, y=trainy, epochs=epochs, verbose=1, validation_data=(testX, testy), callbacks=[tensorboard_callback])\n",
    "    \n",
    "    \n",
    "    #For graph2\n",
    "#\tmodel.fit(x=trainX, y=trainy, epochs=epochs,batch_size=64, verbose=1, callbacks=[LossAndErrorPrintingCallback()])\n",
    "\n",
    "    #For CustomGraph\n",
    "    \n",
    "#\ttest.test1(model);\n",
    "\n",
    "\tmodel.fit(x=trainX, y=trainy, epochs=epochs,batch_size=64, verbose=1, callbacks=[MyCustomCallback()])\n",
    "#\tmodel.fit(x=trainX, y=trainy, epochs=epochs,batch_size=64, verbose=1, callbacks=[test.test1(test, epochs, model)])\n",
    "    \n",
    "    #for Graph3\n",
    "# \tmodel.fit(trainX, trainy, epochs=1,\n",
    "# \t\tcallbacks=[\n",
    "# \t\ttf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
    "# \t\thp.KerasCallback(logdir, hparams),  # log hparams\n",
    "# \t],) # Run with 1 epoch to speed things up for demo purposes\n",
    "    \n",
    "# \t\tmodel.fit(x=trainX, y=trainy, validation_data=(testX, testy), callbacks=[tensorboard_callback])\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=1)\n",
    "\treturn accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "\tprint(scores)\n",
    "\tm, s = mean(scores), std(scores)\n",
    "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "# run an experiment\n",
    "#def run_experiment(repeats=10):\n",
    "def run_experiment(repeats=1):\n",
    "\t# load data\n",
    "\ttrainX, trainy, testX, testy = load_dataset()\n",
    "\t# repeat experiment\n",
    "\tscores = list()\n",
    "\tfor r in range(repeats):\n",
    "\t\tscore = evaluate_model(trainX, trainy, testX, testy)\n",
    "\t\tscore = score * 100.0\n",
    "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
    "\t\tscores.append(score)\n",
    "\t# summarize results\n",
    "\tsummarize_results(scores)\n",
    "\n",
    "# \tsession_num = 0\n",
    "# \tfor num_units in HP_NUM_UNITS.domain.values:\n",
    "# \t\tfor dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "# \t\t\tfor optimizer in HP_OPTIMIZER.domain.values:\n",
    "# \t\t\t\thparams = {\n",
    "# \t\t\t\t\tHP_NUM_UNITS: num_units,\n",
    "# \t\t\t\t\tHP_DROPOUT: dropout_rate,\n",
    "# \t\t\t\t\tHP_OPTIMIZER: optimizer,\n",
    "# \t\t\t\t}\n",
    "# \t\t\t\trun_name = \"run-%d\" % session_num\n",
    "# \t\t\t\tprint('--- Starting trial: %s' % run_name)\n",
    "# \t\t\t\tprint({h.name: hparams[h] for h in hparams})\n",
    "# \t\t\t\trun('logs/hparam_tuning/' + run_name, hparams)\n",
    "# \t\t\t\tsession_num += 1\n",
    "    \n",
    "# def get_model_summary(model):\n",
    "# \tstream = io.StringIO()\n",
    "# \tmodel.summary(print_fn=lambda x: stream.write(x + '\\n'))\n",
    "# \tsummary_string = stream.getvalue()\n",
    "# \tstream.close()\n",
    "# \treturn summary_string\n",
    "\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
